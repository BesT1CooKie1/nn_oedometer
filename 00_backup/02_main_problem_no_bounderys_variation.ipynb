{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202376a2a307e3c2",
   "metadata": {},
   "source": [
    "# Vorhersage des Ödometerversuches implementiert mit PINA\n",
    "Ziel war die Implementierung eines neuronalen Netzwerks zur Modellierung des Ödometerversuchs. Dabei wurden gegebene Input-Parameter verarbeitet, um Output-Parameter vorherzusagen. Die physikalischen Rahmenbedingungen wurden zunächst auf Null gesetzt, sodass das Modell ausschließlich auf der KI-basierten Struktur arbeitet, ohne physikalische Optimierungen durch Physical Informed Neural Networks (PINNs).\n",
    "<br>\n",
    "Diese grundlegende Umsetzung bildet die Basis für weiterführende Optimierungen, wie die Integration physikalischer Gesetzmäßigkeiten, die jedoch nicht Teil des initialen Arbeitsauftrags waren.\n",
    "\n",
    "### Was ist PINA?\n",
    "PINA ist eine Open-Source-Python-Bibliothek, die eine intuitive Schnittstelle zur Lösung von Differentialgleichungen bietet, indem sie Physik-informierte Neuronale Netze (PINNs), Neuronale Operatoren (NOs) oder eine Kombination aus beiden verwendet. Basierend auf PyTorch und PyTorch Lightning ermöglicht PINA die formale Darstellung spezifischer (differentieller) Probleme und deren Lösung mittels neuronaler Netze.<br><br>\n",
    "<strong>Hauptmerkmale von PINA:</strong>\n",
    "\n",
    "- <span style=\"color:gray;\"><i>Problemformulierung: Ermöglicht die Übersetzung mathematischer Gleichungen in Python-Code, um das Differentialproblem zu definieren.</i></span>\n",
    "    - <small><i>→ In diesem Arbeitsauftrag nicht notwendig, da das neuronale Netzwerk ohne physikalische Gesetzmäßigkeiten trainiert wurde.</i></small>\n",
    "- Modelltraining: Bietet Werkzeuge zum Training neuronaler Netze zur Lösung des definierten Problems.\n",
    "- Lösungsauswertung: Erlaubt die Visualisierung und Analyse der approximierten Lösungen.\n",
    "\n",
    "<small><i>Hinweis: Die physikalische Modellierung und die Einbindung von Differentialgleichungen zur Optimierung des Netzwerks (z. B. mittels PINNs) war nicht Teil dieses Arbeitsauftrags, könnte aber in einem späteren Schritt ergänzt werden.</i></small>\n",
    "## Grundlagen\n",
    "In diesem Notebook wird der Ödometerversuch <strong>ohne</strong> Randbedingungen betrachtet. Es werden vorberechnetet Daten aus der Exceltabelle `files/oedometer/oedo_trainingsdata.xlsx` verwendet.<br>\n",
    "#### Das Problem ist wie folgt definiert:\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "    \\sigma_{t+1} & = & \\sigma_{t}+\\Delta\\sigma \\\\ \\\\\n",
    "    \\Delta\\sigma & = & E_s\\cdot \\Delta\\epsilon \\\\ \n",
    "    E_s & = & \\frac{1+e_0}{C_c} \\cdot \\sigma_t\n",
    "\\end{array}\n",
    "\\hspace{2cm}\n",
    "\\begin{array}{l}\n",
    "    \\textbf{Annahmen:} \\\\ \\\\\n",
    "    \\text{Startwert d. Iteration: } \\sigma_t = 1,00 \\\\ \n",
    "    e_0 = 1,00 \\\\ \n",
    "    C_c = 0,005 \\\\\n",
    "    \\Delta\\epsilon = 0,0005\n",
    "\\end{array}\n",
    "$$\n",
    "<div = style=\"text-align: center;\">\n",
    "    <img alt=\"Problem Oedometer Preview\" src=\"./graph/problem_preview.png\" width=\"50%\" height=auto>\n",
    "</div>\n",
    "\n",
    "<br> \n",
    "\n",
    "Um das PINA-Model zu testen werden wir folgende vorberechnete Werte verwenden: `Input` { $\\sigma_t$ ; $\\Delta\\epsilon$ }, `Output` { $\\sigma_{t+1}$ }.\n",
    "<br>\n",
    "### Variablendeklaration\n",
    "- $\\sigma_t$ = `sigma_t`\n",
    "- $\\Delta\\epsilon$ = `delta_epsilon`\n",
    "- $\\sigma_{t+1}$ = `delta_sigma`\n",
    "## Einstellungen und Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ab565a-fc02-41df-89e3-9888204d845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Keine doppelte Darstellung des Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Debugger: Aktiviert\n",
    "debug_mode = True\n",
    "# Normalisierung der Daten: Deaktiviert\n",
    "normalize_data = False\n",
    "use_excel = False\n",
    "max_input_pts = 20\n",
    "\n",
    "# Trainingsdaten e_0:float=1.00, C_c:float=0.005, delta_epsilon:float=0.0005, sigma_t:float=1.00, max_n:int=50\n",
    "oedo_parameter = {'e_0':1.00, 'C_c':0.005, 'delta_epsilon':0.0005, 'sigma_t':1.00, 'max_n':100, 'rand_epsilon':False}\n",
    "\n",
    "new_test = False\n",
    "\n",
    "graph_folder = 'graph'\n",
    "img_extensions = '.png'\n",
    "\n",
    "img_visual_loss = 'visual_loss'\n",
    "img_nn_result_error = 'img_nn_result_error'\n",
    "img_visual_prediction_vs_truesolution_comp = 'visual_prediction-vs-truesolution_comp'\n",
    "img_visual_prediction_vs_truesolution_comp0 = 'visual_prediction-vs-truesolution_comp0'\n",
    "img_visual_prediction_vs_truesolution_comp1 = 'visual_prediction-vs-truesolution_comp1'\n",
    "img_visual_prediction_vs_truesolution_comp2 = 'visual_prediction-vs-truesolution_comp2'\n",
    "img_visual_prediction_vs_truesolution = 'visual_prediction-vs-truesolution'\n",
    "img_visual_sampling = 'visual_sampling'\n",
    "\n",
    "def dict_to_markdown_table(data: dict, title: str = \"Datenübersicht\", include_index: bool = True, round_digits: int = 4):\n",
    "    \"\"\"\n",
    "    Wandelt ein Dictionary mit Listenwerten in eine Markdown-Tabelle für Jupyter Notebooks um.\n",
    "    \n",
    "    - Schlüssel werden als Header genutzt\n",
    "    - Erste Spalte ist ein Index, falls `include_index=True`\n",
    "    - Einzelwerte werden als separate Tabelle unterhalb dargestellt\n",
    "    - Zahlenwerte werden auf eine einstellbare Anzahl an Nachkommastellen gerundet\n",
    "\n",
    "    :param data: Dictionary mit Key-Value-Paaren\n",
    "    :param title: Überschrift für die Tabelle\n",
    "    :param include_index: Falls True, wird eine Index-Spalte erstellt\n",
    "    :param round_digits: Anzahl der Nachkommastellen, auf die Werte gerundet werden sollen\n",
    "    :return: Markdown-String zur Anzeige in Jupyter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hilfsfunktion zum Runden von Zahlen\n",
    "    def round_value(val):\n",
    "        if isinstance(val, (int, float)):\n",
    "            return round(val, round_digits)\n",
    "        return val\n",
    "\n",
    "    # Listen und einzelne Werte trennen\n",
    "    list_data = {k: v for k, v in data.items() if isinstance(v, list)}\n",
    "    single_values = {k: v for k, v in data.items() if not isinstance(v, list)}\n",
    "\n",
    "    # Falls es Listen gibt, erstelle eine Tabelle mit Index\n",
    "    if list_data:\n",
    "        max_len = max(len(v) for v in list_data.values())  # Längste Liste bestimmen\n",
    "\n",
    "        # Tabellenkopf\n",
    "        md_table = f\"### {title}\\n\\n\"\n",
    "        md_table += \"| \" + (\"Index | \" if include_index else \"\") + \" | \".join(list_data.keys()) + \" |\\n\"\n",
    "        md_table += \"|-\" + (\"-|\" if include_index else \"\") + \"-|\".join([\"-\" * len(k) for k in list_data.keys()]) + \"-|\\n\"\n",
    "\n",
    "        # Datenzeilen\n",
    "        for i in range(max_len):\n",
    "            row = [str(i)] if include_index else []  # Index hinzufügen (optional)\n",
    "            for key in list_data:\n",
    "                if i < len(list_data[key]):\n",
    "                    row.append(str(round_value(list_data[key][i])))\n",
    "                else:\n",
    "                    row.append(\"\")  # Leere Werte für ungleich lange Listen\n",
    "            md_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "    \n",
    "    else:\n",
    "        md_table = \"\"\n",
    "\n",
    "    # Einzelwerte als extra Tabelle darstellen\n",
    "    if single_values:\n",
    "        md_table += \"\\n\\n#### Einzelwerte\\n\\n\"\n",
    "        md_table += \"| \" + \" | \".join(single_values.keys()) + \" |\\n\"\n",
    "        md_table += \"|-\" + \"-|\".join([\"-\" * len(k) for k in single_values.keys()]) + \"-|\\n\"\n",
    "        md_table += \"| \" + \" | \".join(map(lambda v: str(round_value(v)), single_values.values())) + \" |\\n\"\n",
    "\n",
    "    return Markdown(md_table)\n",
    "\n",
    "\n",
    "def display_data_loss_table(data_dict, delta_sigma_pred, max_i):\n",
    "    \"\"\"\n",
    "    Erstellt eine Markdown-Tabelle zur übersichtlichen Darstellung von Datenverlust.\n",
    "    \n",
    "    Unterstützt sowohl Python-Listen als auch NumPy-Arrays.\n",
    "    \n",
    "    :param data_dict: Dictionary mit `sigma_t` und `delta_sigma` (Listen oder np.arrays)\n",
    "    :param delta_sigma_pred: Vorhergesagte Werte für `delta_sigma` (Liste oder np.array)\n",
    "    :param max_i: Anzahl der Werte, die in der Tabelle angezeigt werden sollen\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sicherstellen, dass `sigma_t` und `delta_sigma` existieren\n",
    "    if \"sigma_t\" not in data_dict or \"delta_sigma\" not in data_dict or delta_sigma_pred is None:\n",
    "        print(\"Fehler: `data_dict` oder `delta_sigma_pred` ist nicht korrekt definiert!\")\n",
    "        return\n",
    "\n",
    "    # Konvertiere alle Werte zu Listen (falls sie NumPy-Arrays sind)\n",
    "    def to_list(arr):\n",
    "        return arr.tolist() if isinstance(arr, np.ndarray) else arr\n",
    "\n",
    "    total_epsilon = to_list(data_dict[\"total_epsilon\"])\n",
    "    delta_epsilon = to_list(data_dict[\"delta_epsilon\"])\n",
    "    sigma_t = to_list(data_dict[\"sigma_t\"])\n",
    "    delta_sigma_true = to_list(data_dict[\"delta_sigma\"])\n",
    "    delta_sigma_pred = to_list(delta_sigma_pred.flatten())  # Falls `delta_sigma_pred` ein 2D-Array ist\n",
    "    \n",
    "    # Überprüfen, ob die Längen konsistent sind\n",
    "    min_len = min(len(total_epsilon), len(sigma_t), len(delta_epsilon), len(delta_sigma_true), len(delta_sigma_pred), max_i)\n",
    "\n",
    "    # Erstelle eine Tabelle für die übersichtliche Darstellung\n",
    "    data_loss_table = {\n",
    "        \"total_epsilon\" : list(total_epsilon[:min_len]), \n",
    "        \"delta_epsilon\" : list(delta_epsilon[:min_len]), \n",
    "        \"sigma_t\" : list(sigma_t[:min_len]), \n",
    "        \"True delta_sigma\": list(delta_sigma_true[:min_len]),\n",
    "        \"Predicted delta_sigma\": list(delta_sigma_pred[:min_len]),\n",
    "        \"Test-Loss (True - Predicted)\": list(np.round(np.array(delta_sigma_true[:min_len]) - np.array(delta_sigma_pred[:min_len]), 5))\n",
    "    }\n",
    "\n",
    "    # Markdown-Tabelle für bessere Darstellung in Jupyter\n",
    "    display(dict_to_markdown_table(data_loss_table, title=f\"Data-Loss bis sigma_{min_len-1}\", include_index=True))\n",
    "\n",
    "def plot_prediction_vs_true_solution(pinn, data_dict, graph_folder, img_visual_prediction_vs_truesolution, \n",
    "                                     img_extensions, y_axis='delta_sigma', max_i=20, plot_type=\"line\"):\n",
    "    \"\"\"\n",
    "    Erstellt und speichert eine Vorhersage- vs. True-Solution-Grafik für ein gegebenes PINN-Modell.\n",
    "\n",
    "    :param pinn: Das trainierte PINN-Modell zur Vorhersage von delta_sigma\n",
    "    :param data_dict: Dictionary mit den Eingabe- und wahren Ausgabe-Daten\n",
    "    :param graph_folder: Ordner, in dem das Bild gespeichert wird\n",
    "    :param img_visual_prediction_vs_truesolution: Dateiname der gespeicherten Grafik (ohne Erweiterung)\n",
    "    :param img_extensions: Dateiformat der gespeicherten Grafik (z.B. '.png' oder '.jpg')\n",
    "    :param max_i: Anzahl der Datenpunkte, die im Plot gezeigt werden sollen (Default: 20)\n",
    "    :param delta_epsilon: Wert für delta_epsilon, um ihn im Titel anzuzeigen (optional)\n",
    "    :param plot_type: Art der Darstellung - \"line\" für Linienplot, \"scatter\" für Punktplot (Default: \"line\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Überprüfen, ob die notwendigen Keys vorhanden sind\n",
    "    if \"sigma_t\" not in data_dict or y_axis not in data_dict:\n",
    "        print(f\"Fehler: sigma_t oder y_axis fehlen im data_dict!\")\n",
    "        return\n",
    "\n",
    "    # Eingabedaten für das Modell vorbereiten\n",
    "    input_data = LabelTensor(torch.tensor(\n",
    "        np.column_stack((data_dict['sigma_t'], data_dict['delta_epsilon'])), \n",
    "        dtype=torch.float), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "    # Vorhersage berechnen\n",
    "    sigma_t_pred = pinn(input_data).detach().numpy()\n",
    "\n",
    "    # Plot erstellen\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    y_vals = data_dict[y_axis][0:max_i]\n",
    "    x_true = data_dict['delta_sigma'][0:max_i]\n",
    "    x_pred = sigma_t_pred[0:max_i]\n",
    "\n",
    "    if plot_type == \"line\":\n",
    "        plt.plot(x_true, y_vals, label=\"True Solution (delta_sigma)\", linestyle='dashed', color='blue')\n",
    "        plt.plot(x_pred, y_vals, label=\"NN Prediction (delta_sigma)\", linestyle='solid', color='red')\n",
    "    elif plot_type == \"scatter\":\n",
    "        plt.scatter(x_true, y_vals, label=\"True Solution (delta_sigma)\", color='blue', marker='o')\n",
    "        plt.scatter(x_pred, y_vals, label=\"NN Prediction (delta_sigma)\", color='red', marker='x')\n",
    "\n",
    "    plt.xlabel(\"delta_sigma\")\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(f\"Prediction vs. True Solution (max_i={max_i-1})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Bild speichern\n",
    "    img_path = f'./{graph_folder}/{img_visual_prediction_vs_truesolution}{img_extensions}'\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()  # Verhindert doppelte Darstellung\n",
    "\n",
    "    # Markdown-Ausgabe in Jupyter Notebook\n",
    "    display(Markdown(f'![Prediction vs True Solution]({img_path})<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccebd6-ea34-4979-a87a-59aec6f551e9",
   "metadata": {},
   "source": [
    "## Laden der Daten aus `oedo_trainingsdata.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649daf452361b99a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.087047Z",
     "start_time": "2025-03-12T08:30:30.555114Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy.integrals.heurisch import components\n",
    "\n",
    "def extract_excel(file_path, sheet_name, selected_columns, row_start_range):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Dynamische Ermittlung der letzten Zeile mit Daten\n",
    "    row_start_range = 0  # Startet bei Zeile 6 (0-basiert)\n",
    "    row_end_range = df.dropna(how=\"all\").last_valid_index() + 1  # Letzte Zeile mit Daten\n",
    "        \n",
    "    # Daten extrahieren\n",
    "    data_subset = df.iloc[row_start_range:row_end_range, selected_columns]\n",
    "    data_dict = {col: np.array(data_subset[col]) for col in data_subset.columns}\n",
    "    \n",
    "    if debug_mode:\n",
    "        print(data_dict)\n",
    "        dict_to_markdown_table(data=data_dict,title=file_path)\n",
    "    \n",
    "    # Daten als dict speichern\n",
    "    return data_dict\n",
    "    \n",
    "if use_excel:\n",
    "    data_dict = extract_excel(file_path, sheet_name, selected_columns, row_start_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191696f7-1790-4523-b91e-f12aec2a87ce",
   "metadata": {},
   "source": [
    "## Laden der Daten aus `Python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fe8225-b11a-4954-9367-b1312eba8d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Ödometerdaten\n",
       "\n",
       "| Index | e_0 | C_c | sigma_t | delta_epsilon | total_epsilon | delta_sigma | e_s |\n",
       "|--|----|----|--------|--------------|--------------|------------|----|\n",
       "| 0 | 1.0 | 0.005 | 1.0 | 0.0005 | 0 | 0.2 | 400.0 |\n",
       "| 1 | 1.0 | 0.005 | 1.2 | 0.0005 | 0.0005 | 0.24 | 480.0 |\n",
       "| 2 | 1.0 | 0.005 | 1.44 | 0.0005 | 0.001 | 0.288 | 576.0 |\n",
       "| 3 | 1.0 | 0.005 | 1.728 | 0.0005 | 0.0015 | 0.3456 | 691.2 |\n",
       "| 4 | 1.0 | 0.005 | 2.0736 | 0.0005 | 0.002 | 0.4147 | 829.44 |\n",
       "| 5 | 1.0 | 0.005 | 2.4883 | 0.0005 | 0.0025 | 0.4977 | 995.328 |\n",
       "| 6 | 1.0 | 0.005 | 2.986 | 0.0005 | 0.003 | 0.5972 | 1194.3936 |\n",
       "| 7 | 1.0 | 0.005 | 3.5832 | 0.0005 | 0.0035 | 0.7166 | 1433.2723 |\n",
       "| 8 | 1.0 | 0.005 | 4.2998 | 0.0005 | 0.004 | 0.86 | 1719.9268 |\n",
       "| 9 | 1.0 | 0.005 | 5.1598 | 0.0005 | 0.0045 | 1.032 | 2063.9121 |\n",
       "| 10 | 1.0 | 0.005 | 6.1917 | 0.0005 | 0.005 | 1.2383 | 2476.6946 |\n",
       "| 11 | 1.0 | 0.005 | 7.4301 | 0.0005 | 0.0055 | 1.486 | 2972.0335 |\n",
       "| 12 | 1.0 | 0.005 | 8.9161 | 0.0005 | 0.006 | 1.7832 | 3566.4402 |\n",
       "| 13 | 1.0 | 0.005 | 10.6993 | 0.0005 | 0.0065 | 2.1399 | 4279.7282 |\n",
       "| 14 | 1.0 | 0.005 | 12.8392 | 0.0005 | 0.007 | 2.5678 | 5135.6739 |\n",
       "| 15 | 1.0 | 0.005 | 15.407 | 0.0005 | 0.0075 | 3.0814 | 6162.8086 |\n",
       "| 16 | 1.0 | 0.005 | 18.4884 | 0.0005 | 0.008 | 3.6977 | 7395.3704 |\n",
       "| 17 | 1.0 | 0.005 | 22.1861 | 0.0005 | 0.0085 | 4.4372 | 8874.4444 |\n",
       "| 18 | 1.0 | 0.005 | 26.6233 | 0.0005 | 0.009 | 5.3247 | 10649.3333 |\n",
       "| 19 | 1.0 | 0.005 | 31.948 | 0.0005 | 0.0095 | 6.3896 | 12779.2 |\n",
       "| 20 | 1.0 | 0.005 | 38.3376 | 0.0005 | 0.01 | 7.6675 | 15335.04 |\n",
       "| 21 | 1.0 | 0.005 | 46.0051 | 0.0005 | 0.0105 | 9.201 | 18402.048 |\n",
       "| 22 | 1.0 | 0.005 | 55.2061 | 0.0005 | 0.011 | 11.0412 | 22082.4576 |\n",
       "| 23 | 1.0 | 0.005 | 66.2474 | 0.0005 | 0.0115 | 13.2495 | 26498.9491 |\n",
       "| 24 | 1.0 | 0.005 | 79.4968 | 0.0005 | 0.012 | 15.8994 | 31798.7389 |\n",
       "| 25 | 1.0 | 0.005 | 95.3962 | 0.0005 | 0.0125 | 19.0792 | 38158.4867 |\n",
       "| 26 | 1.0 | 0.005 | 114.4755 | 0.0005 | 0.013 | 22.8951 | 45790.184 |\n",
       "| 27 | 1.0 | 0.005 | 137.3706 | 0.0005 | 0.0135 | 27.4741 | 54948.2208 |\n",
       "| 28 | 1.0 | 0.005 | 164.8447 | 0.0005 | 0.014 | 32.9689 | 65937.8649 |\n",
       "| 29 | 1.0 | 0.005 | 197.8136 | 0.0005 | 0.0145 | 39.5627 | 79125.4379 |\n",
       "| 30 | 1.0 | 0.005 | 237.3763 | 0.0005 | 0.015 | 47.4753 | 94950.5255 |\n",
       "| 31 | 1.0 | 0.005 | 284.8516 | 0.0005 | 0.0155 | 56.9703 | 113940.6306 |\n",
       "| 32 | 1.0 | 0.005 | 341.8219 | 0.0005 | 0.016 | 68.3644 | 136728.7567 |\n",
       "| 33 | 1.0 | 0.005 | 410.1863 | 0.0005 | 0.0165 | 82.0373 | 164074.5081 |\n",
       "| 34 | 1.0 | 0.005 | 492.2235 | 0.0005 | 0.017 | 98.4447 | 196889.4097 |\n",
       "| 35 | 1.0 | 0.005 | 590.6682 | 0.0005 | 0.0175 | 118.1336 | 236267.2917 |\n",
       "| 36 | 1.0 | 0.005 | 708.8019 | 0.0005 | 0.018 | 141.7604 | 283520.75 |\n",
       "| 37 | 1.0 | 0.005 | 850.5622 | 0.0005 | 0.0185 | 170.1124 | 340224.9 |\n",
       "| 38 | 1.0 | 0.005 | 1020.6747 | 0.0005 | 0.019 | 204.1349 | 408269.88 |\n",
       "| 39 | 1.0 | 0.005 | 1224.8096 | 0.0005 | 0.0195 | 244.9619 | 489923.856 |\n",
       "| 40 | 1.0 | 0.005 | 1469.7716 | 0.0005 | 0.02 | 293.9543 | 587908.6272 |\n",
       "| 41 | 1.0 | 0.005 | 1763.7259 | 0.0005 | 0.0205 | 352.7452 | 705490.3526 |\n",
       "| 42 | 1.0 | 0.005 | 2116.4711 | 0.0005 | 0.021 | 423.2942 | 846588.4232 |\n",
       "| 43 | 1.0 | 0.005 | 2539.7653 | 0.0005 | 0.0215 | 507.9531 | 1015906.1078 |\n",
       "| 44 | 1.0 | 0.005 | 3047.7183 | 0.0005 | 0.022 | 609.5437 | 1219087.3293 |\n",
       "| 45 | 1.0 | 0.005 | 3657.262 | 0.0005 | 0.0225 | 731.4524 | 1462904.7952 |\n",
       "| 46 | 1.0 | 0.005 | 4388.7144 | 0.0005 | 0.023 | 877.7429 | 1755485.7542 |\n",
       "| 47 | 1.0 | 0.005 | 5266.4573 | 0.0005 | 0.0235 | 1053.2915 | 2106582.9051 |\n",
       "| 48 | 1.0 | 0.005 | 6319.7487 | 0.0005 | 0.024 | 1263.9497 | 2527899.4861 |\n",
       "| 49 | 1.0 | 0.005 | 7583.6985 | 0.0005 | 0.0245 | 1516.7397 | 3033479.3833 |\n",
       "| 50 | 1.0 | 0.005 | 9100.4382 | 0.0005 | 0.025 | 1820.0876 | 3640175.26 |\n",
       "| 51 | 1.0 | 0.005 | 10920.5258 | 0.0005 | 0.0255 | 2184.1052 | 4368210.312 |\n",
       "| 52 | 1.0 | 0.005 | 13104.6309 | 0.0005 | 0.026 | 2620.9262 | 5241852.3744 |\n",
       "| 53 | 1.0 | 0.005 | 15725.5571 | 0.0005 | 0.0265 | 3145.1114 | 6290222.8493 |\n",
       "| 54 | 1.0 | 0.005 | 18870.6685 | 0.0005 | 0.027 | 3774.1337 | 7548267.4191 |\n",
       "| 55 | 1.0 | 0.005 | 22644.8023 | 0.0005 | 0.0275 | 4528.9605 | 9057920.903 |\n",
       "| 56 | 1.0 | 0.005 | 27173.7627 | 0.0005 | 0.028 | 5434.7525 | 10869505.0836 |\n",
       "| 57 | 1.0 | 0.005 | 32608.5153 | 0.0005 | 0.0285 | 6521.7031 | 13043406.1003 |\n",
       "| 58 | 1.0 | 0.005 | 39130.2183 | 0.0005 | 0.029 | 7826.0437 | 15652087.3203 |\n",
       "| 59 | 1.0 | 0.005 | 46956.262 | 0.0005 | 0.0295 | 9391.2524 | 18782504.7844 |\n",
       "| 60 | 1.0 | 0.005 | 56347.5144 | 0.0005 | 0.03 | 11269.5029 | 22539005.7413 |\n",
       "| 61 | 1.0 | 0.005 | 67617.0172 | 0.0005 | 0.0305 | 13523.4034 | 27046806.8895 |\n",
       "| 62 | 1.0 | 0.005 | 81140.4207 | 0.0005 | 0.031 | 16228.0841 | 32456168.2674 |\n",
       "| 63 | 1.0 | 0.005 | 97368.5048 | 0.0005 | 0.0315 | 19473.701 | 38947401.9209 |\n",
       "| 64 | 1.0 | 0.005 | 116842.2058 | 0.0005 | 0.032 | 23368.4412 | 46736882.3051 |\n",
       "| 65 | 1.0 | 0.005 | 140210.6469 | 0.0005 | 0.0325 | 28042.1294 | 56084258.7661 |\n",
       "| 66 | 1.0 | 0.005 | 168252.7763 | 0.0005 | 0.033 | 33650.5553 | 67301110.5193 |\n",
       "| 67 | 1.0 | 0.005 | 201903.3316 | 0.0005 | 0.0335 | 40380.6663 | 80761332.6232 |\n",
       "| 68 | 1.0 | 0.005 | 242283.9979 | 0.0005 | 0.034 | 48456.7996 | 96913599.1478 |\n",
       "| 69 | 1.0 | 0.005 | 290740.7974 | 0.0005 | 0.0345 | 58148.1595 | 116296318.9774 |\n",
       "| 70 | 1.0 | 0.005 | 348888.9569 | 0.0005 | 0.035 | 69777.7914 | 139555582.7729 |\n",
       "| 71 | 1.0 | 0.005 | 418666.7483 | 0.0005 | 0.0355 | 83733.3497 | 167466699.3275 |\n",
       "| 72 | 1.0 | 0.005 | 502400.098 | 0.0005 | 0.036 | 100480.0196 | 200960039.193 |\n",
       "| 73 | 1.0 | 0.005 | 602880.1176 | 0.0005 | 0.0365 | 120576.0235 | 241152047.0315 |\n",
       "| 74 | 1.0 | 0.005 | 723456.1411 | 0.0005 | 0.037 | 144691.2282 | 289382456.4379 |\n",
       "| 75 | 1.0 | 0.005 | 868147.3693 | 0.0005 | 0.0375 | 173629.4739 | 347258947.7254 |\n",
       "| 76 | 1.0 | 0.005 | 1041776.8432 | 0.0005 | 0.038 | 208355.3686 | 416710737.2705 |\n",
       "| 77 | 1.0 | 0.005 | 1250132.2118 | 0.0005 | 0.0385 | 250026.4424 | 500052884.7246 |\n",
       "| 78 | 1.0 | 0.005 | 1500158.6542 | 0.0005 | 0.039 | 300031.7308 | 600063461.6695 |\n",
       "| 79 | 1.0 | 0.005 | 1800190.385 | 0.0005 | 0.0395 | 360038.077 | 720076154.0034 |\n",
       "| 80 | 1.0 | 0.005 | 2160228.462 | 0.0005 | 0.04 | 432045.6924 | 864091384.8041 |\n",
       "| 81 | 1.0 | 0.005 | 2592274.1544 | 0.0005 | 0.0405 | 518454.8309 | 1036909661.7649 |\n",
       "| 82 | 1.0 | 0.005 | 3110728.9853 | 0.0005 | 0.041 | 622145.7971 | 1244291594.1179 |\n",
       "| 83 | 1.0 | 0.005 | 3732874.7824 | 0.0005 | 0.0415 | 746574.9565 | 1493149912.9415 |\n",
       "| 84 | 1.0 | 0.005 | 4479449.7388 | 0.0005 | 0.042 | 895889.9478 | 1791779895.5298 |\n",
       "| 85 | 1.0 | 0.005 | 5375339.6866 | 0.0005 | 0.0425 | 1075067.9373 | 2150135874.6358 |\n",
       "| 86 | 1.0 | 0.005 | 6450407.6239 | 0.0005 | 0.043 | 1290081.5248 | 2580163049.563 |\n",
       "| 87 | 1.0 | 0.005 | 7740489.1487 | 0.0005 | 0.0435 | 1548097.8297 | 3096195659.4755 |\n",
       "| 88 | 1.0 | 0.005 | 9288586.9784 | 0.0005 | 0.044 | 1857717.3957 | 3715434791.3707 |\n",
       "| 89 | 1.0 | 0.005 | 11146304.3741 | 0.0005 | 0.0445 | 2229260.8748 | 4458521749.6448 |\n",
       "| 90 | 1.0 | 0.005 | 13375565.2489 | 0.0005 | 0.045 | 2675113.0498 | 5350226099.5737 |\n",
       "| 91 | 1.0 | 0.005 | 16050678.2987 | 0.0005 | 0.0455 | 3210135.6597 | 6420271319.4885 |\n",
       "| 92 | 1.0 | 0.005 | 19260813.9585 | 0.0005 | 0.046 | 3852162.7917 | 7704325583.3862 |\n",
       "| 93 | 1.0 | 0.005 | 23112976.7502 | 0.0005 | 0.0465 | 4622595.35 | 9245190700.0634 |\n",
       "| 94 | 1.0 | 0.005 | 27735572.1002 | 0.0005 | 0.047 | 5547114.42 | 11094228840.0761 |\n",
       "| 95 | 1.0 | 0.005 | 33282686.5202 | 0.0005 | 0.0475 | 6656537.304 | 13313074608.0913 |\n",
       "| 96 | 1.0 | 0.005 | 39939223.8243 | 0.0005 | 0.048 | 7987844.7649 | 15975689529.7096 |\n",
       "| 97 | 1.0 | 0.005 | 47927068.5891 | 0.0005 | 0.0485 | 9585413.7178 | 19170827435.6515 |\n",
       "| 98 | 1.0 | 0.005 | 57512482.307 | 0.0005 | 0.049 | 11502496.4614 | 23004992922.7818 |\n",
       "| 99 | 1.0 | 0.005 | 69014978.7683 | 0.0005 | 0.0495 | 13802995.7537 | 27605991507.3382 |\n",
       "\n",
       "\n",
       "#### Einzelwerte\n",
       "\n",
       "| max_n |\n",
       "|-------|\n",
       "| 100 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Oedometer:\n",
    "    def __init__(self, e_0: float = 1.00, C_c: float = 0.005, delta_epsilon: float = 0.0005, \n",
    "                 sigma_t: float = 1.00, max_n: int = 50, rand_epsilon:bool=False, **kwargs):\n",
    "        self.max_n = max_n\n",
    "\n",
    "        # Standardwerte als Listen setzen\n",
    "        self.e_0 = [e_0]\n",
    "        self.C_c = [C_c]\n",
    "        self.sigma_t = [sigma_t]\n",
    "        self.delta_epsilon = []\n",
    "        self.total_epsilon = [0]\n",
    "\n",
    "        # Initiale Listen für Berechnungen\n",
    "        self.sigma_t = [sigma_t]\n",
    "        self.delta_sigma = []\n",
    "        self.e_s = []\n",
    "        self.delta_epsilon = [delta_epsilon]\n",
    "        \n",
    "        # Dynamische Zuweisung von kwargs, falls vorhanden\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):  # Nur vorhandene Attribute setzen\n",
    "                setattr(self, key, [value])\n",
    "        \n",
    "        # Berechnungen durchführen\n",
    "        self.__calc_sigma_t_p1()\n",
    "\n",
    "        # Listenlängen anpassen\n",
    "        self.__adjust_list_lengths()\n",
    "        self.__calc_total_epsilon()\n",
    "\n",
    "    def __adjust_list_lengths(self):\n",
    "        \"\"\" Passt ALLE Listen-Attribute an `max_n` an. \"\"\"\n",
    "        attributes = ['e_0', 'C_c', 'delta_epsilon', 'sigma_t', 'sigma_t', 'delta_sigma', 'e_s']\n",
    "        for attr in attributes:\n",
    "            value_list = getattr(self, attr, [])\n",
    "            current_length = len(value_list)\n",
    "\n",
    "            if current_length > self.max_n:\n",
    "                setattr(self, attr, value_list[:self.max_n])  # Kürzen\n",
    "            elif current_length < self.max_n:\n",
    "                setattr(self, attr, value_list + [value_list[-1] if value_list else 0] * (self.max_n - current_length))  # Auffüllen\n",
    "    \n",
    "    def __calc_total_epsilon(self):\n",
    "        for i in range(len(self.delta_epsilon)-1):\n",
    "            self.total_epsilon.append(self.total_epsilon[i] + self.delta_epsilon[i])            \n",
    "    \n",
    "    def __calc_e_s(self, sigma_t):\n",
    "        \"\"\" Berechnet `e_s` aus `sigma_t`. \"\"\"\n",
    "        e_s = (1 + self.e_0[0]) / self.C_c[0] * sigma_t\n",
    "        self.e_s.append(e_s)\n",
    "        return e_s\n",
    "\n",
    "    def __calc_sigma_t_p1(self):\n",
    "        \"\"\" Berechnet `sigma_t` und `delta_sigma` für die nächsten Schritte. \"\"\"\n",
    "        for i in range(self.max_n):  # -1, weil sigma_t bereits gesetzt ist\n",
    "            e_s = self.__calc_e_s(self.sigma_t[i])\n",
    "            delta_sigma = e_s * self.delta_epsilon[0]\n",
    "            sigma = self.sigma_t[i] + delta_sigma\n",
    "            self.sigma_t.append(sigma)\n",
    "            self.delta_sigma.append(delta_sigma)\n",
    "\n",
    "if not use_excel:\n",
    "    data_dict = dict(vars(Oedometer(**oedo_parameter)))\n",
    "    display(dict_to_markdown_table(data_dict, 'Ödometerdaten'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb386144-1aae-4b43-aeb1-c3b715d7eac2",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "\n",
    "## Daten normalisieren\n",
    "Die Normalisierung von Daten für neuronale Netze bedeutet, dass Eingabedaten auf eine vergleichbare Skala gebracht werden, um das Training stabiler und effizienter zu machen. Hier verwendete Methode:\n",
    "- Min-Max-Skalierung: Werte auf einen Bereich (0 bis 1) bringen.  <i class=\"fa fa-info\"> [Wiki](https://en.wikipedia.org/wiki/Feature_scaling#Methods)</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd8f39a-6d82-480e-a011-2e432797803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️ Es wurde keine Normalisierung der Werte vorgenommen.\n"
     ]
    }
   ],
   "source": [
    "if normalize_data:\n",
    "    data_dict.update({'sigma_t_raw': data_dict.pop('sigma_t')})\n",
    "    data_dict.update({'e_s_raw': data_dict.pop('e_s')})\n",
    "    \n",
    "    sigma_t_min, sigma_t_max = data_dict['sigma_t_raw'].min(), data_dict['sigma_t_raw'].max()\n",
    "    delta_sigma_min, delta_sigma_max = data_dict['delta_sigma_raw'].min(), data_dict['delta_sigma_raw'].max()\n",
    "    \n",
    "    # Min-Max-Normalisierung\n",
    "    data_dict['sigma_t'] = (data_dict['sigma_t_raw'] - sigma_t_min) / (sigma_t_max - sigma_t_min)\n",
    "    data_dict['e_s'] = (data_dict['e_s_raw'] - delta_sigma_min) / (delta_sigma_max - delta_sigma_min)\n",
    "    print('‼️Tabellenwerte des Oedometerversuches normalisiert.')\n",
    "else:\n",
    "    print('‼️ Es wurde keine Normalisierung der Werte vorgenommen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d182c1ff77877a1",
   "metadata": {},
   "source": [
    "## **Datenvorbereitung für PINA mit LabelTensor**\n",
    "In diesem Code werden die Eingabedaten aus `data_dict` als **LabelTensor** gespeichert, um sie strukturiert und mit benannten Dimensionen für das neuronale Netz in PINA bereitzustellen.  \n",
    "\n",
    "- `sigma_t_train`, `delta_epsilon_train` und `delta_sigma_train` werden als **einzelne beschriftete Tensoren** erstellt.  \n",
    "- `input_points_combined` kombiniert `sigma_t` und `delta_epsilon` in einem **2D-Tensor** für das Training.  \n",
    "- `LabelTensor` erleichtert die Nutzung der Daten in PINA, indem es Variablen klar zuordnet und mit physischen Größen verknüpft.\n",
    "\n",
    "**Mehr zu `LabelTensor`:**  \n",
    "[PINA Documentation – LabelTensor](https://mathlab.github.io/PINA/_rst/label_tensor.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506469cd2477431e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.150519Z",
     "start_time": "2025-03-12T08:30:31.125143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Data Loaded\n",
      " sigma_t und delta_epsilon combined: torch.Size([100, 1])\n",
      " delta_sigma: torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pina.utils import LabelTensor\n",
    "from torch import tensor\n",
    "\n",
    "# Beispiel-Daten\n",
    "# sigma_t_train = LabelTensor(tensor(data_dict['sigma_t'], dtype=torch.float).unsqueeze(-1),['sigma_t'])\n",
    "# delta_epsilon_train = LabelTensor(tensor(data_dict['delta_epsilon'], dtype=torch.float).unsqueeze(-1), ['delta_epsilon'])\n",
    "delta_sigma_train = LabelTensor(tensor(data_dict['e_s'], dtype=torch.float).unsqueeze(-1), ['e_s'])\n",
    "\n",
    "# Kombinieren der Trainingsdaten (Verwendung von 'np.column_stack' für bessere Performance)\n",
    "input_points_combined =LabelTensor(tensor(data_dict['sigma_t'], dtype=torch.float).unsqueeze(-1),['sigma_t'])\n",
    "\n",
    "if debug_mode:\n",
    "    print('‼️Data Loaded')\n",
    "    print(f' sigma_t und delta_epsilon combined: {input_points_combined.size()}')\n",
    "    print(f' delta_sigma: {delta_sigma_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8c6ec-bac1-4d00-83cb-63b178a72be6",
   "metadata": {},
   "source": [
    "### **Definition eines einfachen PINN-Problems in PINA**  \n",
    "Dieser Code definiert ein **Physics-Informed Neural Network (PINN)**-Problem mithilfe der PINA-Bibliothek.  \n",
    " \n",
    "- **Klassenstruktur (`SimpleODE`)**: Erbt von `AbstractProblem` und spezifiziert die Eingabe- und Ausgabevariablen basierend auf `LabelTensor`.\n",
    "    - [PINA-Dokumentation - AbstractProblem](https://mathlab.github.io/PINA/_rst/problem/abstractproblem.html) \n",
    "- **Definitionsbereich (`domain`)**: Der Wertebereich der Eingabevariablen (`sigma_t`, `delta_epsilon`) wird als `CartesianDomain` festgelegt.\n",
    "    - **Hinweis:** `domain` muss immer definiert sein, selbst wenn sie nicht direkt zur Datengenerierung verwendet wird.  \n",
    "    - [PINA-Dokumentation - CartesianDomain](https://mathlab.github.io/PINA/_rst/geometry/cartesian.html) \n",
    "- **Randbedingungen (`conditions`)**: Die echten Messwerte (`in sigma_t, delta_epsilon` `out delta_sigma_train`) werden als Randbedingung (`Condition`) für das Modell definiert.\n",
    "    - [PINA-Dokumentation - Condition](https://mathlab.github.io/PINA/_rst/condition.html) \n",
    "- **\"Wahre Lösung\" (`truth_solution`)**: Falls erforderlich, kann eine analytische Lösung (hier `torch.exp(...)`) zur Validierung genutzt werden.\n",
    "    - **Hinweis:** Funktioniert in unserem Fall nicht, da die Implementierung nicht für reine Input und Outpunkt Punkte implementiert ist.\n",
    "    - [PINA-Tutorial - Physics Informed Neural Networks on PINA](https://mathlab.github.io/PINA/_rst/tutorials/tutorial1/tutorial.html) \n",
    "- **Probleminstanz (`problem = SimpleODE()`)**: Erstellt das Problem, das für das Training eines PINN verwendet wird.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2de5194c7f49fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.712233Z",
     "start_time": "2025-03-12T08:30:31.590633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Geladene Input Variablen:  ['sigma_t']\n",
      "‼️Geladene Output Variablen:  ['e_s']\n",
      "‼️Input points: {'data': LabelTensor([[1.0000e+00],\n",
      "             [1.2000e+00],\n",
      "             [1.4400e+00],\n",
      "             [1.7280e+00],\n",
      "             [2.0736e+00],\n",
      "             [2.4883e+00],\n",
      "             [2.9860e+00],\n",
      "             [3.5832e+00],\n",
      "             [4.2998e+00],\n",
      "             [5.1598e+00],\n",
      "             [6.1917e+00],\n",
      "             [7.4301e+00],\n",
      "             [8.9161e+00],\n",
      "             [1.0699e+01],\n",
      "             [1.2839e+01],\n",
      "             [1.5407e+01],\n",
      "             [1.8488e+01],\n",
      "             [2.2186e+01],\n",
      "             [2.6623e+01],\n",
      "             [3.1948e+01],\n",
      "             [3.8338e+01],\n",
      "             [4.6005e+01],\n",
      "             [5.5206e+01],\n",
      "             [6.6247e+01],\n",
      "             [7.9497e+01],\n",
      "             [9.5396e+01],\n",
      "             [1.1448e+02],\n",
      "             [1.3737e+02],\n",
      "             [1.6484e+02],\n",
      "             [1.9781e+02],\n",
      "             [2.3738e+02],\n",
      "             [2.8485e+02],\n",
      "             [3.4182e+02],\n",
      "             [4.1019e+02],\n",
      "             [4.9222e+02],\n",
      "             [5.9067e+02],\n",
      "             [7.0880e+02],\n",
      "             [8.5056e+02],\n",
      "             [1.0207e+03],\n",
      "             [1.2248e+03],\n",
      "             [1.4698e+03],\n",
      "             [1.7637e+03],\n",
      "             [2.1165e+03],\n",
      "             [2.5398e+03],\n",
      "             [3.0477e+03],\n",
      "             [3.6573e+03],\n",
      "             [4.3887e+03],\n",
      "             [5.2665e+03],\n",
      "             [6.3197e+03],\n",
      "             [7.5837e+03],\n",
      "             [9.1004e+03],\n",
      "             [1.0921e+04],\n",
      "             [1.3105e+04],\n",
      "             [1.5726e+04],\n",
      "             [1.8871e+04],\n",
      "             [2.2645e+04],\n",
      "             [2.7174e+04],\n",
      "             [3.2609e+04],\n",
      "             [3.9130e+04],\n",
      "             [4.6956e+04],\n",
      "             [5.6348e+04],\n",
      "             [6.7617e+04],\n",
      "             [8.1140e+04],\n",
      "             [9.7369e+04],\n",
      "             [1.1684e+05],\n",
      "             [1.4021e+05],\n",
      "             [1.6825e+05],\n",
      "             [2.0190e+05],\n",
      "             [2.4228e+05],\n",
      "             [2.9074e+05],\n",
      "             [3.4889e+05],\n",
      "             [4.1867e+05],\n",
      "             [5.0240e+05],\n",
      "             [6.0288e+05],\n",
      "             [7.2346e+05],\n",
      "             [8.6815e+05],\n",
      "             [1.0418e+06],\n",
      "             [1.2501e+06],\n",
      "             [1.5002e+06],\n",
      "             [1.8002e+06],\n",
      "             [2.1602e+06],\n",
      "             [2.5923e+06],\n",
      "             [3.1107e+06],\n",
      "             [3.7329e+06],\n",
      "             [4.4794e+06],\n",
      "             [5.3753e+06],\n",
      "             [6.4504e+06],\n",
      "             [7.7405e+06],\n",
      "             [9.2886e+06],\n",
      "             [1.1146e+07],\n",
      "             [1.3376e+07],\n",
      "             [1.6051e+07],\n",
      "             [1.9261e+07],\n",
      "             [2.3113e+07],\n",
      "             [2.7736e+07],\n",
      "             [3.3283e+07],\n",
      "             [3.9939e+07],\n",
      "             [4.7927e+07],\n",
      "             [5.7512e+07],\n",
      "             [6.9015e+07]])}\n"
     ]
    }
   ],
   "source": [
    "from pina.problem import AbstractProblem\n",
    "from pina.domain import CartesianDomain\n",
    "from pina import Condition\n",
    "\n",
    "# Datengenerierung, falls Randbedingungen definiert\n",
    "# problem.discretise_domain(n=993, mode='random', variables='all', locations='all') # Notwendig, wenn \"input_pts\" und \"output_pts\" nicht vorgegeben sind\n",
    "if new_test:\n",
    "    # Trainingsdaten e_0:float=1.00, C_c:float=0.005, delta_epsilon:float=0.0005, sigma_t:float=1.00, max_n:int=50\n",
    "    oedo_parameter = {'e_0':1.00, 'C_c':0.005, 'delta_epsilon':0.0005, 'sigma_t':1.00, 'max_n':100, 'rand_epsilon':False}\n",
    "    input_conditions = {}\n",
    "    for i in range(max_input_pts):\n",
    "        oedo_parameter['delta_epsilon'] = oedo_parameter['delta_epsilon'] + .0001\n",
    "        data_dict = vars(Oedometer(**oedo_parameter))\n",
    "\n",
    "        sigma_t_train = LabelTensor(tensor(data_dict['sigma_t'][0], dtype=torch.float).unsqueeze(-1),['sigma_t'])\n",
    "        delta_epsilon_train = LabelTensor(tensor(data_dict['delta_epsilon'][0], dtype=torch.float).unsqueeze(-1), ['delta_epsilon'])\n",
    "        delta_sigma_train = LabelTensor(tensor(data_dict['delta_sigma'][0], dtype=torch.float).unsqueeze(-1), ['delta_sigma'])\n",
    "        # Kombinieren der Trainingsdaten (Verwendung von 'np.column_stack' für bessere Performance)\n",
    "        input_points_combined = LabelTensor(torch.tensor(np.column_stack([data_dict['sigma_t'][0], data_dict['delta_epsilon'][0]]), dtype=torch.float), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "        input_conditions['condition' + str(i)] = Condition(input_points=input_points_combined, output_points=delta_sigma_train)\n",
    "else:\n",
    "    input_conditions = {'data': Condition(input=input_points_combined, target=delta_sigma_train),}\n",
    "\n",
    "class SimpleODE(AbstractProblem):\n",
    "\n",
    "    # Definition der Eingabe- und Ausgabevariablen basierend auf LabelTensor\n",
    "    input_variables = input_points_combined.labels\n",
    "    output_variables = delta_sigma_train.labels\n",
    "\n",
    "    # Wertebereich\n",
    "    domain = CartesianDomain({'e_s': [0, 1]})  # Wertebereich immer definieren!\n",
    "\n",
    "    # Definition der Randbedingungen und (hier: nur) vorberechnetet Punkte\n",
    "    conditions = input_conditions\n",
    "\n",
    "    output_pts=delta_sigma_train\n",
    "\n",
    "    # Methode zur Definition der \"wahren Lösung\" des Problems\n",
    "    def truth_solution(self, pts):\n",
    "        return torch.exp(pts.extract(['e_s']))\n",
    "\n",
    "# Problem-Instanz erzeugen\n",
    "problem = SimpleODE()\n",
    "\n",
    "\n",
    "\n",
    "if debug_mode:\n",
    "    # Debugging-Ausgaben\n",
    "    print(\"‼️Geladene Input Variablen: \", problem.input_variables)\n",
    "    print(\"‼️Geladene Output Variablen: \", problem.output_variables)\n",
    "    print('‼️Input points:', problem.input_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017454f5732f1b5",
   "metadata": {},
   "source": [
    "## Visualisierung Sampling\n",
    "Darstellung Input: `sigma_t` und `delta_epsilon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8177115081d371bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:33.410973Z",
     "start_time": "2025-03-12T08:30:32.818773Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Plotter' from 'pina' (C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpina\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Plotter\n\u001b[32m      2\u001b[39m pl = Plotter()\n\u001b[32m      3\u001b[39m pl.plot_samples(problem=problem, filename=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_visual_sampling\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mimg_extensions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, variables=[\u001b[33m'\u001b[39m\u001b[33mdelta_epsilon\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33msigma_t\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Plotter' from 'pina' (C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pina import Plotter\n",
    "pl = Plotter()\n",
    "pl.plot_samples(problem=problem, filename=f'./{graph_folder}/{img_visual_sampling}{img_extensions}', variables=['delta_epsilon','sigma_t'])\n",
    "display(Markdown('![Result of sampling](' + f'./{graph_folder}/{img_visual_sampling}{img_extensions}' + ')'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b78c6b-22bf-4a9a-8d00-be05b47deb71",
   "metadata": {},
   "source": [
    "# Training eines Physics-Informed Neural Networks (PINN) mit PINA\n",
    "\n",
    "Dieser Code definiert und trainiert ein **Physics-Informed Neural Network (PINN)** zur Lösung des Problems in PINA.\n",
    "\n",
    "- **Modell (`FeedForward`)**: Ein neuronales Netz mit drei versteckten Schichten (`[50, 50, 50]`), das mit der ReLU-Aktivierungsfunktion arbeitet.\n",
    "- **PINN-Objekt (`PINN`)**: Erstellt das PINN-Modell, das die physikalischen Randbedingungen des Problems berücksichtigt.\n",
    "- **TensorBoard-Logger (`TensorBoardLogger`)**: Speichert Trainingsmetriken zur Visualisierung.\n",
    "- **Trainer (`Trainer`)**: Führt das Training für 1500 Epochen mit Batch-Größe 10 durch.\n",
    "- **Training starten (`trainer.train()`)**: Startet den Optimierungsprozess und protokolliert die Metriken.\n",
    "\n",
    "Am Ende wird die **finale Loss-Funktion** ausgegeben, um die Trainingsqualität zu bewerten.\n",
    "\n",
    "**Mehr zu `Trainer`:**  \n",
    "[PINA-Dokumentation – Trainer](https://mathlab.github.io/PINA/_rst/trainer.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb7ce50b0b515f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-12T08:30:34.000486Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Info:\n",
      "‼️Länge der Eingabepunkte (input_pts): 1\n",
      "‼️Länge der Ausgabepunkte (output_pts): 100\n",
      "Epoch 5249:  20%|▏| 2/10 [00:00<00:00, 28.70it/s, v_num=5, data_loss_step=6.97e+4, train_loss_step=6.97e+4, data_loss_e"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pina import Trainer\n",
    "from pina.solvers import PINN\n",
    "from pina.model import FeedForward\n",
    "from pina.callbacks import MetricTracker\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Import TensorBoard Logger\n",
    "\n",
    "if debug_mode:\n",
    "    print('Debugging Info:')\n",
    "    # Überprüfen der Größe der Eingabepunkte und Ausgabepunkte\n",
    "    print(\"‼️Länge der Eingabepunkte (input_pts):\", len(problem.input_pts))\n",
    "    print(\"‼️Länge der Ausgabepunkte (output_pts):\", len(problem.output_pts))\n",
    "\n",
    "# Model erstellen\n",
    "model = FeedForward(\n",
    "    layers=[50, 50, 50],\n",
    "    func=torch.nn.ReLU,\n",
    "    output_dimensions=len(problem.output_variables),\n",
    "    input_dimensions=len(problem.input_variables)\n",
    ")\n",
    "\n",
    "# PINN-Objekt erstellen\n",
    "pinn = PINN(problem, model)\n",
    "\n",
    "# TensorBoard-Logger\n",
    "logger = TensorBoardLogger(\"tensorboard_logs\", name=\"pina_experiment\")\n",
    "\n",
    "# Trainer erstellen mit TensorBoard-Logger\n",
    "trainer = Trainer(\n",
    "    solver=pinn,\n",
    "    max_epochs=10000,\n",
    "    callbacks=[MetricTracker()],\n",
    "    batch_size=10,\n",
    "    accelerator='cpu',\n",
    "    logger=logger,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Training starten\n",
    "trainer.train()\n",
    "\n",
    "print('\\nFinale Loss Werte')\n",
    "# Inspect final loss\n",
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a21a7-66f3-4684-b49f-e1d1aeaaa974",
   "metadata": {},
   "source": [
    "## **Visualisierung der Modellvorhersage für delta_sigma**\n",
    "\n",
    "Dieser Code erstellt einen **Plot der wahren Werte (`delta_sigma`)** im Vergleich zur **Vorhersage des neuronalen Netzwerks**.\n",
    "\n",
    "- **Datenvorbereitung (`input_data`)**: Die Eingabedaten (`sigma_t` und `delta_epsilon`) werden als `LabelTensor` für das trainierte Modell erstellt.\n",
    "- **Modellvorhersage (`pinn(input_data)`)**: Das trainierte PINN-Modell gibt eine Prognose für `delta_sigma` aus.\n",
    "- **Plot-Erstellung mit `matplotlib`**:  \n",
    "  - Die wahre Lösung (`delta_sigma`) wird als **blaue gestrichelte Linie** dargestellt.  \n",
    "  - Die Vorhersage des neuronalen Netzwerks wird als **rote durchgezogene Linie** geplottet.  \n",
    "\n",
    "**Zusätzlicher Schritt:**  \n",
    "Die Nutzung von `matplotlib` war notwendig, da die interne Plot-Funktion von PINA `pl.plot()` das Diagramm nicht wie in den Tutorials erwartungsgemäß generierte, selbst wenn `delta_epsilon` auf einen fixen Wert gesetzt wurde. Dies könnte auf eine fehlerhafte Nutzung der Funktion oder auf eine Inkompatibilität in der Darstellung zurückzuführen sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de070fe2-16f3-40f1-8602-36aebfb3818a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_data_loss_table(data_dict=data_dict, delta_sigma_pred=pinn(input_points_combined).detach().numpy(), max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=data_dict, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution, \n",
    "                                     img_extensions=img_extensions, y_axis='total_epsilon', max_i=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51709f02-c3c7-4076-b873-41e9d45d0c97",
   "metadata": {},
   "source": [
    "## Visualisierung Error-Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367434e3c1076341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:26:45.282465Z",
     "start_time": "2025-03-12T08:26:44.026059Z"
    }
   },
   "outputs": [],
   "source": [
    "pl.plot(solver=pinn, filename=f'./{graph_folder}/{img_nn_result_error}{img_extensions}')\n",
    "display(Markdown('![NN Error result](' + f'./{graph_folder}/{img_nn_result_error}{img_extensions}' + ')'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875cc14cf077767",
   "metadata": {},
   "source": [
    "## Visualisierung Loss-Kurve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc792fe16f92e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:21:28.768753Z",
     "start_time": "2025-03-12T08:21:26.295329Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the solution\n",
    "pl.plot_loss(trainer, label='mean_loss', logy=True, filename=f'./{graph_folder}/{img_visual_loss}{img_extensions}')\n",
    "display(Markdown('![Loss Kurve](' + f'./{graph_folder}/{img_visual_loss}{img_extensions}' + ')'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979e1d6-7feb-442b-b59f-afe2593f58d6",
   "metadata": {},
   "source": [
    "# Testdaten (1 Input-Wert) $\\Delta\\epsilon=0,0005$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d6d6b-82bc-4e94-aad6-44206ddebbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = extract_excel(file_path=\"files/oedometer/oedo_trainingsdata_compare.xlsx\", sheet_name=\"Res\", selected_columns=[1, 2, 3, 5], row_start_range=0)\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_t'], new_data['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "display_data_loss_table(data_dict=new_data, delta_sigma_pred=pinn(input_data).detach().numpy(), max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution_comp0, \n",
    "                                     img_extensions=img_extensions, y_axis='total_epsilon', max_i=20, plot_type=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bff797-ce23-479e-bfa6-ee6607f42cf0",
   "metadata": {},
   "source": [
    "# Testwerte (2 Input-Wert) $\\Delta\\epsilon=0,0005$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb148e33-5cce-4311-91f3-f4e11197f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = extract_excel(file_path=\"files/oedometer/oedo_trainingsdata_compare2.xlsx\", sheet_name=\"Res\", selected_columns=[1, 2, 3, 5], row_start_range=0)\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_t'], new_data['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "display_data_loss_table(data_dict=new_data, delta_sigma_pred=pinn(input_data).detach().numpy(), max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution_comp1, \n",
    "                                     img_extensions=img_extensions, y_axis='total_epsilon', max_i=20, plot_type=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d66b7b-df39-4ffb-996e-42197cccae2c",
   "metadata": {},
   "source": [
    "# Testwerte (2 Input-Wert) $\\Delta\\epsilon=0,001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d968d0-ed7a-4ea2-b613-23935a7b789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = extract_excel(file_path=\"files/oedometer/oedo_trainingsdata_compare3.xlsx\", sheet_name=\"Res\", selected_columns=[1, 2, 3, 5], row_start_range=0)\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_t'], new_data['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "display_data_loss_table(data_dict=new_data, delta_sigma_pred=pinn(input_data).detach().numpy(), max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution_comp2, \n",
    "                                     img_extensions=img_extensions, y_axis='total_epsilon', max_i=20, plot_type=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409ad12-42d8-40a2-bff3-bdb2b5dd40d7",
   "metadata": {},
   "source": [
    "Gemäß statischem Trainingswert für $\\Delta\\epsilon$ wurde keine korrekte Prognose vorgenommen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
