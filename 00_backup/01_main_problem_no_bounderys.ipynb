{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202376a2a307e3c2",
   "metadata": {},
   "source": [
    "# Vorhersage des Ödometerversuches implementiert mit PINA\n",
    "Ziel war die Implementierung eines neuronalen Netzwerks zur Modellierung des Ödometerversuchs. Dabei wurden gegebene Input-Parameter verarbeitet, um Output-Parameter vorherzusagen. Die physikalischen Rahmenbedingungen wurden zunächst auf Null gesetzt, sodass das Modell ausschließlich auf der KI-basierten Struktur arbeitet, ohne physikalische Optimierungen durch Physical Informed Neural Networks (PINNs).\n",
    "<br>\n",
    "Diese grundlegende Umsetzung bildet die Basis für weiterführende Optimierungen, wie die Integration physikalischer Gesetzmäßigkeiten, die jedoch nicht Teil des initialen Arbeitsauftrags waren.\n",
    "\n",
    "### Was ist PINA?\n",
    "PINA ist eine Open-Source-Python-Bibliothek, die eine intuitive Schnittstelle zur Lösung von Differentialgleichungen bietet, indem sie Physik-informierte Neuronale Netze (PINNs), Neuronale Operatoren (NOs) oder eine Kombination aus beiden verwendet. Basierend auf PyTorch und PyTorch Lightning ermöglicht PINA die formale Darstellung spezifischer (differentieller) Probleme und deren Lösung mittels neuronaler Netze.<br><br>\n",
    "<strong>Hauptmerkmale von PINA:</strong>\n",
    "\n",
    "- <span style=\"color:gray;\"><i>Problemformulierung: Ermöglicht die Übersetzung mathematischer Gleichungen in Python-Code, um das Differentialproblem zu definieren.</i></span>\n",
    "    - <small><i>→ In diesem Arbeitsauftrag nicht notwendig, da das neuronale Netzwerk ohne physikalische Gesetzmäßigkeiten trainiert wurde.</i></small>\n",
    "- Modelltraining: Bietet Werkzeuge zum Training neuronaler Netze zur Lösung des definierten Problems.\n",
    "- Lösungsauswertung: Erlaubt die Visualisierung und Analyse der approximierten Lösungen.\n",
    "\n",
    "<small><i>Hinweis: Die physikalische Modellierung und die Einbindung von Differentialgleichungen zur Optimierung des Netzwerks (z. B. mittels PINNs) war nicht Teil dieses Arbeitsauftrags, könnte aber in einem späteren Schritt ergänzt werden.</i></small>\n",
    "## Grundlagen\n",
    "In diesem Notebook wird der Ödometerversuch <strong>ohne</strong> Randbedingungen betrachtet. Es werden vorberechnetet Daten aus der Exceltabelle `files/oedometer/oedo_trainingsdata.xlsx` verwendet.<br>\n",
    "#### Das Problem ist wie folgt definiert:\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "    \\sigma_{t+1} & = & \\sigma_{t}+\\Delta\\sigma \\\\ \\\\\n",
    "    \\Delta\\sigma & = & E_s\\cdot \\Delta\\epsilon \\\\ \n",
    "    E_s & = & \\frac{1+e_0}{C_c} \\cdot \\sigma_t\n",
    "\\end{array}\n",
    "\\hspace{2cm}\n",
    "\\begin{array}{l}\n",
    "    \\textbf{Annahmen:} \\\\ \\\\\n",
    "    \\text{Startwert d. Iteration: } \\sigma_t = 1,00 \\\\ \n",
    "    e_0 = 1,00 \\\\ \n",
    "    C_c = 0,005 \\\\\n",
    "    \\Delta\\epsilon = 0,0005\n",
    "\\end{array}\n",
    "$$\n",
    "<div = style=\"text-align: center;\">\n",
    "    <img alt=\"Problem Oedometer Preview\" src=\"./graph/problem_preview.png\" width=\"50%\" height=auto>\n",
    "</div>\n",
    "\n",
    "<br> \n",
    "\n",
    "Um das PINA-Model zu testen werden wir folgende vorberechnete Werte verwenden: `Input` { $\\sigma_t$ ; $\\Delta\\epsilon$ }, `Output` { $\\sigma_{t+1}$ }.\n",
    "<br>\n",
    "### Variablendeklaration\n",
    "- $\\sigma_t$ = `sigma_t`\n",
    "- $\\Delta\\epsilon$ = `delta_epsilon`\n",
    "- $\\sigma_{t+1}$ = `delta_sigma`\n",
    "## Einstellungen und Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ab565a-fc02-41df-89e3-9888204d845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import matplotlib  # Keine doppelte Darstellung des Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Debugger: Aktiviert\n",
    "debug_mode = True\n",
    "# Normalisierung der Daten: Deaktiviert\n",
    "normalize_data = False\n",
    "use_excel = False\n",
    "\n",
    "input_data = 'sigma_t'\n",
    "output_data = 'e_s'\n",
    "\n",
    "# Trainingsdaten e_0:float=1.00, C_c:float=0.005, delta_epsilon:float=0.0005, sigma_t:float=1.00, max_n:int=50\n",
    "oedo_parameter = {'e_0':1.00, 'C_c':0.005, 'delta_epsilon':0.0005, 'sigma_t':1.00, 'max_n':100, 'rand_epsilon':False}\n",
    "\n",
    "graph_folder = 'graph'\n",
    "img_extensions = '.png'\n",
    "\n",
    "img_visual_loss = 'visual_loss'\n",
    "img_nn_result_error = 'img_nn_result_error'\n",
    "img_visual_prediction_vs_truesolution_comp = 'visual_prediction-vs-truesolution_comp'\n",
    "img_visual_prediction_vs_truesolution_comp0 = 'visual_prediction-vs-truesolution_comp0'\n",
    "img_visual_prediction_vs_truesolution_comp1 = 'visual_prediction-vs-truesolution_comp1'\n",
    "img_visual_prediction_vs_truesolution_comp2 = 'visual_prediction-vs-truesolution_comp2'\n",
    "img_visual_prediction_vs_truesolution = 'visual_prediction-vs-truesolution'\n",
    "img_visual_sampling = 'visual_sampling'\n",
    "\n",
    "def dict_to_markdown_table(data: dict, title: str = \"Datenübersicht\", include_index: bool = True, round_digits: int = 4):\n",
    "    \"\"\"\n",
    "    Wandelt ein Dictionary mit Listenwerten in eine Markdown-Tabelle für Jupyter Notebooks um.\n",
    "    \n",
    "    - Schlüssel werden als Header genutzt\n",
    "    - Erste Spalte ist ein Index, falls `include_index=True`\n",
    "    - Einzelwerte werden als separate Tabelle unterhalb dargestellt\n",
    "    - Zahlenwerte werden auf eine einstellbare Anzahl an Nachkommastellen gerundet\n",
    "\n",
    "    :param data: Dictionary mit Key-Value-Paaren\n",
    "    :param title: Überschrift für die Tabelle\n",
    "    :param include_index: Falls True, wird eine Index-Spalte erstellt\n",
    "    :param round_digits: Anzahl der Nachkommastellen, auf die Werte gerundet werden sollen\n",
    "    :return: Markdown-String zur Anzeige in Jupyter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hilfsfunktion zum Runden von Zahlen\n",
    "    def round_value(val):\n",
    "        if isinstance(val, (int, float)):\n",
    "            return round(val, round_digits)\n",
    "        return val\n",
    "\n",
    "    # Listen und einzelne Werte trennen\n",
    "    list_data = {k: v for k, v in data.items() if isinstance(v, list)}\n",
    "    single_values = {k: v for k, v in data.items() if not isinstance(v, list)}\n",
    "\n",
    "    # Falls es Listen gibt, erstelle eine Tabelle mit Index\n",
    "    if list_data:\n",
    "        max_len = max(len(v) for v in list_data.values())  # Längste Liste bestimmen\n",
    "\n",
    "        # Tabellenkopf\n",
    "        md_table = f\"### {title}\\n\\n\"\n",
    "        md_table += \"| \" + (\"Index | \" if include_index else \"\") + \" | \".join(list_data.keys()) + \" |\\n\"\n",
    "        md_table += \"|-\" + (\"-|\" if include_index else \"\") + \"-|\".join([\"-\" * len(k) for k in list_data.keys()]) + \"-|\\n\"\n",
    "\n",
    "        # Datenzeilen\n",
    "        for i in range(max_len):\n",
    "            row = [str(i)] if include_index else []  # Index hinzufügen (optional)\n",
    "            for key in list_data:\n",
    "                if i < len(list_data[key]):\n",
    "                    row.append(str(round_value(list_data[key][i])))\n",
    "                else:\n",
    "                    row.append(\"\")  # Leere Werte für ungleich lange Listen\n",
    "            md_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "    \n",
    "    else:\n",
    "        md_table = \"\"\n",
    "\n",
    "    # Einzelwerte als extra Tabelle darstellen\n",
    "    if single_values:\n",
    "        md_table += \"\\n\\n#### Einzelwerte\\n\\n\"\n",
    "        md_table += \"| \" + \" | \".join(single_values.keys()) + \" |\\n\"\n",
    "        md_table += \"|-\" + \"-|\".join([\"-\" * len(k) for k in single_values.keys()]) + \"-|\\n\"\n",
    "        md_table += \"| \" + \" | \".join(map(lambda v: str(round_value(v)), single_values.values())) + \" |\\n\"\n",
    "\n",
    "    return Markdown(md_table)\n",
    "\n",
    "\n",
    "def display_data_loss_table(data_dict, delta_sigma_pred, max_i):\n",
    "    \"\"\"\n",
    "    Erstellt eine Markdown-Tabelle zur übersichtlichen Darstellung von Datenverlust.\n",
    "    \n",
    "    Unterstützt sowohl Python-Listen als auch NumPy-Arrays.\n",
    "    \n",
    "    :param data_dict: Dictionary mit `sigma_t` und `delta_sigma` (Listen oder np.arrays)\n",
    "    :param delta_sigma_pred: Vorhergesagte Werte für `delta_sigma` (Liste oder np.array)\n",
    "    :param max_i: Anzahl der Werte, die in der Tabelle angezeigt werden sollen\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sicherstellen, dass `sigma_t` und `delta_sigma` existieren\n",
    "    if \"sigma_t\" not in data_dict or \"delta_sigma\" not in data_dict or delta_sigma_pred is None:\n",
    "        print(\"Fehler: `data_dict` oder `delta_sigma_pred` ist nicht korrekt definiert!\")\n",
    "        return\n",
    "\n",
    "    # Konvertiere alle Werte zu Listen (falls sie NumPy-Arrays sind)\n",
    "    def to_list(arr):\n",
    "        return arr.tolist() if isinstance(arr, np.ndarray) else arr\n",
    "\n",
    "    total_epsilon = to_list(data_dict[\"total_epsilon\"])\n",
    "    delta_epsilon = to_list(data_dict[\"delta_epsilon\"])\n",
    "    sigma_t = to_list(data_dict[\"sigma_t\"])\n",
    "    delta_sigma_true = to_list(data_dict[\"delta_sigma\"])\n",
    "    delta_sigma_pred = to_list(delta_sigma_pred.flatten())  # Falls `delta_sigma_pred` ein 2D-Array ist\n",
    "    \n",
    "    # Überprüfen, ob die Längen konsistent sind\n",
    "    min_len = min(len(total_epsilon), len(sigma_t), len(delta_epsilon), len(delta_sigma_true), len(delta_sigma_pred), max_i)\n",
    "\n",
    "    # Erstelle eine Tabelle für die übersichtliche Darstellung\n",
    "    data_loss_table = {\n",
    "        \"total_epsilon\" : list(total_epsilon[:min_len]), \n",
    "        \"delta_epsilon\" : list(delta_epsilon[:min_len]), \n",
    "        \"sigma_t\" : list(sigma_t[:min_len]), \n",
    "        \"True delta_sigma\": list(delta_sigma_true[:min_len]),\n",
    "        \"Predicted delta_sigma\": list(delta_sigma_pred[:min_len]),\n",
    "        \"Test-Loss (True - Predicted)\": list(np.round(np.array(delta_sigma_true[:min_len]) - np.array(delta_sigma_pred[:min_len]), 5))\n",
    "    }\n",
    "    \n",
    "    # Markdown-Tabelle für bessere Darstellung in Jupyter\n",
    "    display(dict_to_markdown_table(data_loss_table, title=f\"Data-Loss bis sigma_{min_len-1}\", include_index=True))\n",
    "\n",
    "def plot_prediction_vs_true_solution(pinn, data_dict, graph_folder, img_visual_prediction_vs_truesolution, \n",
    "                                     img_extensions, y_axis='delta_sigma', max_i=20, plot_type=\"line\"):\n",
    "    \"\"\"\n",
    "    Erstellt und speichert eine Vorhersage- vs. True-Solution-Grafik für ein gegebenes PINN-Modell.\n",
    "\n",
    "    :param pinn: Das trainierte PINN-Modell zur Vorhersage von delta_sigma\n",
    "    :param data_dict: Dictionary mit den Eingabe- und wahren Ausgabe-Daten\n",
    "    :param graph_folder: Ordner, in dem das Bild gespeichert wird\n",
    "    :param img_visual_prediction_vs_truesolution: Dateiname der gespeicherten Grafik (ohne Erweiterung)\n",
    "    :param img_extensions: Dateiformat der gespeicherten Grafik (z.B. '.png' oder '.jpg')\n",
    "    :param max_i: Anzahl der Datenpunkte, die im Plot gezeigt werden sollen (Default: 20)\n",
    "    :param delta_epsilon: Wert für delta_epsilon, um ihn im Titel anzuzeigen (optional)\n",
    "    :param plot_type: Art der Darstellung - \"line\" für Linienplot, \"scatter\" für Punktplot (Default: \"line\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Überprüfen, ob die notwendigen Keys vorhanden sind\n",
    "    if \"sigma_t\" not in data_dict or y_axis not in data_dict:\n",
    "        print(f\"Fehler: sigma_t oder y_axis fehlen im data_dict!\")\n",
    "        return\n",
    "\n",
    "    # Eingabedaten für das Modell vorbereiten\n",
    "    input_data = LabelTensor(torch.tensor(\n",
    "        np.column_stack((data_dict['sigma_t'], data_dict['delta_epsilon'])), \n",
    "        dtype=torch.float), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "    # Vorhersage berechnen\n",
    "    sigma_t_pred = pinn(input_data).detach().numpy()\n",
    "    \n",
    "    # Plot erstellen\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    y_vals = data_dict[y_axis][0:max_i]\n",
    "    x_true = data_dict['delta_sigma'][0:max_i]\n",
    "    x_pred = sigma_t_pred[0:max_i]\n",
    "\n",
    "    if plot_type == \"line\":\n",
    "        plt.plot(x_true, y_vals, label=\"True Solution (delta_sigma)\", linestyle='dashed', color='blue')\n",
    "        plt.plot(x_pred, y_vals, label=\"NN Prediction (delta_sigma)\", linestyle='solid', color='red')\n",
    "    elif plot_type == \"scatter\":\n",
    "        plt.scatter(x_true, y_vals, label=\"True Solution (delta_sigma)\", color='blue', marker='o')\n",
    "        plt.scatter(x_pred, y_vals, label=\"NN Prediction (delta_sigma)\", color='red', marker='x')\n",
    "\n",
    "    plt.xlabel(\"delta_sigma\")\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(f\"Prediction vs. True Solution (max_i={max_i-1})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Bild speichern\n",
    "    img_path = f'./{graph_folder}/{img_visual_prediction_vs_truesolution}{img_extensions}'\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()  # Verhindert doppelte Darstellung\n",
    "\n",
    "    # Markdown-Ausgabe in Jupyter Notebook\n",
    "    display(Markdown(f'![Prediction vs True Solution]({img_path})<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccebd6-ea34-4979-a87a-59aec6f551e9",
   "metadata": {},
   "source": [
    "## Laden der Daten aus `oedo_trainingsdata.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649daf452361b99a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.087047Z",
     "start_time": "2025-03-12T08:30:30.555114Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy.integrals.heurisch import components\n",
    "\n",
    "def extract_excel(file_path, sheet_name, selected_columns, row_start_range):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Dynamische Ermittlung der letzten Zeile mit Daten\n",
    "    row_start_range = 0  # Startet bei Zeile 6 (0-basiert)\n",
    "    row_end_range = df.dropna(how=\"all\").last_valid_index() + 1  # Letzte Zeile mit Daten\n",
    "        \n",
    "    # Daten extrahieren\n",
    "    data_subset = df.iloc[row_start_range:row_end_range, selected_columns]\n",
    "    data_dict = {col: np.array(data_subset[col]) for col in data_subset.columns}\n",
    "    \n",
    "    if debug_mode:\n",
    "        print(data_dict)\n",
    "        dict_to_markdown_table(data=data_dict,title=file_path)\n",
    "    \n",
    "    # Daten als dict speichern\n",
    "    return data_dict\n",
    "    \n",
    "if use_excel:\n",
    "    data_dict = extract_excel(file_path, sheet_name, selected_columns, row_start_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191696f7-1790-4523-b91e-f12aec2a87ce",
   "metadata": {},
   "source": [
    "## Laden der Daten aus `Python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fe8225-b11a-4954-9367-b1312eba8d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Ödometerdaten\n",
       "\n",
       "| Index | e_0 | C_c | sigma_t | delta_epsilon | total_epsilon | delta_sigma | e_s |\n",
       "|--|----|----|--------|--------------|--------------|------------|----|\n",
       "| 0 | 1.0 | 0.005 | 1.0 | 0.0005 | 0 | 0.2 | 400.0 |\n",
       "| 1 | 1.0 | 0.005 | 1.2 | 0.0005 | 0.0005 | 0.24 | 480.0 |\n",
       "| 2 | 1.0 | 0.005 | 1.44 | 0.0005 | 0.001 | 0.288 | 576.0 |\n",
       "| 3 | 1.0 | 0.005 | 1.728 | 0.0005 | 0.0015 | 0.3456 | 691.2 |\n",
       "| 4 | 1.0 | 0.005 | 2.0736 | 0.0005 | 0.002 | 0.4147 | 829.44 |\n",
       "| 5 | 1.0 | 0.005 | 2.4883 | 0.0005 | 0.0025 | 0.4977 | 995.328 |\n",
       "| 6 | 1.0 | 0.005 | 2.986 | 0.0005 | 0.003 | 0.5972 | 1194.3936 |\n",
       "| 7 | 1.0 | 0.005 | 3.5832 | 0.0005 | 0.0035 | 0.7166 | 1433.2723 |\n",
       "| 8 | 1.0 | 0.005 | 4.2998 | 0.0005 | 0.004 | 0.86 | 1719.9268 |\n",
       "| 9 | 1.0 | 0.005 | 5.1598 | 0.0005 | 0.0045 | 1.032 | 2063.9121 |\n",
       "| 10 | 1.0 | 0.005 | 6.1917 | 0.0005 | 0.005 | 1.2383 | 2476.6946 |\n",
       "| 11 | 1.0 | 0.005 | 7.4301 | 0.0005 | 0.0055 | 1.486 | 2972.0335 |\n",
       "| 12 | 1.0 | 0.005 | 8.9161 | 0.0005 | 0.006 | 1.7832 | 3566.4402 |\n",
       "| 13 | 1.0 | 0.005 | 10.6993 | 0.0005 | 0.0065 | 2.1399 | 4279.7282 |\n",
       "| 14 | 1.0 | 0.005 | 12.8392 | 0.0005 | 0.007 | 2.5678 | 5135.6739 |\n",
       "| 15 | 1.0 | 0.005 | 15.407 | 0.0005 | 0.0075 | 3.0814 | 6162.8086 |\n",
       "| 16 | 1.0 | 0.005 | 18.4884 | 0.0005 | 0.008 | 3.6977 | 7395.3704 |\n",
       "| 17 | 1.0 | 0.005 | 22.1861 | 0.0005 | 0.0085 | 4.4372 | 8874.4444 |\n",
       "| 18 | 1.0 | 0.005 | 26.6233 | 0.0005 | 0.009 | 5.3247 | 10649.3333 |\n",
       "| 19 | 1.0 | 0.005 | 31.948 | 0.0005 | 0.0095 | 6.3896 | 12779.2 |\n",
       "| 20 | 1.0 | 0.005 | 38.3376 | 0.0005 | 0.01 | 7.6675 | 15335.04 |\n",
       "| 21 | 1.0 | 0.005 | 46.0051 | 0.0005 | 0.0105 | 9.201 | 18402.048 |\n",
       "| 22 | 1.0 | 0.005 | 55.2061 | 0.0005 | 0.011 | 11.0412 | 22082.4576 |\n",
       "| 23 | 1.0 | 0.005 | 66.2474 | 0.0005 | 0.0115 | 13.2495 | 26498.9491 |\n",
       "| 24 | 1.0 | 0.005 | 79.4968 | 0.0005 | 0.012 | 15.8994 | 31798.7389 |\n",
       "| 25 | 1.0 | 0.005 | 95.3962 | 0.0005 | 0.0125 | 19.0792 | 38158.4867 |\n",
       "| 26 | 1.0 | 0.005 | 114.4755 | 0.0005 | 0.013 | 22.8951 | 45790.184 |\n",
       "| 27 | 1.0 | 0.005 | 137.3706 | 0.0005 | 0.0135 | 27.4741 | 54948.2208 |\n",
       "| 28 | 1.0 | 0.005 | 164.8447 | 0.0005 | 0.014 | 32.9689 | 65937.8649 |\n",
       "| 29 | 1.0 | 0.005 | 197.8136 | 0.0005 | 0.0145 | 39.5627 | 79125.4379 |\n",
       "| 30 | 1.0 | 0.005 | 237.3763 | 0.0005 | 0.015 | 47.4753 | 94950.5255 |\n",
       "| 31 | 1.0 | 0.005 | 284.8516 | 0.0005 | 0.0155 | 56.9703 | 113940.6306 |\n",
       "| 32 | 1.0 | 0.005 | 341.8219 | 0.0005 | 0.016 | 68.3644 | 136728.7567 |\n",
       "| 33 | 1.0 | 0.005 | 410.1863 | 0.0005 | 0.0165 | 82.0373 | 164074.5081 |\n",
       "| 34 | 1.0 | 0.005 | 492.2235 | 0.0005 | 0.017 | 98.4447 | 196889.4097 |\n",
       "| 35 | 1.0 | 0.005 | 590.6682 | 0.0005 | 0.0175 | 118.1336 | 236267.2917 |\n",
       "| 36 | 1.0 | 0.005 | 708.8019 | 0.0005 | 0.018 | 141.7604 | 283520.75 |\n",
       "| 37 | 1.0 | 0.005 | 850.5622 | 0.0005 | 0.0185 | 170.1124 | 340224.9 |\n",
       "| 38 | 1.0 | 0.005 | 1020.6747 | 0.0005 | 0.019 | 204.1349 | 408269.88 |\n",
       "| 39 | 1.0 | 0.005 | 1224.8096 | 0.0005 | 0.0195 | 244.9619 | 489923.856 |\n",
       "| 40 | 1.0 | 0.005 | 1469.7716 | 0.0005 | 0.02 | 293.9543 | 587908.6272 |\n",
       "| 41 | 1.0 | 0.005 | 1763.7259 | 0.0005 | 0.0205 | 352.7452 | 705490.3526 |\n",
       "| 42 | 1.0 | 0.005 | 2116.4711 | 0.0005 | 0.021 | 423.2942 | 846588.4232 |\n",
       "| 43 | 1.0 | 0.005 | 2539.7653 | 0.0005 | 0.0215 | 507.9531 | 1015906.1078 |\n",
       "| 44 | 1.0 | 0.005 | 3047.7183 | 0.0005 | 0.022 | 609.5437 | 1219087.3293 |\n",
       "| 45 | 1.0 | 0.005 | 3657.262 | 0.0005 | 0.0225 | 731.4524 | 1462904.7952 |\n",
       "| 46 | 1.0 | 0.005 | 4388.7144 | 0.0005 | 0.023 | 877.7429 | 1755485.7542 |\n",
       "| 47 | 1.0 | 0.005 | 5266.4573 | 0.0005 | 0.0235 | 1053.2915 | 2106582.9051 |\n",
       "| 48 | 1.0 | 0.005 | 6319.7487 | 0.0005 | 0.024 | 1263.9497 | 2527899.4861 |\n",
       "| 49 | 1.0 | 0.005 | 7583.6985 | 0.0005 | 0.0245 | 1516.7397 | 3033479.3833 |\n",
       "| 50 | 1.0 | 0.005 | 9100.4382 | 0.0005 | 0.025 | 1820.0876 | 3640175.26 |\n",
       "| 51 | 1.0 | 0.005 | 10920.5258 | 0.0005 | 0.0255 | 2184.1052 | 4368210.312 |\n",
       "| 52 | 1.0 | 0.005 | 13104.6309 | 0.0005 | 0.026 | 2620.9262 | 5241852.3744 |\n",
       "| 53 | 1.0 | 0.005 | 15725.5571 | 0.0005 | 0.0265 | 3145.1114 | 6290222.8493 |\n",
       "| 54 | 1.0 | 0.005 | 18870.6685 | 0.0005 | 0.027 | 3774.1337 | 7548267.4191 |\n",
       "| 55 | 1.0 | 0.005 | 22644.8023 | 0.0005 | 0.0275 | 4528.9605 | 9057920.903 |\n",
       "| 56 | 1.0 | 0.005 | 27173.7627 | 0.0005 | 0.028 | 5434.7525 | 10869505.0836 |\n",
       "| 57 | 1.0 | 0.005 | 32608.5153 | 0.0005 | 0.0285 | 6521.7031 | 13043406.1003 |\n",
       "| 58 | 1.0 | 0.005 | 39130.2183 | 0.0005 | 0.029 | 7826.0437 | 15652087.3203 |\n",
       "| 59 | 1.0 | 0.005 | 46956.262 | 0.0005 | 0.0295 | 9391.2524 | 18782504.7844 |\n",
       "| 60 | 1.0 | 0.005 | 56347.5144 | 0.0005 | 0.03 | 11269.5029 | 22539005.7413 |\n",
       "| 61 | 1.0 | 0.005 | 67617.0172 | 0.0005 | 0.0305 | 13523.4034 | 27046806.8895 |\n",
       "| 62 | 1.0 | 0.005 | 81140.4207 | 0.0005 | 0.031 | 16228.0841 | 32456168.2674 |\n",
       "| 63 | 1.0 | 0.005 | 97368.5048 | 0.0005 | 0.0315 | 19473.701 | 38947401.9209 |\n",
       "| 64 | 1.0 | 0.005 | 116842.2058 | 0.0005 | 0.032 | 23368.4412 | 46736882.3051 |\n",
       "| 65 | 1.0 | 0.005 | 140210.6469 | 0.0005 | 0.0325 | 28042.1294 | 56084258.7661 |\n",
       "| 66 | 1.0 | 0.005 | 168252.7763 | 0.0005 | 0.033 | 33650.5553 | 67301110.5193 |\n",
       "| 67 | 1.0 | 0.005 | 201903.3316 | 0.0005 | 0.0335 | 40380.6663 | 80761332.6232 |\n",
       "| 68 | 1.0 | 0.005 | 242283.9979 | 0.0005 | 0.034 | 48456.7996 | 96913599.1478 |\n",
       "| 69 | 1.0 | 0.005 | 290740.7974 | 0.0005 | 0.0345 | 58148.1595 | 116296318.9774 |\n",
       "| 70 | 1.0 | 0.005 | 348888.9569 | 0.0005 | 0.035 | 69777.7914 | 139555582.7729 |\n",
       "| 71 | 1.0 | 0.005 | 418666.7483 | 0.0005 | 0.0355 | 83733.3497 | 167466699.3275 |\n",
       "| 72 | 1.0 | 0.005 | 502400.098 | 0.0005 | 0.036 | 100480.0196 | 200960039.193 |\n",
       "| 73 | 1.0 | 0.005 | 602880.1176 | 0.0005 | 0.0365 | 120576.0235 | 241152047.0315 |\n",
       "| 74 | 1.0 | 0.005 | 723456.1411 | 0.0005 | 0.037 | 144691.2282 | 289382456.4379 |\n",
       "| 75 | 1.0 | 0.005 | 868147.3693 | 0.0005 | 0.0375 | 173629.4739 | 347258947.7254 |\n",
       "| 76 | 1.0 | 0.005 | 1041776.8432 | 0.0005 | 0.038 | 208355.3686 | 416710737.2705 |\n",
       "| 77 | 1.0 | 0.005 | 1250132.2118 | 0.0005 | 0.0385 | 250026.4424 | 500052884.7246 |\n",
       "| 78 | 1.0 | 0.005 | 1500158.6542 | 0.0005 | 0.039 | 300031.7308 | 600063461.6695 |\n",
       "| 79 | 1.0 | 0.005 | 1800190.385 | 0.0005 | 0.0395 | 360038.077 | 720076154.0034 |\n",
       "| 80 | 1.0 | 0.005 | 2160228.462 | 0.0005 | 0.04 | 432045.6924 | 864091384.8041 |\n",
       "| 81 | 1.0 | 0.005 | 2592274.1544 | 0.0005 | 0.0405 | 518454.8309 | 1036909661.7649 |\n",
       "| 82 | 1.0 | 0.005 | 3110728.9853 | 0.0005 | 0.041 | 622145.7971 | 1244291594.1179 |\n",
       "| 83 | 1.0 | 0.005 | 3732874.7824 | 0.0005 | 0.0415 | 746574.9565 | 1493149912.9415 |\n",
       "| 84 | 1.0 | 0.005 | 4479449.7388 | 0.0005 | 0.042 | 895889.9478 | 1791779895.5298 |\n",
       "| 85 | 1.0 | 0.005 | 5375339.6866 | 0.0005 | 0.0425 | 1075067.9373 | 2150135874.6358 |\n",
       "| 86 | 1.0 | 0.005 | 6450407.6239 | 0.0005 | 0.043 | 1290081.5248 | 2580163049.563 |\n",
       "| 87 | 1.0 | 0.005 | 7740489.1487 | 0.0005 | 0.0435 | 1548097.8297 | 3096195659.4755 |\n",
       "| 88 | 1.0 | 0.005 | 9288586.9784 | 0.0005 | 0.044 | 1857717.3957 | 3715434791.3707 |\n",
       "| 89 | 1.0 | 0.005 | 11146304.3741 | 0.0005 | 0.0445 | 2229260.8748 | 4458521749.6448 |\n",
       "| 90 | 1.0 | 0.005 | 13375565.2489 | 0.0005 | 0.045 | 2675113.0498 | 5350226099.5737 |\n",
       "| 91 | 1.0 | 0.005 | 16050678.2987 | 0.0005 | 0.0455 | 3210135.6597 | 6420271319.4885 |\n",
       "| 92 | 1.0 | 0.005 | 19260813.9585 | 0.0005 | 0.046 | 3852162.7917 | 7704325583.3862 |\n",
       "| 93 | 1.0 | 0.005 | 23112976.7502 | 0.0005 | 0.0465 | 4622595.35 | 9245190700.0634 |\n",
       "| 94 | 1.0 | 0.005 | 27735572.1002 | 0.0005 | 0.047 | 5547114.42 | 11094228840.0761 |\n",
       "| 95 | 1.0 | 0.005 | 33282686.5202 | 0.0005 | 0.0475 | 6656537.304 | 13313074608.0913 |\n",
       "| 96 | 1.0 | 0.005 | 39939223.8243 | 0.0005 | 0.048 | 7987844.7649 | 15975689529.7096 |\n",
       "| 97 | 1.0 | 0.005 | 47927068.5891 | 0.0005 | 0.0485 | 9585413.7178 | 19170827435.6515 |\n",
       "| 98 | 1.0 | 0.005 | 57512482.307 | 0.0005 | 0.049 | 11502496.4614 | 23004992922.7818 |\n",
       "| 99 | 1.0 | 0.005 | 69014978.7683 | 0.0005 | 0.0495 | 13802995.7537 | 27605991507.3382 |\n",
       "\n",
       "\n",
       "#### Einzelwerte\n",
       "\n",
       "| max_n |\n",
       "|-------|\n",
       "| 100 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Oedometer:\n",
    "    def __init__(self, e_0: float = 1.00, C_c: float = 0.005, delta_epsilon: float = 0.0005, \n",
    "                 sigma_t: float = 1.00, max_n: int = 50, rand_epsilon:bool=False, **kwargs):\n",
    "        self.max_n = max_n\n",
    "\n",
    "        # Standardwerte als Listen setzen\n",
    "        self.e_0 = [e_0]\n",
    "        self.C_c = [C_c]\n",
    "        self.sigma_t = [sigma_t]\n",
    "        self.delta_epsilon = []\n",
    "        self.total_epsilon = [0]\n",
    "\n",
    "        # Initiale Listen für Berechnungen\n",
    "        self.sigma_t = [sigma_t]\n",
    "        self.delta_sigma = []\n",
    "        self.e_s = []\n",
    "        self.delta_epsilon = [delta_epsilon]\n",
    "        \n",
    "        # Dynamische Zuweisung von kwargs, falls vorhanden\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):  # Nur vorhandene Attribute setzen\n",
    "                setattr(self, key, [value])\n",
    "        \n",
    "        # Berechnungen durchführen\n",
    "        self.__calc_sigma_t_p1()\n",
    "\n",
    "        # Listenlängen anpassen\n",
    "        self.__adjust_list_lengths()\n",
    "        self.__calc_total_epsilon()\n",
    "\n",
    "    def __adjust_list_lengths(self):\n",
    "        \"\"\" Passt ALLE Listen-Attribute an `max_n` an. \"\"\"\n",
    "        attributes = ['e_0', 'C_c', 'delta_epsilon', 'sigma_t', 'sigma_t', 'delta_sigma', 'e_s']\n",
    "        for attr in attributes:\n",
    "            value_list = getattr(self, attr, [])\n",
    "            current_length = len(value_list)\n",
    "\n",
    "            if current_length > self.max_n:\n",
    "                setattr(self, attr, value_list[:self.max_n])  # Kürzen\n",
    "            elif current_length < self.max_n:\n",
    "                setattr(self, attr, value_list + [value_list[-1] if value_list else 0] * (self.max_n - current_length))  # Auffüllen\n",
    "    \n",
    "    def __calc_total_epsilon(self):\n",
    "        for i in range(len(self.delta_epsilon)-1):\n",
    "            self.total_epsilon.append(self.total_epsilon[i] + self.delta_epsilon[i])            \n",
    "    \n",
    "    def __calc_e_s(self, sigma_t):\n",
    "        \"\"\" Berechnet `e_s` aus `sigma_t`. \"\"\"\n",
    "        e_s = (1 + self.e_0[0]) / self.C_c[0] * sigma_t\n",
    "        self.e_s.append(e_s)\n",
    "        return e_s\n",
    "\n",
    "    def __calc_sigma_t_p1(self):\n",
    "        \"\"\" Berechnet `sigma_t` und `delta_sigma` für die nächsten Schritte. \"\"\"\n",
    "        for i in range(self.max_n):  # -1, weil sigma_t bereits gesetzt ist\n",
    "            e_s = self.__calc_e_s(self.sigma_t[i])\n",
    "            delta_sigma = e_s * self.delta_epsilon[0]\n",
    "            sigma = self.sigma_t[i] + delta_sigma\n",
    "            self.sigma_t.append(sigma)\n",
    "            self.delta_sigma.append(delta_sigma)\n",
    "\n",
    "if not use_excel:\n",
    "    data_dict = dict(vars(Oedometer(**oedo_parameter)))\n",
    "    display(dict_to_markdown_table(data_dict, 'Ödometerdaten'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb386144-1aae-4b43-aeb1-c3b715d7eac2",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "\n",
    "## Daten normalisieren\n",
    "Die Normalisierung von Daten für neuronale Netze bedeutet, dass Eingabedaten auf eine vergleichbare Skala gebracht werden, um das Training stabiler und effizienter zu machen. Hier verwendete Methode:\n",
    "- Min-Max-Skalierung: Werte auf einen Bereich (0 bis 1) bringen.  <i class=\"fa fa-info\"> [Wiki](https://en.wikipedia.org/wiki/Feature_scaling#Methods)</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd8f39a-6d82-480e-a011-2e432797803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️ Es wurde keine Normalisierung der Werte vorgenommen.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "if normalize_data:\n",
    "    # Wir speichern die Rohdaten als Referenzen, bevor die Normalisierung angewendet wird\n",
    "    data_dict.update({f'{input_data}_raw': data_dict.pop(input_data)})\n",
    "    data_dict.update({f'{output_data}_raw': data_dict.pop(output_data)})\n",
    "\n",
    "    # Erstelle den MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Kombiniere die Rohdaten in einem DataFrame, um sie zu normalisieren\n",
    "    df_raw = pd.DataFrame({\n",
    "        f'{input_data}_raw': data_dict[f'{input_data}_raw'],\n",
    "        f'{output_data}_raw': data_dict[f'{output_data}_raw']\n",
    "    })\n",
    "\n",
    "    # Fit the scaler und transformiere die Daten\n",
    "    scaled_data = scaler.fit_transform(df_raw)\n",
    "\n",
    "    # Aktualisiere die normalisierten Werte im data_dict\n",
    "    data_dict['sigma_t'] = scaled_data[:, 0]  # Die erste Spalte enthält normalisierte sigma_t\n",
    "    data_dict['e_s'] = scaled_data[:, 1]  # Die zweite Spalte enthält normalisierte delta_sigma\n",
    "\n",
    "    print('‼️Tabellenwerte des Oedometerversuches normalisiert.')\n",
    "\n",
    "else:\n",
    "    print('‼️ Es wurde keine Normalisierung der Werte vorgenommen.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d182c1ff77877a1",
   "metadata": {},
   "source": [
    "## **Datenvorbereitung für PINA mit LabelTensor**\n",
    "In diesem Code werden die Eingabedaten aus `data_dict` als **LabelTensor** gespeichert, um sie strukturiert und mit benannten Dimensionen für das neuronale Netz in PINA bereitzustellen.  \n",
    "\n",
    "- `sigma_t_train`, `delta_epsilon_train` und `delta_sigma_train` werden als **einzelne beschriftete Tensoren** erstellt.  \n",
    "- `input_points_combined` kombiniert `sigma_t` und `delta_epsilon` in einem **2D-Tensor** für das Training.  \n",
    "- `LabelTensor` erleichtert die Nutzung der Daten in PINA, indem es Variablen klar zuordnet und mit physischen Größen verknüpft.\n",
    "\n",
    "**Mehr zu `LabelTensor`:**  \n",
    "[PINA Documentation – LabelTensor](https://mathlab.github.io/PINA/_rst/label_tensor.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506469cd2477431e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.150519Z",
     "start_time": "2025-03-12T08:30:31.125143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Data Loaded\n",
      " sigma_t: torch.Size([100, 1])\n",
      " e_s: torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pina.utils import LabelTensor\n",
    "from torch import tensor\n",
    "\n",
    "# Beispiel-Daten\n",
    "input_pts = LabelTensor(tensor(data_dict[input_data], dtype=torch.float).unsqueeze(-1),[input_data])\n",
    "# delta_epsilon_train = LabelTensor(tensor(data_dict['delta_epsilon'], dtype=torch.float).unsqueeze(-1), ['delta_epsilon'])\n",
    "output_pts = LabelTensor(tensor(data_dict[output_data], dtype=torch.float).unsqueeze(-1), [output_data])\n",
    "\n",
    "# Kombinieren der Trainingsdaten (Verwendung von 'np.column_stack' für bessere Performance)\n",
    "# input_points_combined = LabelTensor(torch.tensor(np.column_stack([data_dict['sigma_t'], data_dict['delta_epsilon']]), dtype=torch.float), ['sigma_t', 'delta_epsilon'])\n",
    "if debug_mode:\n",
    "    print('‼️Data Loaded')\n",
    "    print(f' {input_data}: {input_pts.size()}')\n",
    "    print(f' {output_data}: {output_pts.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8c6ec-bac1-4d00-83cb-63b178a72be6",
   "metadata": {},
   "source": [
    "### **Definition eines einfachen PINN-Problems in PINA**  \n",
    "Dieser Code definiert ein **Physics-Informed Neural Network (PINN)**-Problem mithilfe der PINA-Bibliothek.  \n",
    " \n",
    "- **Klassenstruktur (`SimpleODE`)**: Erbt von `AbstractProblem` und spezifiziert die Eingabe- und Ausgabevariablen basierend auf `LabelTensor`.\n",
    "    - [PINA-Dokumentation - AbstractProblem](https://mathlab.github.io/PINA/_rst/problem/abstractproblem.html) \n",
    "- **Definitionsbereich (`domain`)**: Der Wertebereich der Eingabevariablen (`sigma_t`, `delta_epsilon`) wird als `CartesianDomain` festgelegt.\n",
    "    - **Hinweis:** `domain` muss immer definiert sein, selbst wenn sie nicht direkt zur Datengenerierung verwendet wird.  \n",
    "    - [PINA-Dokumentation - CartesianDomain](https://mathlab.github.io/PINA/_rst/geometry/cartesian.html) \n",
    "- **Randbedingungen (`conditions`)**: Die echten Messwerte (`in sigma_t, delta_epsilon` `out delta_sigma_train`) werden als Randbedingung (`Condition`) für das Modell definiert.\n",
    "    - [PINA-Dokumentation - Condition](https://mathlab.github.io/PINA/_rst/condition.html) \n",
    "- **\"Wahre Lösung\" (`truth_solution`)**: Falls erforderlich, kann eine analytische Lösung (hier `torch.exp(...)`) zur Validierung genutzt werden.\n",
    "    - **Hinweis:** Funktioniert in unserem Fall nicht, da die Implementierung nicht für reine Input und Outpunkt Punkte implementiert ist.\n",
    "    - [PINA-Tutorial - Physics Informed Neural Networks on PINA](https://mathlab.github.io/PINA/_rst/tutorials/tutorial1/tutorial.html) \n",
    "- **Probleminstanz (`problem = SimpleODE()`)**: Erstellt das Problem, das für das Training eines PINN verwendet wird.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2de5194c7f49fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.712233Z",
     "start_time": "2025-03-12T08:30:31.590633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Geladene Input Variablen:  ['sigma_t']\n",
      "‼️Geladene Output Variablen:  ['e_s']\n",
      "‼️Input points: {'data': LabelTensor([[1.0000e+00],\n",
      "             [1.2000e+00],\n",
      "             [1.4400e+00],\n",
      "             [1.7280e+00],\n",
      "             [2.0736e+00],\n",
      "             [2.4883e+00],\n",
      "             [2.9860e+00],\n",
      "             [3.5832e+00],\n",
      "             [4.2998e+00],\n",
      "             [5.1598e+00],\n",
      "             [6.1917e+00],\n",
      "             [7.4301e+00],\n",
      "             [8.9161e+00],\n",
      "             [1.0699e+01],\n",
      "             [1.2839e+01],\n",
      "             [1.5407e+01],\n",
      "             [1.8488e+01],\n",
      "             [2.2186e+01],\n",
      "             [2.6623e+01],\n",
      "             [3.1948e+01],\n",
      "             [3.8338e+01],\n",
      "             [4.6005e+01],\n",
      "             [5.5206e+01],\n",
      "             [6.6247e+01],\n",
      "             [7.9497e+01],\n",
      "             [9.5396e+01],\n",
      "             [1.1448e+02],\n",
      "             [1.3737e+02],\n",
      "             [1.6484e+02],\n",
      "             [1.9781e+02],\n",
      "             [2.3738e+02],\n",
      "             [2.8485e+02],\n",
      "             [3.4182e+02],\n",
      "             [4.1019e+02],\n",
      "             [4.9222e+02],\n",
      "             [5.9067e+02],\n",
      "             [7.0880e+02],\n",
      "             [8.5056e+02],\n",
      "             [1.0207e+03],\n",
      "             [1.2248e+03],\n",
      "             [1.4698e+03],\n",
      "             [1.7637e+03],\n",
      "             [2.1165e+03],\n",
      "             [2.5398e+03],\n",
      "             [3.0477e+03],\n",
      "             [3.6573e+03],\n",
      "             [4.3887e+03],\n",
      "             [5.2665e+03],\n",
      "             [6.3197e+03],\n",
      "             [7.5837e+03],\n",
      "             [9.1004e+03],\n",
      "             [1.0921e+04],\n",
      "             [1.3105e+04],\n",
      "             [1.5726e+04],\n",
      "             [1.8871e+04],\n",
      "             [2.2645e+04],\n",
      "             [2.7174e+04],\n",
      "             [3.2609e+04],\n",
      "             [3.9130e+04],\n",
      "             [4.6956e+04],\n",
      "             [5.6348e+04],\n",
      "             [6.7617e+04],\n",
      "             [8.1140e+04],\n",
      "             [9.7369e+04],\n",
      "             [1.1684e+05],\n",
      "             [1.4021e+05],\n",
      "             [1.6825e+05],\n",
      "             [2.0190e+05],\n",
      "             [2.4228e+05],\n",
      "             [2.9074e+05],\n",
      "             [3.4889e+05],\n",
      "             [4.1867e+05],\n",
      "             [5.0240e+05],\n",
      "             [6.0288e+05],\n",
      "             [7.2346e+05],\n",
      "             [8.6815e+05],\n",
      "             [1.0418e+06],\n",
      "             [1.2501e+06],\n",
      "             [1.5002e+06],\n",
      "             [1.8002e+06],\n",
      "             [2.1602e+06],\n",
      "             [2.5923e+06],\n",
      "             [3.1107e+06],\n",
      "             [3.7329e+06],\n",
      "             [4.4794e+06],\n",
      "             [5.3753e+06],\n",
      "             [6.4504e+06],\n",
      "             [7.7405e+06],\n",
      "             [9.2886e+06],\n",
      "             [1.1146e+07],\n",
      "             [1.3376e+07],\n",
      "             [1.6051e+07],\n",
      "             [1.9261e+07],\n",
      "             [2.3113e+07],\n",
      "             [2.7736e+07],\n",
      "             [3.3283e+07],\n",
      "             [3.9939e+07],\n",
      "             [4.7927e+07],\n",
      "             [5.7512e+07],\n",
      "             [6.9015e+07]])}\n",
      "‼️Output points: 1: {'dof': ['e_s'], 'name': 1}\n",
      "\n",
      "tensor([[4.0000e+02],\n",
      "        [4.8000e+02],\n",
      "        [5.7600e+02],\n",
      "        [6.9120e+02],\n",
      "        [8.2944e+02],\n",
      "        [9.9533e+02],\n",
      "        [1.1944e+03],\n",
      "        [1.4333e+03],\n",
      "        [1.7199e+03],\n",
      "        [2.0639e+03],\n",
      "        [2.4767e+03],\n",
      "        [2.9720e+03],\n",
      "        [3.5664e+03],\n",
      "        [4.2797e+03],\n",
      "        [5.1357e+03],\n",
      "        [6.1628e+03],\n",
      "        [7.3954e+03],\n",
      "        [8.8744e+03],\n",
      "        [1.0649e+04],\n",
      "        [1.2779e+04],\n",
      "        [1.5335e+04],\n",
      "        [1.8402e+04],\n",
      "        [2.2082e+04],\n",
      "        [2.6499e+04],\n",
      "        [3.1799e+04],\n",
      "        [3.8158e+04],\n",
      "        [4.5790e+04],\n",
      "        [5.4948e+04],\n",
      "        [6.5938e+04],\n",
      "        [7.9125e+04],\n",
      "        [9.4951e+04],\n",
      "        [1.1394e+05],\n",
      "        [1.3673e+05],\n",
      "        [1.6407e+05],\n",
      "        [1.9689e+05],\n",
      "        [2.3627e+05],\n",
      "        [2.8352e+05],\n",
      "        [3.4022e+05],\n",
      "        [4.0827e+05],\n",
      "        [4.8992e+05],\n",
      "        [5.8791e+05],\n",
      "        [7.0549e+05],\n",
      "        [8.4659e+05],\n",
      "        [1.0159e+06],\n",
      "        [1.2191e+06],\n",
      "        [1.4629e+06],\n",
      "        [1.7555e+06],\n",
      "        [2.1066e+06],\n",
      "        [2.5279e+06],\n",
      "        [3.0335e+06],\n",
      "        [3.6402e+06],\n",
      "        [4.3682e+06],\n",
      "        [5.2419e+06],\n",
      "        [6.2902e+06],\n",
      "        [7.5483e+06],\n",
      "        [9.0579e+06],\n",
      "        [1.0870e+07],\n",
      "        [1.3043e+07],\n",
      "        [1.5652e+07],\n",
      "        [1.8783e+07],\n",
      "        [2.2539e+07],\n",
      "        [2.7047e+07],\n",
      "        [3.2456e+07],\n",
      "        [3.8947e+07],\n",
      "        [4.6737e+07],\n",
      "        [5.6084e+07],\n",
      "        [6.7301e+07],\n",
      "        [8.0761e+07],\n",
      "        [9.6914e+07],\n",
      "        [1.1630e+08],\n",
      "        [1.3956e+08],\n",
      "        [1.6747e+08],\n",
      "        [2.0096e+08],\n",
      "        [2.4115e+08],\n",
      "        [2.8938e+08],\n",
      "        [3.4726e+08],\n",
      "        [4.1671e+08],\n",
      "        [5.0005e+08],\n",
      "        [6.0006e+08],\n",
      "        [7.2008e+08],\n",
      "        [8.6409e+08],\n",
      "        [1.0369e+09],\n",
      "        [1.2443e+09],\n",
      "        [1.4931e+09],\n",
      "        [1.7918e+09],\n",
      "        [2.1501e+09],\n",
      "        [2.5802e+09],\n",
      "        [3.0962e+09],\n",
      "        [3.7154e+09],\n",
      "        [4.4585e+09],\n",
      "        [5.3502e+09],\n",
      "        [6.4203e+09],\n",
      "        [7.7043e+09],\n",
      "        [9.2452e+09],\n",
      "        [1.1094e+10],\n",
      "        [1.3313e+10],\n",
      "        [1.5976e+10],\n",
      "        [1.9171e+10],\n",
      "        [2.3005e+10],\n",
      "        [2.7606e+10]])\n"
     ]
    }
   ],
   "source": [
    "from pina.problem import AbstractProblem\n",
    "from pina.domain import CartesianDomain\n",
    "from pina import Condition\n",
    "\n",
    "\n",
    "input_conditions = {'data': Condition(input=input_pts, target=output_pts),}\n",
    "\n",
    "\n",
    "class SimpleODE(AbstractProblem):\n",
    "\n",
    "    # Definition der Eingabe- und Ausgabevariablen basierend auf LabelTensor\n",
    "    input_variables = input_pts.labels\n",
    "    output_variables = output_pts.labels\n",
    "\n",
    "    # Wertebereich\n",
    "    domain = CartesianDomain({input_data: [0, 1]})#, 'delta_epsilon': [0, 1]})  # Wertebereich immer definieren!\n",
    "\n",
    "    # Definition der Randbedingungen und (hier: nur) vorberechnetet Punkte\n",
    "    conditions = input_conditions\n",
    "\n",
    "    output_pts=output_pts\n",
    "\n",
    "    # Methode zur Definition der \"wahren Lösung\" des Problems\n",
    "    def truth_solution(self, pts):\n",
    "        return torch.exp(pts.extract([input_data]))\n",
    "\n",
    "# Problem-Instanz erzeugen\n",
    "problem = SimpleODE()\n",
    "\n",
    "\n",
    "\n",
    "if debug_mode:\n",
    "    # Debugging-Ausgaben\n",
    "    print(\"‼️Geladene Input Variablen: \", problem.input_variables)\n",
    "    print(\"‼️Geladene Output Variablen: \", problem.output_variables)\n",
    "    print('‼️Input points:', problem.input_pts)\n",
    "    print('‼️Output points:', problem.output_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017454f5732f1b5",
   "metadata": {},
   "source": [
    "## Visualisierung Sampling\n",
    "Darstellung Input: `sigma_t` und `delta_epsilon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8177115081d371bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:33.410973Z",
     "start_time": "2025-03-12T08:30:32.818773Z"
    }
   },
   "outputs": [],
   "source": [
    "# from pina import Plotter\n",
    "\n",
    "# pl = Plotter()\n",
    "# pl.plot_samples(problem=problem, filename=f'./{graph_folder}/{img_visual_sampling}{img_extensions}', variables=['delta_epsilon','sigma_t'])\n",
    "# display(Markdown('![Result of sampling](' + f'./{graph_folder}/{img_visual_sampling}{img_extensions}' + ')'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b78c6b-22bf-4a9a-8d00-be05b47deb71",
   "metadata": {},
   "source": [
    "# Training eines Physics-Informed Neural Networks (PINN) mit PINA\n",
    "\n",
    "Dieser Code definiert und trainiert ein **Physics-Informed Neural Network (PINN)** zur Lösung des Problems in PINA.\n",
    "\n",
    "- **Modell (`FeedForward`)**: Ein neuronales Netz mit drei versteckten Schichten (`[50, 50, 50]`), das mit der ReLU-Aktivierungsfunktion arbeitet.\n",
    "- **PINN-Objekt (`PINN`)**: Erstellt das PINN-Modell, das die physikalischen Randbedingungen des Problems berücksichtigt.\n",
    "- **TensorBoard-Logger (`TensorBoardLogger`)**: Speichert Trainingsmetriken zur Visualisierung.\n",
    "- **Trainer (`Trainer`)**: Führt das Training für 1500 Epochen mit Batch-Größe 10 durch.\n",
    "- **Training starten (`trainer.train()`)**: Startet den Optimierungsprozess und protokolliert die Metriken.\n",
    "\n",
    "Am Ende wird die **finale Loss-Funktion** ausgegeben, um die Trainingsqualität zu bewerten.\n",
    "\n",
    "**Mehr zu `Trainer`:**  \n",
    "[PINA-Dokumentation – Trainer](https://mathlab.github.io/PINA/_rst/trainer.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb7ce50b0b515f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-12T08:30:34.000486Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Info:\n",
      "‼️Länge der Eingabepunkte (input_pts): 1\n",
      "‼️Länge der Ausgabepunkte (output_pts): 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|█| 20/20 [00:00<00:00, 74.02it/s, v_num=138, data_loss_step=5.99e+6, train_loss_step=5.99e+6, data_loss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|█| 20/20 [00:00<00:00, 66.40it/s, v_num=138, data_loss_step=5.99e+6, train_loss_step=5.99e+6, data_loss\n",
      "\n",
      "Finale Loss Werte\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_loss_step': tensor(5985359.),\n",
       " 'train_loss_step': tensor(5985359.),\n",
       " 'data_loss_epoch': tensor(89028912.),\n",
       " 'train_loss_epoch': tensor(89028912.)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pina import Trainer\n",
    "from pina.solver import PINN\n",
    "from pina.model import FeedForward\n",
    "from pina.callback import MetricTracker\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Import TensorBoard Logger\n",
    "\n",
    "if debug_mode:\n",
    "    print('Debugging Info:')\n",
    "    # Überprüfen der Größe der Eingabepunkte und Ausgabepunkte\n",
    "    print(\"‼️Länge der Eingabepunkte (input_pts):\", len(problem.input_pts))\n",
    "    print(\"‼️Länge der Ausgabepunkte (output_pts):\", len(problem.output_pts))\n",
    "\n",
    "# Model erstellen\n",
    "model = FeedForward(\n",
    "    layers=[20],\n",
    "    func=torch.nn.ReLU,\n",
    "    output_dimensions=len(problem.output_variables),\n",
    "    input_dimensions=len(problem.input_variables)\n",
    ")\n",
    "\n",
    "# PINN-Objekt erstellen\n",
    "pinn = PINN(problem, model)\n",
    "\n",
    "# TensorBoard-Logger\n",
    "logger = TensorBoardLogger(\"tensorboard_logs\", name=\"pina_experiment\")\n",
    "\n",
    "# Trainer erstellen mit TensorBoard-Logger\n",
    "trainer = Trainer(\n",
    "    solver=pinn,\n",
    "    max_epochs=1000,\n",
    "    callbacks=[MetricTracker()],\n",
    "    batch_size=5,\n",
    "    accelerator='cpu',\n",
    "    logger=logger,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Training starten\n",
    "trainer.train()\n",
    "\n",
    "print('\\nFinale Loss Werte')\n",
    "# Inspect final loss\n",
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a21a7-66f3-4684-b49f-e1d1aeaaa974",
   "metadata": {},
   "source": [
    "## **Visualisierung der Modellvorhersage für delta_sigma**\n",
    "\n",
    "Dieser Code erstellt einen **Plot der wahren Werte (`delta_sigma`)** im Vergleich zur **Vorhersage des neuronalen Netzwerks**.\n",
    "\n",
    "- **Datenvorbereitung (`input_data`)**: Die Eingabedaten (`sigma_t` und `delta_epsilon`) werden als `LabelTensor` für das trainierte Modell erstellt.\n",
    "- **Modellvorhersage (`pinn(input_data)`)**: Das trainierte PINN-Modell gibt eine Prognose für `delta_sigma` aus.\n",
    "- **Plot-Erstellung mit `matplotlib`**:  \n",
    "  - Die wahre Lösung (`delta_sigma`) wird als **blaue gestrichelte Linie** dargestellt.  \n",
    "  - Die Vorhersage des neuronalen Netzwerks wird als **rote durchgezogene Linie** geplottet.  \n",
    "\n",
    "**Zusätzlicher Schritt:**  \n",
    "Die Nutzung von `matplotlib` war notwendig, da die interne Plot-Funktion von PINA `pl.plot()` das Diagramm nicht wie in den Tutorials erwartungsgemäß generierte, selbst wenn `delta_epsilon` auf einen fixen Wert gesetzt wurde. Dies könnte auf eine fehlerhafte Nutzung der Funktion oder auf eine Inkompatibilität in der Darstellung zurückzuführen sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8ad2a2-0e03-453a-9428-ef2c8e3d0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_delta_sigma(delta_sigma_pred, scaler):\n",
    "    \"\"\"\n",
    "    Denormalisiert die Vorhersagewerte für delta_sigma zurück auf den ursprünglichen Bereich.\n",
    "    \n",
    "    :param delta_sigma_pred: Normalisierte Vorhersagewerte für `delta_sigma`\n",
    "    :param scaler: Der MinMaxScaler, der für die Normalisierung verwendet wurde\n",
    "    :return: Denormalisierte Werte für `delta_sigma_pred`\n",
    "    \"\"\"\n",
    "    # Denormalisieren basierend auf den min und max Werten des Scalers\n",
    "    delta_sigma_pred_denorm = delta_sigma_pred * (scaler.data_max_[0] - scaler.data_min_[0]) + scaler.data_min_[0]\n",
    "    return delta_sigma_pred_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1ac89b-8b69-4b72-bbea-1673ce6e4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "oedo_para = {\n",
    "    'max_n': 1, \n",
    "    'e_0': 1.0, \n",
    "    'C_c': 0.005,   \n",
    "    'total_epsilon': 0,\n",
    "}\n",
    "\n",
    "# Vorbereitung Tensoren\n",
    "sigma_t = np.random.choice(range(1, 10000), size=i, replace=False)\n",
    "delta_sigma = []\n",
    "delta_epsilon = np.repeat(np.array(np.float64(0.0005)), i)\n",
    "new_data = {\n",
    "    'total_epsilon' : [],\n",
    "    'delta_epsilon' : [],\n",
    "    'delta_sigma' : [],\n",
    "    'sigma_t' : [],\n",
    "}\n",
    "# delta_epsilon = np.random.uniform(0.0001, 0.001, size=i)\n",
    "for i in range(i):\n",
    "    oedo_para['sigma_t'] = sigma_t[i]\n",
    "    oedo_para['delta_epsilon'] = delta_epsilon[i]\n",
    "    oedo = Oedometer(**oedo_para)\n",
    "    delta_sigma.append(round(oedo.delta_sigma[0], 2))\n",
    "    new_data['total_epsilon'].append(oedo.total_epsilon[0])\n",
    "    new_data['delta_epsilon'].append(oedo.delta_epsilon[0])\n",
    "    new_data['delta_sigma'].append(oedo.delta_sigma[0])\n",
    "    new_data['sigma_t'].append(oedo.sigma_t[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de070fe2-16f3-40f1-8602-36aebfb3818a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Data-Loss bis sigma_19\n",
       "\n",
       "| Index | total_epsilon | delta_epsilon | sigma_t | True delta_sigma | Predicted delta_sigma | Test-Loss (True - Predicted) |\n",
       "|--|--------------|--------------|--------|-----------------|----------------------|-----------------------------|\n",
       "| 0 | 0 | 0.0005 | 238 | 47.6 | 95722.0156 | -95674.4156 |\n",
       "| 1 | 0 | 0.0005 | 4503 | 900.6 | 1801719.0 | -1800818.4 |\n",
       "| 2 | 0 | 0.0005 | 7414 | 1482.8 | 2966117.0 | -2964634.2 |\n",
       "| 3 | 0 | 0.0005 | 6184 | 1236.8 | 2474117.5 | -2472880.7 |\n",
       "| 4 | 0 | 0.0005 | 1303 | 260.6 | 521721.2188 | -521460.6188 |\n",
       "| 5 | 0 | 0.0005 | 7170 | 1434.0 | 2868516.75 | -2867082.75 |\n",
       "| 6 | 0 | 0.0005 | 5541 | 1108.2 | 2216918.0 | -2215809.8 |\n",
       "| 7 | 0 | 0.0005 | 3730 | 746.0 | 1492519.375 | -1491773.375 |\n",
       "| 8 | 0 | 0.0005 | 263 | 52.6 | 105721.9922 | -105669.3922 |\n",
       "| 9 | 0 | 0.0005 | 2211 | 442.2 | 884920.5 | -884478.3 |\n",
       "| 10 | 0 | 0.0005 | 4821 | 964.2 | 1928918.625 | -1927954.425 |\n",
       "| 11 | 0 | 0.0005 | 8192 | 1638.4 | 3277316.0 | -3275677.6 |\n",
       "| 12 | 0 | 0.0005 | 4658 | 931.6 | 1863718.875 | -1862787.275 |\n",
       "| 13 | 0 | 0.0005 | 5948 | 1189.6 | 2379717.5 | -2378527.9 |\n",
       "| 14 | 0 | 0.0005 | 4667 | 933.4 | 1867318.875 | -1866385.475 |\n",
       "| 15 | 0 | 0.0005 | 9131 | 1826.2 | 3652915.5 | -3651089.3 |\n",
       "| 16 | 0 | 0.0005 | 4499 | 899.8 | 1800118.875 | -1799219.075 |\n",
       "| 17 | 0 | 0.0005 | 7657 | 1531.4 | 3063316.25 | -3061784.85 |\n",
       "| 18 | 0 | 0.0005 | 9699 | 1939.8 | 3880115.25 | -3878175.45 |\n",
       "| 19 | 0 | 0.0005 | 1017 | 203.4 | 407321.4062 | -407118.0062 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "![Prediction vs True Solution](./graph/visual_prediction-vs-truesolution.png)<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_t'], new_data['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "if normalize_data:\n",
    "    delta_sigma_pred = denormalize_delta_sigma(pinn(input_points_combined).detach().numpy(), scaler)\n",
    "    data_dict['delta_sigma'] = denormalize_delta_sigma(data_dict['delta_sigma'], scaler)\n",
    "else:\n",
    "    delta_sigma_pred = pinn(input_data).detach().numpy()\n",
    "\n",
    "display_data_loss_table(data_dict=new_data, delta_sigma_pred=delta_sigma_pred, max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution, \n",
    "                                     img_extensions=img_extensions, y_axis='delta_epsilon', max_i=20, plot_type=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51709f02-c3c7-4076-b873-41e9d45d0c97",
   "metadata": {},
   "source": [
    "## Visualisierung Error-Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "367434e3c1076341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:26:45.282465Z",
     "start_time": "2025-03-12T08:26:44.026059Z"
    }
   },
   "outputs": [],
   "source": [
    "# pl.plot(solver=pinn, filename=f'./{graph_folder}/{img_nn_result_error}{img_extensions}')\n",
    "# display(Markdown('![NN Error result](' + f'./{graph_folder}/{img_nn_result_error}{img_extensions}' + ')'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875cc14cf077767",
   "metadata": {},
   "source": [
    "## Visualisierung Loss-Kurve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc792fe16f92e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:21:28.768753Z",
     "start_time": "2025-03-12T08:21:26.295329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![Loss Kurve](./graph/visual_loss.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the solution\n",
    "# pl.plot_loss(trainer, label='mean_loss', logy=True, filename=f'./{graph_folder}/{img_visual_loss}{img_extensions}')\n",
    "display(Markdown('![Loss Kurve](' + f'./{graph_folder}/{img_visual_loss}{img_extensions}' + ')'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979e1d6-7feb-442b-b59f-afe2593f58d6",
   "metadata": {},
   "source": [
    "# Testdaten (1 Input-Wert) $\\Delta\\epsilon=0,0005$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31d6d6b-82bc-4e94-aad6-44206ddebbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.         1.2        1.44       1.728      2.0736     2.48832\n",
      "  2.985984   3.583181   4.299817   5.1597805  6.191736   7.4300838\n",
      "  8.9161005 10.699321  12.839185  15.4070215 18.488426  22.186111\n",
      " 26.623333  31.948    ]\n",
      "[1.0000000e+00 9.2307745e+02 3.7067553e+05 1.4864112e+08 5.9604976e+10\n",
      " 2.3901550e+13 9.5845041e+15 3.8433789e+18 1.5411920e+21 6.1801680e+23\n",
      " 2.4782428e+26 9.9377348e+28 3.9850245e+31 1.5979919e+34 6.4079358e+36\n",
      "           inf           inf           inf           inf           inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\local_hab185\\Temp\\ipykernel_1868\\1840271716.py: RuntimeWarning: overflow encountered in multiply\n",
      "C:\\Users\\local_hab185\\Temp\\ipykernel_1868\\2310422469.py: RuntimeWarning: overflow encountered in multiply\n",
      "C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\scipy\\integrate\\_quadrature.py: RuntimeWarning: invalid value encountered in scalar subtract\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "def simulate_oedometer_pinn(pinn, Oedometer, LabelTensor, normalize_data=False,\n",
    "                             denormalize_delta_sigma=None, scaler=None,\n",
    "                             start_val=10.00, e_0=1.00, C_c=0.005, delta_epsilon=0.0005,\n",
    "                             max_n=20, rand_epsilon=False, plot_ln_sigma=False):\n",
    "    \"\"\"\n",
    "    Führt eine Oedometer-Simulation mit einem PINN-Modell durch.\n",
    "    \n",
    "    Args:\n",
    "        pinn: Das trainierte PINN-Modell.\n",
    "        Oedometer: Oedometer-Klasse zur Spannungs-Dehnungs-Berechnung.\n",
    "        LabelTensor: Funktion zum Erstellen eines beschrifteten Eingabe-Tensors.\n",
    "        normalize_data (bool): Ob Daten normalisiert eingegeben werden.\n",
    "        denormalize_delta_sigma (callable): Falls normalize_data=True, Funktion zur Rücktransformation.\n",
    "        scaler: Skaler, der zur Denormalisierung verwendet wird.\n",
    "        start_val (float): Startwert für sigma_t.\n",
    "        e_0, C_c, delta_epsilon (float): Oedometer-Parameter.\n",
    "        max_n (int): Anzahl der Iterationen.\n",
    "        rand_epsilon (bool): Zufälliges epsilon oder nicht.\n",
    "        plot_ln_sigma (bool): Falls True, wird die X-Achse als ln(σ_t) geplottet.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initiale Eingabe ins Oedometer-Modell\n",
    "    input_oedo = {\n",
    "        'e_0': e_0,\n",
    "        'C_c': C_c,\n",
    "        'delta_epsilon': delta_epsilon,\n",
    "        'sigma_t': start_val,\n",
    "        'max_n': max_n,\n",
    "        'rand_epsilon': rand_epsilon\n",
    "    }\n",
    "    X = Oedometer(**input_oedo)\n",
    "\n",
    "    # Initialisierung\n",
    "    output_oedo = {\n",
    "        'sigma_t': np.array([X.sigma_t[0]], dtype=np.float32),\n",
    "        'delta_epsilon': np.array([X.delta_epsilon[0]], dtype=np.float32),\n",
    "        'total_epsilon': np.array([0], dtype=np.float32),\n",
    "        'delta_sigma': np.empty(0, dtype=np.float32),\n",
    "        'e_s': np.array([X.e_s[0]], dtype=np.float32),\n",
    "    }\n",
    "\n",
    "    # Erste Eingabe\n",
    "    input_data = LabelTensor(\n",
    "        torch.tensor(np.column_stack((output_oedo['sigma_t'],)), dtype=torch.float),\n",
    "        ['sigma_t']\n",
    "    )\n",
    "\n",
    "    for i in range(max_n):\n",
    "        # Vorhersage\n",
    "        if normalize_data and denormalize_delta_sigma is not None:\n",
    "            delta_sigma_pred = denormalize_delta_sigma(pinn(input_data).detach().numpy(), scaler)\n",
    "        else:\n",
    "            delta_sigma_pred = pinn(input_data).detach().numpy()\n",
    "\n",
    "        # Werte updaten\n",
    "        output_oedo['delta_sigma'] = np.append(output_oedo['delta_sigma'], delta_sigma_pred[0])\n",
    "        new_sigma = output_oedo['sigma_t'][i] + delta_sigma_pred[0]\n",
    "        output_oedo['sigma_t'] = np.append(output_oedo['sigma_t'], new_sigma)\n",
    "\n",
    "        new_epsilon = output_oedo['total_epsilon'][i] + output_oedo['delta_epsilon'][0]\n",
    "        output_oedo['total_epsilon'] = np.append(output_oedo['total_epsilon'], new_epsilon)\n",
    "        # Nächster Input\n",
    "        input_data = LabelTensor(\n",
    "            torch.tensor(np.column_stack((output_oedo['sigma_t'][i + 1],)), dtype=torch.float),\n",
    "            ['sigma_t']\n",
    "        )\n",
    "\n",
    "        # e_s Update\n",
    "        e_s_input = input_oedo.copy()\n",
    "        e_s_input['sigma_t'] = new_sigma\n",
    "        e_s_input['max_n'] = 1\n",
    "        X_next = Oedometer(**e_s_input)\n",
    "        output_oedo['e_s'] = np.append(output_oedo['e_s'], X_next.e_s[0])\n",
    "    \n",
    "    # Plotten \n",
    "    if plot_ln_sigma:\n",
    "        sigma_t_true = np.array(X.sigma_t, dtype=np.float32)\n",
    "        sigma_t_pred = np.array(output_oedo['sigma_t'][:-1], dtype=np.float32)\n",
    "\n",
    "        es_true = np.array(X.e_s, dtype=np.float32)\n",
    "        es_pred = np.array(output_oedo['e_s'][:-1], dtype=np.float32)\n",
    "        \n",
    "        es_sigma_true = np.array(X.e_s, dtype=np.float32) * sigma_t_true\n",
    "        es_sigma_pred = np.array(output_oedo['e_s'][:-1], dtype=np.float32) * sigma_t_pred\n",
    "  \n",
    "        # Sigma - Epsilon\n",
    "        plt.plot(sigma_t_true, es_sigma_true-es_sigma_pred)\n",
    "        # Sigma - E_s * Sigma\n",
    "        plt.plot(sigma_t_true, es_sigma_true)\n",
    "        plt.scatter(sigma_t_pred, es_sigma_pred).set_color(\"green\")\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel(\"σ_t\")\n",
    "        # Fehlerflächen berechnen\n",
    "        abs_error = np.abs(es_sigma_true - es_sigma_pred)\n",
    "        area_l1 = simpson(abs_error, x=sigma_t_true)\n",
    "          \n",
    "    print(sigma_t_true)\n",
    "    print(sigma_t_pred)\n",
    "    plt.fill_between(sigma_t_true, es_sigma_true, es_sigma_pred, color='red', alpha=0.3, label='Fehlerfläche (|Δ|)')\n",
    "    # plt.plot(mn  np.array(X.sigma_t, dtype=np.float32), np.array(X.total_epsilon, dtype=np.float32))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.ylabel(\"ε_total\")\n",
    "    plt.title(\"Oedometer-Vorhersage\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    return output_oedo\n",
    "\n",
    "result = simulate_oedometer_pinn(\n",
    "    pinn=pinn,\n",
    "    start_val=1,\n",
    "    Oedometer=Oedometer,\n",
    "    LabelTensor=LabelTensor,\n",
    "    normalize_data=False,\n",
    "    denormalize_delta_sigma=None,\n",
    "    scaler=None,\n",
    "    plot_ln_sigma=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bff797-ce23-479e-bfa6-ee6607f42cf0",
   "metadata": {},
   "source": [
    "# Testwerte (2 Input-Wert) $\\Delta\\epsilon=0,0005$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb148e33-5cce-4311-91f3-f4e11197f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sigma_t': array([1500,    0,    0,    0,    0,    0,    0,    0,    0,  854,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0]), 'total_epsilon': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'delta_epsilon': array([0.0005, 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.0005, 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.    , 0.    , 0.    ]), 'delta_sigma': array([300. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
      "       170.8,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,   0. ,\n",
      "         0. ,   0. ])}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of dof (1) does not match tensor shape (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m new_data = extract_excel(file_path=\u001b[33m\"\u001b[39m\u001b[33mfiles/oedometer/oedo_trainingsdata_compare2.xlsx\u001b[39m\u001b[33m\"\u001b[39m, sheet_name=\u001b[33m\"\u001b[39m\u001b[33mRes\u001b[39m\u001b[33m\"\u001b[39m, selected_columns=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m], row_start_range=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m input_data = \u001b[43mLabelTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msigma_t\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msigma_t\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m display_data_loss_table(data_dict=new_data, delta_sigma_pred=pinn(input_data).detach().numpy(), max_i=\u001b[32m20\u001b[39m)\n\u001b[32m      9\u001b[39m plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution_comp1, \n\u001b[32m     10\u001b[39m                                      img_extensions=img_extensions, y_axis=\u001b[33m'\u001b[39m\u001b[33mtotal_epsilon\u001b[39m\u001b[33m'\u001b[39m, max_i=\u001b[32m20\u001b[39m, plot_type=\u001b[33m\"\u001b[39m\u001b[33mscatter\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\label_tensor.py:79\u001b[39m, in \u001b[36mLabelTensor.__init__\u001b[39m\u001b[34m(self, x, labels)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabels\u001b[49m = labels\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m._labels = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\label_tensor.py:143\u001b[39m, in \u001b[36mLabelTensor.labels\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_labels_from_dict(labels)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mrange\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_labels_from_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    145\u001b[39m     labels = [labels]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\label_tensor.py:214\u001b[39m, in \u001b[36mLabelTensor._init_labels_from_list\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Create a dict with labels\u001b[39;00m\n\u001b[32m    211\u001b[39m last_dim_labels = {\n\u001b[32m    212\u001b[39m     \u001b[38;5;28mself\u001b[39m.ndim - \u001b[32m1\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdof\u001b[39m\u001b[33m\"\u001b[39m: labels, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.ndim - \u001b[32m1\u001b[39m}\n\u001b[32m    213\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_labels_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_dim_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\label_tensor.py:186\u001b[39m, in \u001b[36mLabelTensor._init_labels_from_dict\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dof_list, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mrange\u001b[39m)):\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    183\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdof\u001b[39m\u001b[33m'\u001b[39m\u001b[33m should be a list or range, not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dof_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[43mvalidate_dof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdof_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    189\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLabels dictionary must contain either \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdof\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keys\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pina\\label_tensor.py:167\u001b[39m, in \u001b[36mLabelTensor._init_labels_from_dict.<locals>.validate_dof\u001b[39m\u001b[34m(dof_list, dim_size)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdof must be unique\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dof_list) != dim_size:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    168\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of dof (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dof_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) does not match \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtensor shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Number of dof (1) does not match tensor shape (20)"
     ]
    }
   ],
   "source": [
    "new_data = extract_excel(file_path=\"files/oedometer/oedo_trainingsdata_compare2.xlsx\", sheet_name=\"Res\", selected_columns=[1, 2, 3, 5], row_start_range=0)\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_t'])), dtype=torch.float\n",
    "), ['sigma_t'])\n",
    "\n",
    "display_data_loss_table(data_dict=new_data, delta_sigma_pred=pinn(input_data).detach().numpy(), max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution_comp1, \n",
    "                                     img_extensions=img_extensions, y_axis='total_epsilon', max_i=20, plot_type=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d66b7b-df39-4ffb-996e-42197cccae2c",
   "metadata": {},
   "source": [
    "# Testwerte (2 Input-Wert) $\\Delta\\epsilon=0,001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d968d0-ed7a-4ea2-b613-23935a7b789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = extract_excel(file_path=\"files/oedometer/oedo_trainingsdata_compare3.xlsx\", sheet_name=\"Res\", selected_columns=[1, 2, 3, 5], row_start_range=0)\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_t'], new_data['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_t', 'delta_epsilon'])\n",
    "\n",
    "display_data_loss_table(data_dict=new_data, delta_sigma_pred=pinn(input_data).detach().numpy(), max_i=20)\n",
    "plot_prediction_vs_true_solution(pinn=pinn, data_dict=new_data, graph_folder=graph_folder, img_visual_prediction_vs_truesolution=img_visual_prediction_vs_truesolution_comp2, \n",
    "                                     img_extensions=img_extensions, y_axis='total_epsilon', max_i=20, plot_type=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409ad12-42d8-40a2-bff3-bdb2b5dd40d7",
   "metadata": {},
   "source": [
    "Gemäß statischem Trainingswert für $\\Delta\\epsilon$ wurde keine korrekte Prognose vorgenommen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
