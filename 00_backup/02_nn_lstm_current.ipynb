{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eed3593-c200-4353-96ac-b4508e0aafea",
   "metadata": {
    "id": "8eed3593-c200-4353-96ac-b4508e0aafea"
   },
   "source": [
    "# LSTM Model for Oedometer Data Prediction\n",
    "This code implements an LSTM model to predict future values based on time-series data for a geotechnical engineering problem. The goal is to predict `delta_sigma` values from the given inputs `sigma_t` (stress) and `delta_epsilon` (strain). Below are the code blocks with explanations.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4c446a-ed81-46b4-a5e4-90f6a55c1afd",
   "metadata": {
    "id": "3e4c446a-ed81-46b4-a5e4-90f6a55c1afd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import random as r\n",
    "from sys import exit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb68479-e6da-4410-ae64-a823e686dc13",
   "metadata": {
    "id": "aeb68479-e6da-4410-ae64-a823e686dc13"
   },
   "source": [
    "This section imports all the necessary libraries, including PyTorch, pandas, and matplotlib, which are used for neural network operations, data handling, and visualization.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db9fdfa-2bdf-425b-a34f-517b7608404b",
   "metadata": {
    "id": "1db9fdfa-2bdf-425b-a34f-517b7608404b"
   },
   "outputs": [],
   "source": [
    "# Debugger: Aktiviert\n",
    "debug_mode = True\n",
    "normalize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec504e-2c5c-452e-bc33-0883ac04dc72",
   "metadata": {
    "id": "caec504e-2c5c-452e-bc33-0883ac04dc72"
   },
   "source": [
    "Here, we define two key parameters:\n",
    "\n",
    "*   `debug_mode`: Used to toggle debugging functionalities.\n",
    "*   `normalize`: A flag to enable or disable data normalization.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Preloaded Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464f85c5-4347-47b8-a999-876c3405ab38",
   "metadata": {
    "id": "464f85c5-4347-47b8-a999-876c3405ab38"
   },
   "outputs": [],
   "source": [
    "def dict_to_markdown_table(data: dict, title: str = \"Datenübersicht\", include_index: bool = True, round_digits: int = 4):\n",
    "    \"\"\"\n",
    "    Wandelt ein Dictionary mit Listenwerten in eine Markdown-Tabelle für Jupyter Notebooks um.\n",
    "\n",
    "    - Schlüssel werden als Header genutzt\n",
    "    - Erste Spalte ist ein Index, falls `include_index=True`\n",
    "    - Einzelwerte werden als separate Tabelle unterhalb dargestellt\n",
    "    - Zahlenwerte werden auf eine einstellbare Anzahl an Nachkommastellen gerundet\n",
    "\n",
    "    :param data: Dictionary mit Key-Value-Paaren\n",
    "    :param title: Überschrift für die Tabelle\n",
    "    :param include_index: Falls True, wird eine Index-Spalte erstellt\n",
    "    :param round_digits: Anzahl der Nachkommastellen, auf die Werte gerundet werden sollen\n",
    "    :return: Markdown-String zur Anzeige in Jupyter\n",
    "    \"\"\"\n",
    "\n",
    "    # Hilfsfunktion zum Runden von Zahlen\n",
    "    def round_value(val):\n",
    "        if isinstance(val, (int, float)):\n",
    "            return round(val, round_digits)\n",
    "        return val\n",
    "\n",
    "    # Listen und einzelne Werte trennen\n",
    "    list_data = {k: v for k, v in data.items() if isinstance(v, list)}\n",
    "    single_values = {k: v for k, v in data.items() if not isinstance(v, list)}\n",
    "\n",
    "    # Falls es Listen gibt, erstelle eine Tabelle mit Index\n",
    "    if list_data:\n",
    "        max_len = max(len(v) for v in list_data.values())  # Längste Liste bestimmen\n",
    "\n",
    "        # Tabellenkopf\n",
    "        md_table = f\"### {title}\\n\\n\"\n",
    "        md_table += \"| \" + (\"Index | \" if include_index else \"\") + \" | \".join(list_data.keys()) + \" |\\n\"\n",
    "        md_table += \"|-\" + (\"-|\" if include_index else \"\") + \"-|\".join([\"-\" * len(k) for k in list_data.keys()]) + \"-|\\n\"\n",
    "\n",
    "        # Datenzeilen\n",
    "        for i in range(max_len):\n",
    "            row = [str(i)] if include_index else []  # Index hinzufügen (optional)\n",
    "            for key in list_data:\n",
    "                if i < len(list_data[key]):\n",
    "                    row.append(str(round_value(list_data[key][i])))\n",
    "                else:\n",
    "                    row.append(\"\")  # Leere Werte für ungleich lange Listen\n",
    "            md_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "\n",
    "    else:\n",
    "        md_table = \"\"\n",
    "\n",
    "    # Einzelwerte als extra Tabelle darstellen\n",
    "    if single_values:\n",
    "        md_table += \"\\n\\n#### Einzelwerte\\n\\n\"\n",
    "        md_table += \"| \" + \" | \".join(single_values.keys()) + \" |\\n\"\n",
    "        md_table += \"|-\" + \"-|\".join([\"-\" * len(k) for k in single_values.keys()]) + \"-|\\n\"\n",
    "        md_table += \"| \" + \" | \".join(map(lambda v: str(round_value(v)), single_values.values())) + \" |\\n\"\n",
    "\n",
    "    return Markdown(md_table)\n",
    "\n",
    "\n",
    "def display_data_loss_table(data_dict, delta_sigma_pred, max_i):\n",
    "    \"\"\"\n",
    "    Erstellt eine Markdown-Tabelle zur übersichtlichen Darstellung von Datenverlust.\n",
    "\n",
    "    Unterstützt sowohl Python-Listen als auch NumPy-Arrays.\n",
    "\n",
    "    :param data_dict: Dictionary mit `sigma_t` und `delta_sigma` (Listen oder np.arrays)\n",
    "    :param delta_sigma_pred: Vorhergesagte Werte für `delta_sigma` (Liste oder np.array)\n",
    "    :param max_i: Anzahl der Werte, die in der Tabelle angezeigt werden sollen\n",
    "    \"\"\"\n",
    "\n",
    "    # Sicherstellen, dass `sigma_t` und `delta_sigma` existieren\n",
    "    if \"sigma_t\" not in data_dict or \"delta_sigma\" not in data_dict or delta_sigma_pred is None:\n",
    "        print(\"Fehler: `data_dict` oder `delta_sigma_pred` ist nicht korrekt definiert!\")\n",
    "        return\n",
    "\n",
    "    # Konvertiere alle Werte zu Listen (falls sie NumPy-Arrays sind)\n",
    "    def to_list(arr):\n",
    "        return arr.tolist() if isinstance(arr, np.ndarray) else arr\n",
    "\n",
    "    total_epsilon = to_list(data_dict[\"total_epsilon\"])\n",
    "    delta_epsilon = to_list(data_dict[\"delta_epsilon\"])\n",
    "    sigma_t = to_list(data_dict[\"sigma_t\"])\n",
    "    delta_sigma_true = to_list(data_dict[\"delta_sigma\"])\n",
    "    delta_sigma_pred = to_list(delta_sigma_pred)  # Falls `delta_sigma_pred` ein 2D-Array ist\n",
    "\n",
    "    # Überprüfen, ob die Längen konsistent sind\n",
    "    min_len = min(len(total_epsilon), len(sigma_t), len(delta_epsilon), len(delta_sigma_true), len(delta_sigma_pred), max_i)\n",
    "\n",
    "    # Erstelle eine Tabelle für die übersichtliche Darstellung\n",
    "    data_loss_table = {\n",
    "        \"total_epsilon\" : list(total_epsilon[:min_len]),\n",
    "        \"delta_epsilon\" : list(delta_epsilon[:min_len]),\n",
    "        \"sigma_t\" : list(sigma_t[:min_len]),\n",
    "        \"True delta_sigma\": list(delta_sigma_true[:min_len]),\n",
    "        \"Predicted delta_sigma\": list(delta_sigma_pred[:min_len]),\n",
    "        \"Test-Loss (True - Predicted)\": list(np.round(np.array(delta_sigma_true[:min_len]) - np.array(delta_sigma_pred[:min_len]), 5))\n",
    "    }\n",
    "\n",
    "    # Markdown-Tabelle für bessere Darstellung in Jupyter\n",
    "    display(dict_to_markdown_table(data_loss_table, title=f\"Data-Loss bis sigma_{min_len-1}\", include_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbada5-603e-41c4-a741-932497c15772",
   "metadata": {
    "id": "23dbada5-603e-41c4-a741-932497c15772"
   },
   "source": [
    "This function converts a dictionary of lists into a Markdown table for easy visualization in Jupyter Notebooks. It helps in presenting data in a clear and structured way during debugging and analysis.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Check for use of CONDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45429180-216e-482f-be87-1702b19c8890",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45429180-216e-482f-be87-1702b19c8890",
    "outputId": "5331237b-753c-496d-e8bd-dc98973cfd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    device_num = 0\n",
    "    print('No GPU available.')\n",
    "else:\n",
    "    device_num = torch.cuda.device_count()\n",
    "    print('Device:', device, '-- Number of devices:', device_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5e68d-54d7-40dd-bd8c-91f6c7349e3a",
   "metadata": {
    "id": "aee5e68d-54d7-40dd-bd8c-91f6c7349e3a"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Defining the Oedometer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80cbec0-a5d5-4310-88a0-db99ec043b36",
   "metadata": {
    "id": "c80cbec0-a5d5-4310-88a0-db99ec043b36"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Oedometer:\n",
    "    def __init__(self, e_0: float = 1.00, C_c: float = 0.005, delta_epsilon: float = 0.0005,\n",
    "                 sigma_t: float = 1.00, max_n: int = 50, rand_epsilon:bool=False, **kwargs):\n",
    "        self.max_n = max_n\n",
    "\n",
    "        # Standardwerte als Listen setzen\n",
    "        self.e_0 = [e_0]\n",
    "        self.C_c = [C_c]\n",
    "        self.sigma_t = [sigma_t]\n",
    "        self.delta_epsilon = []\n",
    "        self.total_epsilon = [0]\n",
    "\n",
    "        # Initiale Listen für Berechnungen\n",
    "        self.sigma_t = [sigma_t]\n",
    "        self.delta_sigma = []\n",
    "        self.e_s = []\n",
    "        self.delta_epsilon = [delta_epsilon]\n",
    "\n",
    "        # Dynamische Zuweisung von kwargs, falls vorhanden\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):  # Nur vorhandene Attribute setzen\n",
    "                setattr(self, key, [value])\n",
    "\n",
    "        # Berechnungen durchführen\n",
    "        self.__calc_sigma_t_p1()\n",
    "\n",
    "        # Listenlängen anpassen\n",
    "        self.__adjust_list_lengths()\n",
    "        self.__calc_total_epsilon()\n",
    "\n",
    "    def __adjust_list_lengths(self):\n",
    "        \"\"\" Passt ALLE Listen-Attribute an `max_n` an. \"\"\"\n",
    "        attributes = ['e_0', 'C_c', 'delta_epsilon', 'sigma_t', 'sigma_t', 'delta_sigma', 'e_s']\n",
    "        for attr in attributes:\n",
    "            value_list = getattr(self, attr, [])\n",
    "            current_length = len(value_list)\n",
    "\n",
    "            if current_length > self.max_n:\n",
    "                setattr(self, attr, value_list[:self.max_n])  # Kürzen\n",
    "            elif current_length < self.max_n:\n",
    "                setattr(self, attr, value_list + [value_list[-1] if value_list else 0] * (self.max_n - current_length))  # Auffüllen\n",
    "\n",
    "    def __calc_total_epsilon(self):\n",
    "        for i in range(len(self.delta_epsilon)-1):\n",
    "            self.total_epsilon.append(self.total_epsilon[i] + self.delta_epsilon[i])\n",
    "\n",
    "    def __calc_e_s(self, sigma_t):\n",
    "        \"\"\" Berechnet `e_s` aus `sigma_t`. \"\"\"\n",
    "        e_s = (1 + self.e_0[0]) / self.C_c[0] * sigma_t\n",
    "        self.e_s.append(e_s)\n",
    "        return e_s\n",
    "\n",
    "    def __calc_sigma_t_p1(self):\n",
    "        \"\"\" Berechnet `sigma_t` und `delta_sigma` für die nächsten Schritte. \"\"\"\n",
    "        for i in range(self.max_n):  # -1, weil sigma_t bereits gesetzt ist\n",
    "            e_s = self.__calc_e_s(self.sigma_t[i])\n",
    "            delta_sigma = e_s * self.delta_epsilon[0]\n",
    "            sigma = self.sigma_t[i] + delta_sigma\n",
    "            self.sigma_t.append(sigma)\n",
    "            self.delta_sigma.append(delta_sigma)\n",
    "\n",
    "def plot_input():\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data_dict_raw['sigma_t'], data_dict_raw['delta_sigma'], marker='o', linestyle='-', label='Sigma_0 = 1')\n",
    "\n",
    "    # Formatting\n",
    "    plt.xlabel('sigma_t')\n",
    "    plt.ylabel('delta_simga')\n",
    "    plt.title('Sigma_0 in relation to Sigma_1')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P4zh-pBwwQSK",
   "metadata": {
    "id": "P4zh-pBwwQSK"
   },
   "source": [
    "The `Oedometer` class simulates the calculation of `delta_sigma` values based on various material parameters such as `sigma_t` (stress), `delta_epsilon` (strain), and others. The class provides methods to adjust list lengths and perform calculations that simulate geotechnical behavior.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Data Generation and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fb2661-f310-4b18-ab78-d819b4c9376b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9fb2661-f310-4b18-ab78-d819b4c9376b",
    "outputId": "4f21b8f0-7df7-4be9-e6be-18fec9b4713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Elemente delta_epsilon: 100\n",
      "Anzahl Elemente sigma_t: 100\n",
      "Anzahl Elemente delta_sigma: 100\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "\n",
    "oedo_para = {\n",
    "    'max_n': 1,\n",
    "    'e_0': 1.0,\n",
    "    'C_c': 0.005,\n",
    "    'total_epsilon': 0,\n",
    "    'e_s': 400.0\n",
    "}\n",
    "\n",
    "# Vorbereitung Tensoren\n",
    "sigma_t = np.random.choice(range(1, 1000), size=i, replace=False)\n",
    "delta_sigma = []\n",
    "delta_epsilon = np.repeat(np.array(np.float64(0.0005)), i)\n",
    "# delta_epsilon = np.random.uniform(0.0001, 0.001, size=i)\n",
    "\n",
    "for i in range(i):\n",
    "    oedo_para['sigma_t'] = sigma_t[i]\n",
    "    oedo_para['e_s'] = delta_epsilon[i]\n",
    "    oedo = Oedometer(**oedo_para)\n",
    "    delta_sigma.append(round(oedo.delta_sigma[0], 2))\n",
    "\n",
    "\n",
    "print('Anzahl Elemente delta_epsilon: ' + str(len(delta_epsilon)))\n",
    "print('Anzahl Elemente sigma_t: ' + str(len(sigma_t)))\n",
    "print('Anzahl Elemente delta_sigma: ' + str(len(delta_sigma)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pmfuh71rwZYg",
   "metadata": {
    "id": "Pmfuh71rwZYg"
   },
   "source": [
    "This part generates synthetic data for `sigma_t` (stress) and `delta_epsilon` (strain) to simulate the inputs. The class Oedometer is used to compute `delta_sigma` values from the generated data.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05dca2c-7485-48cd-ba46-c46330373129",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "f05dca2c-7485-48cd-ba46-c46330373129",
    "outputId": "cb67a5c3-77a5-4780-beac-84da94cbd0be"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### RawData"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "|    |   sigma_t |   e_s |\n",
       "|---:|----------:|------:|\n",
       "|  0 |       664 | 132.8 |\n",
       "|  1 |       486 |  97.2 |\n",
       "|  2 |       201 |  40.2 |\n",
       "|  3 |       871 | 174.2 |\n",
       "|  4 |       811 | 162.2 |\n",
       "|  5 |        71 |  14.2 |\n",
       "|  6 |       476 |  95.2 |\n",
       "|  7 |        94 |  18.8 |\n",
       "|  8 |       460 |  92   |\n",
       "|  9 |        54 |  10.8 |\n",
       "| 10 |       228 |  45.6 |\n",
       "| 11 |       861 | 172.2 |\n",
       "| 12 |       266 |  53.2 |\n",
       "| 13 |       751 | 150.2 |\n",
       "| 14 |       208 |  41.6 |\n",
       "| 15 |       641 | 128.2 |\n",
       "| 16 |       643 | 128.6 |\n",
       "| 17 |       989 | 197.8 |\n",
       "| 18 |       719 | 143.8 |\n",
       "| 19 |       718 | 143.6 |\n",
       "| 20 |       222 |  44.4 |\n",
       "| 21 |       646 | 129.2 |\n",
       "| 22 |       261 |  52.2 |\n",
       "| 23 |       671 | 134.2 |\n",
       "| 24 |       587 | 117.4 |\n",
       "| 25 |       132 |  26.4 |\n",
       "| 26 |       195 |  39   |\n",
       "| 27 |       356 |  71.2 |\n",
       "| 28 |        69 |  13.8 |\n",
       "| 29 |       351 |  70.2 |\n",
       "| 30 |       295 |  59   |\n",
       "| 31 |       254 |  50.8 |\n",
       "| 32 |       923 | 184.6 |\n",
       "| 33 |       591 | 118.2 |\n",
       "| 34 |       942 | 188.4 |\n",
       "| 35 |       499 |  99.8 |\n",
       "| 36 |       684 | 136.8 |\n",
       "| 37 |       972 | 194.4 |\n",
       "| 38 |       473 |  94.6 |\n",
       "| 39 |       639 | 127.8 |\n",
       "| 40 |       534 | 106.8 |\n",
       "| 41 |       683 | 136.6 |\n",
       "| 42 |       877 | 175.4 |\n",
       "| 43 |       726 | 145.2 |\n",
       "| 44 |       961 | 192.2 |\n",
       "| 45 |       613 | 122.6 |\n",
       "| 46 |       695 | 139   |\n",
       "| 47 |       687 | 137.4 |\n",
       "| 48 |       883 | 176.6 |\n",
       "| 49 |       441 |  88.2 |\n",
       "| 50 |        60 |  12   |\n",
       "| 51 |       272 |  54.4 |\n",
       "| 52 |       503 | 100.6 |\n",
       "| 53 |        39 |   7.8 |\n",
       "| 54 |       302 |  60.4 |\n",
       "| 55 |       526 | 105.2 |\n",
       "| 56 |       522 | 104.4 |\n",
       "| 57 |       271 |  54.2 |\n",
       "| 58 |       163 |  32.6 |\n",
       "| 59 |       600 | 120   |\n",
       "| 60 |       822 | 164.4 |\n",
       "| 61 |       798 | 159.6 |\n",
       "| 62 |        48 |   9.6 |\n",
       "| 63 |       186 |  37.2 |\n",
       "| 64 |       994 | 198.8 |\n",
       "| 65 |       197 |  39.4 |\n",
       "| 66 |       471 |  94.2 |\n",
       "| 67 |       860 | 172   |\n",
       "| 68 |       256 |  51.2 |\n",
       "| 69 |       621 | 124.2 |\n",
       "| 70 |       436 |  87.2 |\n",
       "| 71 |       575 | 115   |\n",
       "| 72 |       138 |  27.6 |\n",
       "| 73 |       967 | 193.4 |\n",
       "| 74 |       849 | 169.8 |\n",
       "| 75 |        53 |  10.6 |\n",
       "| 76 |       757 | 151.4 |\n",
       "| 77 |       996 | 199.2 |\n",
       "| 78 |       854 | 170.8 |\n",
       "| 79 |       949 | 189.8 |\n",
       "| 80 |        26 |   5.2 |\n",
       "| 81 |       650 | 130   |\n",
       "| 82 |       358 |  71.6 |\n",
       "| 83 |       953 | 190.6 |\n",
       "| 84 |       632 | 126.4 |\n",
       "| 85 |       593 | 118.6 |\n",
       "| 86 |       383 |  76.6 |\n",
       "| 87 |       470 |  94   |\n",
       "| 88 |       334 |  66.8 |\n",
       "| 89 |       817 | 163.4 |\n",
       "| 90 |       644 | 128.8 |\n",
       "| 91 |       903 | 180.6 |\n",
       "| 92 |       615 | 123   |\n",
       "| 93 |       930 | 186   |\n",
       "| 94 |       640 | 128   |\n",
       "| 95 |       866 | 173.2 |\n",
       "| 96 |       395 |  79   |\n",
       "| 97 |       813 | 162.6 |\n",
       "| 98 |       884 | 176.8 |\n",
       "| 99 |       202 |  40.4 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\n",
    "    'sigma_t' : sigma_t.tolist(),\n",
    "    'e_s' : delta_sigma,\n",
    "}\n",
    "\n",
    "# data = {\n",
    "# 'sigma_t' : [1,2,3,4,5],\n",
    "#     'delta_sigma' : [2,3,4,5,6],\n",
    "#     'delta_epsilon' : [3,5,7,9,11]\n",
    "# }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Markdown Headlin 'RawData'\n",
    "display(Markdown('### RawData'))\n",
    "display(Markdown(df.to_markdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cp26_ZYawkq2",
   "metadata": {
    "id": "cp26_ZYawkq2"
   },
   "source": [
    "Here, the raw data is converted into a pandas DataFrame and displayed as a Markdown table. This allows for easy inspection of the data before feeding it into the LSTM model.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qsjRsF4bDCxI",
   "metadata": {
    "id": "qsjRsF4bDCxI"
   },
   "outputs": [],
   "source": [
    "min_val_in = None\n",
    "max_val_in = None\n",
    "min_val_out = None\n",
    "max_val_out = None\n",
    "\n",
    "def min_max_normalize(tensor, input_tensor=True):\n",
    "    \"\"\"\n",
    "      Normalisiert einen Tensor anhand der globalen min_val und max_val.\n",
    "      \"\"\"\n",
    "    global min_val_in, max_val_in, min_val_out, max_val_out\n",
    "    if min_val_in is None and max_val_in is None and input_tensor:\n",
    "        min_val = torch.min(tensor)\n",
    "        max_val = torch.max(tensor)\n",
    "        min_val_in = min_val\n",
    "        max_val_in = max_val\n",
    "        print(min_val)\n",
    "        print(max_val)\n",
    "    elif min_val_out is None and max_val_out is None and not input_tensor:\n",
    "        min_val = torch.min(tensor)\n",
    "        max_val = torch.max(tensor)\n",
    "        min_val_out = min_val\n",
    "        max_val_out = max_val\n",
    "    elif input_tensor:\n",
    "        min_val = min_val_in\n",
    "        max_val = min_val_in\n",
    "    elif not input_tensor:\n",
    "        min_val = min_val_out\n",
    "        max_val = min_val_out\n",
    "              \n",
    "        \n",
    "    display(Markdown(f'### Skalierungseinheiten für {'Input' if input_tensor else 'Output'}: Min. = {min_val}, Max. = {max_val}'))\n",
    "    return (tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "def min_max_denormalize(tensor, input_tensor=True):\n",
    "    \"\"\"\n",
    "      Denormalisiert einen Tensor anhand der globalen min_val und max_val.\n",
    "      \"\"\"\n",
    "    if min_val_in is None and max_val_in is None and input_tensor:\n",
    "        print(\"Fehler: min_val und/oder max_val sind nicht gesetzt. Normalisierung muss zuerst durchgeführt werden.\")\n",
    "        return tensor # Gibt den ursprünglichen Tensor zurück, wenn nicht normalisiert werden kann\n",
    "    elif min_val_out is None and max_val_out is None and not input_tensor:\n",
    "        print(\"Fehler: min_val und/oder max_val sind nicht gesetzt. Normalisierung muss zuerst durchgeführt werden.\")\n",
    "        return tensor # Gibt den ursprünglichen Tensor zurück, wenn nicht normalisiert werden kann\n",
    "    if input_tensor:\n",
    "        min_val = min_val_in\n",
    "        max_val = max_val_in\n",
    "    else:\n",
    "        min_val = min_val_out\n",
    "        max_val = max_val_out\n",
    "    return tensor * (max_val - min_val) + min_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lYOajlZuOb0r",
   "metadata": {
    "id": "lYOajlZuOb0r"
   },
   "source": [
    "This function normalizes input tensors using the Min-Max scaling method. Normalization helps in improving the training stability by ensuring that all features are within the same scale.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Creating the Dataset for LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b39746-e5a5-4ad7-8a2e-941b6539639a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 58
    },
    "id": "86b39746-e5a5-4ad7-8a2e-941b6539639a",
    "outputId": "ce71cbc3-6624-41b5-8afe-07bc7a49da08"
   },
   "outputs": [],
   "source": [
    "def create_dataset(df, lookback=1, input_columns=None, output_columns=None, normalize=True):\n",
    "    \"\"\"\n",
    "    Erzeugt die Eingabe- und Ziel-Datensätze für ein LSTM.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): Der Eingabedatenrahmen.\n",
    "    lookback (int): Die Anzahl der vergangenen Zeitschritte, die als Eingabe dienen.\n",
    "    input_columns (list): Liste der Spaltennamen, die als Eingabewerte dienen.\n",
    "    output_columns (list): Liste der Spaltennamen, die als Zielwerte dienen.\n",
    "    normalize (bool): Ob die Eingabedaten normalisiert werden sollen.\n",
    "\n",
    "    Returns:\n",
    "    X (Tensor): Eingabedaten im Format (batch_size, seq_length, input_size).\n",
    "    y (Tensor): Zielwerte im Format (batch_size, output_size).\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    # Falls keine input_columns übergeben wurden, nehmen wir alle Spalten außer der letzten\n",
    "    if input_columns is None:\n",
    "        input_columns = df.columns[:-1].tolist()\n",
    "\n",
    "    # Falls keine output_columns übergeben wurden, nehmen wir die letzte(n) Spalte(n)\n",
    "    if output_columns is None:\n",
    "        output_columns = df.columns[-1:].tolist()  # Eine Liste mit der letzten Spalte\n",
    "\n",
    "    for i in range(len(df) - lookback):\n",
    "        # Wir nehmen 'lookback' Zeilen als eine Sequenz für die Eingabe\n",
    "        seq = df.iloc[i:i+lookback][input_columns].values\n",
    "        X.append(seq)\n",
    "\n",
    "        # Zielwert(e) ist (sind) der Wert(e) der output_columns nach dieser Sequenz\n",
    "        y_values = df.iloc[i+lookback][output_columns].values\n",
    "        y.append(y_values)\n",
    "\n",
    "    # Umwandlung in Tensoren\n",
    "    X_tensor = torch.tensor(np.array(X), dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(np.array(y), dtype=torch.float32)\n",
    "\n",
    "    # Falls Normalisierung gewünscht ist, wenden wir min-max Normalisierung an\n",
    "    if normalize:\n",
    "        X = min_max_normalize(X_tensor)\n",
    "        y = min_max_normalize(y_tensor, False)\n",
    "    else:\n",
    "        X = X_tensor\n",
    "        y = y_tensor\n",
    "    return X, y\n",
    "\n",
    "X, y = create_dataset(df, lookback=1, normalize=normalize, input_columns=['sigma_t'], output_columns=['e_s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qBsMWCXnxC1L",
   "metadata": {
    "id": "qBsMWCXnxC1L"
   },
   "source": [
    "This function creates the input-output pairs for the LSTM model. The `lookback` parameter determines how many previous time steps are used to predict the next value. The function normalizes the input data if the `normalize` flag is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8133f1-409f-4879-a685-ec141fb4189f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d8133f1-409f-4879-a685-ec141fb4189f",
    "outputId": "b9277dad-e1a4-4260-a060-6a922954a17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X_train: torch.Size([66, 1, 1]) y_train: torch.Size([66, 1])\n",
      "  X_test:  torch.Size([33, 1, 1]) y_test:  torch.Size([33, 1])\n"
     ]
    }
   ],
   "source": [
    "# --- Aufteilen in Training (2/3) und Test (1/3) ---\n",
    "train_size = int(X.shape[0] * 2/3)\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size].view(-1, 1)  # als (batch_size, 1)\n",
    "X_test  = X[train_size:]\n",
    "y_test  = y[train_size:].view(-1, 1)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"  X_test: \", X_test.shape,  \"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "MrCd2SbaLZBV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MrCd2SbaLZBV",
    "outputId": "8e99d647-e778-42a4-c448-9db061f21a97"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Trainingsdaten (Normalisierte Input Parameter)\n",
       "\n",
       "| Index | Input (sigma_t) | Output (e_s) |\n",
       "|--|----------------|-------------|\n",
       "| 0 | 664.0 | 97.2 |\n",
       "| 1 | 486.0 | 40.2 |\n",
       "| 2 | 201.0 | 174.2 |\n",
       "| 3 | 871.0 | 162.2 |\n",
       "| 4 | 811.0 | 14.2 |\n",
       "| 5 | 71.0 | 95.2 |\n",
       "| 6 | 476.0 | 18.8 |\n",
       "| 7 | 94.0 | 92.0 |\n",
       "| 8 | 460.0 | 10.8 |\n",
       "| 9 | 54.0 | 45.6 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler: min_val und/oder max_val sind nicht gesetzt. Normalisierung muss zuerst durchgeführt werden.\n",
      "Fehler: min_val und/oder max_val sind nicht gesetzt. Normalisierung muss zuerst durchgeführt werden.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'delta_epsilon'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Rohdaten für den Vergleich extrahieren (entspricht den Trainingsdaten)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Die Trainingsdaten sind die ersten 'train_size' Samples der Input-Output-Paare.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Wir müssen die entsprechenden originalen Werte aus dem 'data' Dictionary holen.\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Die Inputs X_train[i] stammen aus den Originaldaten bei Index i.\u001b[39;00m\n\u001b[32m     19\u001b[39m original_sigma_t_input = data[\u001b[33m'\u001b[39m\u001b[33msigma_t\u001b[39m\u001b[33m'\u001b[39m][:train_size]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m original_delta_epsilon_input = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdelta_epsilon\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:train_size]\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Die Outputs y_train[i] stammen aus den Originaldaten bei Index i + lookback.\u001b[39;00m\n\u001b[32m     23\u001b[39m original_delta_sigma_output = data[\u001b[33m'\u001b[39m\u001b[33mdelta_sigma\u001b[39m\u001b[33m'\u001b[39m][lookback : train_size + lookback]\n",
      "\u001b[31mKeyError\u001b[39m: 'delta_epsilon'"
     ]
    }
   ],
   "source": [
    "num_rows = 10  # Anzahl der Zeilen, die in den Tabellen angezeigt werden sollen\n",
    "lookback = 1 # Stelle sicher, dass dies deinem tatsächlichen lookback-Wert entspricht\n",
    "\n",
    "# Trainingsdaten anzeigen (Normalisiert) - Hier passen Input und Output zusammen, wie vom create_dataset erstellt\n",
    "display(dict_to_markdown_table({\n",
    "    'Input (sigma_t)': [X_train[i].squeeze().tolist() for i in range(min(num_rows, X_train.shape[0]))],\n",
    "    'Output (e_s)': y_train[:min(num_rows, y_train.shape[0])].squeeze().tolist()\n",
    "}, title=\"Trainingsdaten (Normalisierte Input Parameter)\", include_index=True))\n",
    "\n",
    "# Trainingsdaten denormalisiert anzeigen\n",
    "X_train_denormalized = min_max_denormalize(X_train)\n",
    "y_train_denormalized = min_max_denormalize(y_train, False)\n",
    "\n",
    "# Rohdaten für den Vergleich extrahieren (entspricht den Trainingsdaten)\n",
    "# Die Trainingsdaten sind die ersten 'train_size' Samples der Input-Output-Paare.\n",
    "# Wir müssen die entsprechenden originalen Werte aus dem 'data' Dictionary holen.\n",
    "\n",
    "# Die Inputs X_train[i] stammen aus den Originaldaten bei Index i.\n",
    "original_sigma_t_input = data['sigma_t'][:train_size]\n",
    "original_delta_epsilon_input = data['delta_epsilon'][:train_size]\n",
    "\n",
    "# Die Outputs y_train[i] stammen aus den Originaldaten bei Index i + lookback.\n",
    "original_delta_sigma_output = data['delta_sigma'][lookback : train_size + lookback]\n",
    "\n",
    "\n",
    "# Listen für die detaillierte denormalisierte Tabelle\n",
    "denormalized_inputs_list = []\n",
    "denormalized_outputs_list = []\n",
    "input_original_indices = [] # Um die Rohdaten-Indizes für Inputs zu speichern\n",
    "output_original_indices = [] # Um die Rohdaten-Indizes für Outputs zu speichern\n",
    "input_verification_diff = []\n",
    "output_verification_diff = []\n",
    "\n",
    "for i in range(min(num_rows, X_train_denormalized.shape[0])):\n",
    "    # Denormalisierte Werte\n",
    "    denorm_sigma_t = X_train_denormalized[i].squeeze()[0].item()\n",
    "    denorm_delta_epsilon = X_train_denormalized[i].squeeze()[1].item()\n",
    "    denorm_delta_sigma_output = y_train_denormalized[i].squeeze().item()\n",
    "\n",
    "    denormalized_inputs_list.append([denorm_sigma_t, denorm_delta_epsilon])\n",
    "    denormalized_outputs_list.append(denorm_delta_sigma_output)\n",
    "\n",
    "    # Rohdaten-Index für den Input: i\n",
    "    input_index = i\n",
    "    input_original_indices.append(input_index)\n",
    "    original_sigma_t = data['sigma_t'][input_index]\n",
    "    original_delta_epsilon = data['delta_epsilon'][input_index]\n",
    "    diff_sigma_t = denorm_sigma_t - original_sigma_t\n",
    "    diff_delta_epsilon = denorm_delta_epsilon - original_delta_epsilon\n",
    "    input_verification_diff.append(f\"sigma_t Diff: {diff_sigma_t:.4f}, delta_epsilon Diff: {diff_delta_epsilon:.6f}\")\n",
    "\n",
    "\n",
    "    # Rohdaten-Index für den Output: i + lookback\n",
    "    output_index = i + lookback\n",
    "    output_original_indices.append(output_index)\n",
    "    original_delta_sigma = data['delta_sigma'][output_index]\n",
    "    diff_delta_sigma = denorm_delta_sigma_output - original_delta_sigma\n",
    "    output_verification_diff.append(f\"delta_sigma Diff: {diff_delta_sigma:.4f}\")\n",
    "\n",
    "\n",
    "display(Markdown('## Hier wird geprüft, ob das normalisieren bzw. denormalisieren funktioniert hat.'))\n",
    "\n",
    "# Anzeige der denormalisierten Trainingsdaten mit Input-Verifizierung\n",
    "# Wir fügen die Rohdaten-Indizes für Input und Output zur besseren Übersicht hinzu.\n",
    "display(dict_to_markdown_table({\n",
    "    'Input Rohdaten Index': input_original_indices,\n",
    "    'Input (sigma_t, delta_epsilon)': denormalized_inputs_list,\n",
    "    'Denormalisierung Input Check (Diff zu Original)': input_verification_diff,\n",
    "    'Output Rohdaten Index': output_original_indices,\n",
    "    }, title=\"Trainingsdaten (Denormalisiert) mit Checks\", include_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fkt6OwKTxjXC",
   "metadata": {
    "id": "Fkt6OwKTxjXC"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "## LSTM Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4faff38-40ab-485b-a758-7eb316c7e8a7",
   "metadata": {
    "id": "e4faff38-40ab-485b-a758-7eb316c7e8a7"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6FbWR9KxsEL",
   "metadata": {
    "id": "f6FbWR9KxsEL"
   },
   "source": [
    "This is the definition of the LSTM model. It uses one LSTM layer followed by a fully connected layer. The model learns from the input sequence and makes a prediction about the output value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26b13fa-21ad-4800-aea6-6db1bbeef8d3",
   "metadata": {
    "id": "e26b13fa-21ad-4800-aea6-6db1bbeef8d3"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "input_size = X_train.shape[2]  # Anzahl der Input-Features\n",
    "hidden_size = 32  # Die Anzahl der Neuronen im LSTM\n",
    "num_layers = 10  # Anzahl der LSTM-Schichten\n",
    "output_size = 1  # Output ist eine einzelne Zahl (z. B. Vorhersage)\n",
    "\n",
    "# Modell, Loss und Optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = torch.nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r29vWyV3xwBm",
   "metadata": {
    "id": "r29vWyV3xwBm"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Model Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446ada0-bbee-46c2-9a87-253f6c324e83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a446ada0-bbee-46c2-9a87-253f6c324e83",
    "outputId": "ef499d31-9d98-46d8-dc25-378b94e49f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Train Loss: 12777.865530, Value Loss: 843339.124987\n",
      "Epoch 20/1000, Train Loss: 12223.459895, Value Loss: 806748.353050\n",
      "Epoch 30/1000, Train Loss: 11879.480138, Value Loss: 784045.689123\n",
      "Epoch 40/1000, Train Loss: 11585.961951, Value Loss: 764673.488794\n",
      "Epoch 50/1000, Train Loss: 11314.179797, Value Loss: 746735.866588\n",
      "Epoch 60/1000, Train Loss: 11055.343249, Value Loss: 729652.654457\n",
      "Epoch 70/1000, Train Loss: 10805.783687, Value Loss: 713181.723325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Frühzeitige Beendigung: Überwache den Verlust auf den Validierungsdaten\n",
    "best_val_loss = float('inf')  # Initialer hoher Verlust\n",
    "patience = 100  # Anzahl der Epochen ohne Verbesserung, bevor das Training gestoppt wird\n",
    "patience_counter = 10  # Zähler für die Anzahl der Epochen ohne Verbesserung\n",
    "\n",
    "# Liste zum Speichern der Loss-Werte\n",
    "losses = []\n",
    "\n",
    "# Batches erstellen\n",
    "batch_size = 1\n",
    "\n",
    "# Erstelle TensorDataset und DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_test, y_test)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Improvement Block Aktivierung (True/False)\n",
    "improvement_block = False\n",
    "\n",
    "# Training\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Setze das Modell in den Trainingsmodus\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Schleife über Batches\n",
    "    for i, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Modellvorhersage\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)  # Verlust auf den Trainingsdaten\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Verlust sammeln\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Durchschnittlichen Trainingsverlust berechnen\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    losses.append(avg_train_loss)\n",
    "\n",
    "    # Frühzeitige Beendigung (improvement block) aktivieren\n",
    "    if improvement_block:\n",
    "        # Validierungsverlust berechnen\n",
    "        model.eval()  # Modell in den Evaluierungsmodus setzen\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_batch_val, y_batch_val in val_dataloader:\n",
    "                val_outputs = model(x_batch_val)\n",
    "                loss = criterion(val_outputs, y_batch_val)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "        # Frühzeitige Beendigung überwachen\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0  # Reset der Geduld\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Wenn keine Verbesserung erfolgt, abbrechen\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Frühzeitige Beendigung nach {epoch + 1} Epochen wegen fehlender Verbesserung.\")\n",
    "            break\n",
    "\n",
    "        # Ausgabe der Verlustinformationen\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}')\n",
    "    else:\n",
    "        # Ausgabe der Verlustinformationen ohne Validierung\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.6f}, Value Loss: {running_loss:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S8MwWIb9x234",
   "metadata": {
    "id": "S8MwWIb9x234"
   },
   "source": [
    "This section implements the training loop with early stopping. Early stopping monitors the validation loss and stops the training process if the loss does not improve after a set number of epochs (`patience`).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Loss Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c2bd79-ee9e-4b97-a744-ee65cbe67db5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "40c2bd79-ee9e-4b97-a744-ee65cbe67db5",
    "outputId": "bbc7a5b2-1c2c-422c-df54-7dcb47f9b6d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot der Losskurve\n",
    "plt.plot(range(len(losses)), losses, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YwwI0U0lx8Fc",
   "metadata": {
    "id": "YwwI0U0lx8Fc"
   },
   "source": [
    "This code generates a plot of the training loss over epochs. Visualizing the loss curve is important for diagnosing model convergence and training performance.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Residual and Prediction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8ebf5-c49c-45b4-846c-b14c03c3bc3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddb8ebf5-c49c-45b4-846c-b14c03c3bc3e",
    "outputId": "2c452650-fb35-4f96-f155-517431761253",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_residuals(y_true, y_pred, max_points=None):\n",
    "    \"\"\"\n",
    "    Plots the residuals (y_pred - y_true) for each sample.\n",
    "    If max_points is set, only the first max_points residuals are shown.\n",
    "    Converts lists to numpy arrays for subtraction.\n",
    "    \"\"\"\n",
    "    # Ensure numpy arrays\n",
    "    y_true_arr = np.array(y_true, dtype=float)\n",
    "    y_pred_arr = np.array(y_pred, dtype=float)\n",
    "    residuals = y_pred_arr - y_true_arr\n",
    "\n",
    "    if max_points is not None:\n",
    "        residuals = residuals[:max_points]\n",
    "    plt.figure()\n",
    "    plt.scatter(range(len(residuals)), residuals)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Residual (Prediction - Real)')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pred_vs_real(y_true, y_pred, max_points=None):\n",
    "    \"\"\"\n",
    "    Plots predicted vs. real values.\n",
    "    If max_points is set, only the first max_points points are plotted.\n",
    "    Converts lists to numpy arrays for plotting.\n",
    "    \"\"\"\n",
    "    # Ensure numpy arrays\n",
    "    y_true_arr = np.array(y_true, dtype=float)\n",
    "    y_pred_arr = np.array(y_pred, dtype=float)\n",
    "\n",
    "    if max_points is not None:\n",
    "        y_true_arr = y_true_arr[:max_points]\n",
    "        y_pred_arr = y_pred_arr[:max_points]\n",
    "    plt.figure()\n",
    "    plt.plot(y_true_arr, label='Real')\n",
    "    plt.plot(y_pred_arr, label='Predicted')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Prediction vs. Real')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "overfitting_check = True\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if overfitting_check:\n",
    "        X = X_train\n",
    "        y = y_train\n",
    "    else:\n",
    "        X = X_test\n",
    "        y = y_test\n",
    "    y_pred_unsorted = min_max_denormalize(model(X)).tolist() #[1:]\n",
    "    y_true_unsorted = min_max_denormalize(y).tolist() #[:-1]\n",
    "\n",
    "    # sorted_indices = np.argsort(y_true_unsorted)\n",
    "\n",
    "    y_pred = y_pred_unsorted#[sorted_indices]\n",
    "    y_true = y_true_unsorted#[sorted_indices]\n",
    "\n",
    "print(y_pred_unsorted)\n",
    "print('TEST')\n",
    "print(min_max_denormalize(y).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gPaTCRizyMfO",
   "metadata": {
    "id": "gPaTCRizyMfO"
   },
   "source": [
    "This function plots the residuals (i.e., the difference between predicted and true values) to check how well the model is fitting the data. A similar function `plot_pred_vs_real` is used to visualize the predicted vs real values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0f670-e99d-483f-8965-1287c8da2667",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "07e0f670-e99d-483f-8965-1287c8da2667",
    "outputId": "a1c2a134-6f65-4724-c24b-2b37060c04c5"
   },
   "outputs": [],
   "source": [
    "plot_residuals(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca153a0-b827-427b-b893-3d27c8cf5d3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "aca153a0-b827-427b-b893-3d27c8cf5d3a",
    "outputId": "03fc8250-6196-4067-92d6-a65367a955c3"
   },
   "outputs": [],
   "source": [
    "plot_pred_vs_real(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07bd80-b73a-42d4-9f93-9cf829e0a993",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "ab07bd80-b73a-42d4-9f93-9cf829e0a993",
    "outputId": "87fecdf7-a205-4789-edfb-e57b8eac8174",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_print = {\n",
    "    'sigma_t': data['sigma_t'][1+len(y_true):],\n",
    "    'delta_epsilon': data['delta_epsilon'][1+len(y_true):],\n",
    "    'delta_sigma': data['delta_sigma'][1+len(y_true):],\n",
    "    'delta_sigma_pred': y_pred.tolist(),\n",
    "    'true - pred': [data['sigma_t'][len(y_true):][i] - y_pred.tolist()[i] for i in range(len(y_true.tolist()))]\n",
    "}\n",
    "\n",
    "\n",
    "# Print a markdown table\n",
    "display(pd.DataFrame(data_print).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rXuRwIvEyPWo",
   "metadata": {
    "id": "rXuRwIvEyPWo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Final Model Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m2GmB0hcXtpM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "m2GmB0hcXtpM",
    "outputId": "b4702e6e-ef2a-4b86-b539-5a9c77195ecd"
   },
   "outputs": [],
   "source": [
    "def predict_oedometer(model, sigma_t_input, delta_epsilon_input, normalize=True):\n",
    "    \"\"\"\n",
    "    Macht eine Prognose für delta_sigma basierend auf sigma_t und delta_epsilon\n",
    "    unter Berücksichtigung von Normalisierung und der benötigten Tensor-Shape.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Das trainierte LSTM-Modell.\n",
    "        sigma_t_input (float): Der Eingabewert für sigma_t.\n",
    "        delta_epsilon_input (float): Der Eingabewert für delta_epsilon.\n",
    "        normalize (bool): Gibt an, ob der Input normalisiert werden soll.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Ein Tuple mit (denormalisierte_prognose, wahrer_delta_sigma_wert),\n",
    "               wobei der wahre Wert aus der Oedometer-Klasse ermittelt wird.\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = torch.tensor([[sigma_t_input, delta_epsilon_input]], dtype=torch.float32) # Shape (1, 1, 2)\n",
    "\n",
    "    # Optional Normalisierung anwenden\n",
    "    if normalize:\n",
    "        temp_tensor = torch.tensor([[sigma_t_input, delta_epsilon_input]], dtype=torch.float32).unsqueeze(0) # Shape (1, 1, 2)\n",
    "        normalized_input = min_max_normalize(temp_tensor, True)\n",
    "        input_tensor = normalized_input.squeeze(0) # Shape wieder (1, 1, 2)\n",
    "    else:\n",
    "         # Auch wenn nicht normalisiert wird, stellen wir sicher, dass die Dimensionen korrekt sind\n",
    "        input_tensor = input_tensor.unsqueeze(0) # Shape (1, 1, 2)\n",
    "\n",
    "\n",
    "    # Setze das Modell in den Evaluierungsmodus\n",
    "    model.eval()\n",
    "\n",
    "    # Mache die Prognose ohne Gradientenberechnung\n",
    "    with torch.no_grad():\n",
    "        prediction = min_max_denormalize(model(input_tensor))\n",
    "\n",
    "    predicted_delta_sigma = prediction.item() # Konvertiere den Tensor zu einem Python-Float\n",
    "\n",
    "    # Ermittle den wahren Wert aus der Oedometer-Klasse\n",
    "    oedo_para_prediction = {\n",
    "        'max_n': 1,\n",
    "        'e_0': 1.0,\n",
    "        'C_c': 0.005,\n",
    "        'sigma_t': sigma_t_input, # Der gegebene Input sigma_t\n",
    "        'delta_epsilon': delta_epsilon_input, # Der gegebene Input delta_epsilon\n",
    "        'total_epsilon': 0, # Wird für die delta_sigma Berechnung im ersten Schritt nicht benötigt\n",
    "        'e_s': 400.0 # Wird für die delta_sigma Berechnung im ersten Schritt nicht benötigt\n",
    "    }\n",
    "    oedo_prediction = Oedometer(**oedo_para_prediction)\n",
    "    # Der wahre delta_sigma Wert ist der erste Wert in der delta_sigma Liste der Oedometer-Instanz\n",
    "    true_delta_sigma = oedo_prediction.delta_sigma[0]\n",
    "\n",
    "\n",
    "    return predicted_delta_sigma, true_delta_sigma\n",
    "\n",
    "\n",
    "example_sigma_t_input = 1\n",
    "example_delta_epsilon_input = 0.0005\n",
    "\n",
    "# Mache die Prognose\n",
    "predicted_delta_sigma, true_delta_sigma = predict_oedometer(\n",
    "    model,\n",
    "    example_sigma_t_input,\n",
    "    example_delta_epsilon_input,\n",
    "    normalize=normalize\n",
    ")\n",
    "\n",
    "# Berechne die Differenz\n",
    "difference = predicted_delta_sigma - true_delta_sigma\n",
    "\n",
    "# Anzeige der Ergebnisse im Markdown-Format\n",
    "display(Markdown(\"### Prognoseergebnis\"))\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "| Parameter             | Wert (Rohdaten) |\n",
    "|-----------------------|-----------------|\n",
    "| Eingabe sigma_t       | {example_sigma_t_input:.4f}   |\n",
    "| Eingabe delta_epsilon | {example_delta_epsilon_input:.6f}   |\n",
    "| Prognostizierte delta_sigma | {predicted_delta_sigma:.4f}   |\n",
    "| Wahrer delta_sigma (Oedometer) | {true_delta_sigma:.4f}   |\n",
    "| Differenz (Prognose - Wahr) | {difference:.4f}   |\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z8ltkwqPyT3b",
   "metadata": {
    "id": "Z8ltkwqPyT3b"
   },
   "source": [
    "This final section makes a prediction using the trained LSTM model and compares the predicted value with the true value calculated using the `Oedometer` class. The results are displayed in a Markdown table for easy inspection."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
