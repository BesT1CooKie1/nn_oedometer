{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202376a2a307e3c2",
   "metadata": {},
   "source": [
    "# Vorhersage des Ödometerversuches implementiert mit PINA\n",
    "Ziel war die Implementierung eines neuronalen Netzwerks zur Modellierung des Ödometerversuchs. Dabei wurden gegebene Input-Parameter verarbeitet, um Output-Parameter vorherzusagen. Die physikalischen Rahmenbedingungen wurden zunächst auf Null gesetzt, sodass das Modell ausschließlich auf der KI-basierten Struktur arbeitet, ohne physikalische Optimierungen durch Physical Informed Neural Networks (PINNs).\n",
    "<br>\n",
    "Diese grundlegende Umsetzung bildet die Basis für weiterführende Optimierungen, wie die Integration physikalischer Gesetzmäßigkeiten, die jedoch nicht Teil des initialen Arbeitsauftrags waren.\n",
    "\n",
    "### Was ist PINA?\n",
    "PINA ist eine Open-Source-Python-Bibliothek, die eine intuitive Schnittstelle zur Lösung von Differentialgleichungen bietet, indem sie Physik-informierte Neuronale Netze (PINNs), Neuronale Operatoren (NOs) oder eine Kombination aus beiden verwendet. Basierend auf PyTorch und PyTorch Lightning ermöglicht PINA die formale Darstellung spezifischer (differentieller) Probleme und deren Lösung mittels neuronaler Netze.<br><br>\n",
    "<strong>Hauptmerkmale von PINA:</strong>\n",
    "\n",
    "- <span style=\"color:gray;\"><i>Problemformulierung: Ermöglicht die Übersetzung mathematischer Gleichungen in Python-Code, um das Differentialproblem zu definieren.</i></span>\n",
    "    - <small><i>→ In diesem Arbeitsauftrag nicht notwendig, da das neuronale Netzwerk ohne physikalische Gesetzmäßigkeiten trainiert wurde.</i></small>\n",
    "- Modelltraining: Bietet Werkzeuge zum Training neuronaler Netze zur Lösung des definierten Problems.\n",
    "- Lösungsauswertung: Erlaubt die Visualisierung und Analyse der approximierten Lösungen.\n",
    "\n",
    "<small><i>Hinweis: Die physikalische Modellierung und die Einbindung von Differentialgleichungen zur Optimierung des Netzwerks (z. B. mittels PINNs) war nicht Teil dieses Arbeitsauftrags, könnte aber in einem späteren Schritt ergänzt werden.</i></small>\n",
    "## Grundlagen\n",
    "In diesem Notebook wird der Ödometerversuch <strong>ohne</strong> Randbedingungen betrachtet. Es werden vorberechnetet Daten aus der Exceltabelle `files/oedometer/oedo_trainingsdata.xlsx` verwendet.<br>\n",
    "#### Das Problem ist wie folgt definiert:\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "    \\sigma_{t+1} & = & \\sigma_{t}+\\Delta\\sigma \\\\ \\\\\n",
    "    \\Delta\\sigma & = & E_s\\cdot \\Delta\\epsilon \\\\ \n",
    "    E_s & = & \\frac{1+e_0}{C_c} \\cdot \\sigma_t\n",
    "\\end{array}\n",
    "\\hspace{2cm}\n",
    "\\begin{array}{l}\n",
    "    \\textbf{Annahmen:} \\\\ \\\\\n",
    "    \\text{Startwert d. Iteration: } \\sigma_0 = 1,00 \\\\ \n",
    "    e_0 = 1,00 \\\\ \n",
    "    C_c = 0,005 \\\\\n",
    "    \\Delta\\epsilon = 0,0005\n",
    "\\end{array}\n",
    "$$\n",
    "<div = style=\"text-align: center;\">\n",
    "    <img alt=\"Problem Oedometer Preview\" src=\"./graph/problem_preview.png\" width=\"50%\" height=auto>\n",
    "</div>\n",
    "\n",
    "<br> \n",
    "\n",
    "Um das PINA-Model zu testen werden wir folgende vorberechnete Werte verwenden: `Input` { $\\sigma_t$ ; $\\Delta\\epsilon$ }, `Output` { $\\sigma_{t+1}$ }.\n",
    "<br>\n",
    "### Variablendeklaration\n",
    "- $\\sigma_t$ = `sigma_0`\n",
    "- $\\Delta\\epsilon$ = `delta_epsilon`\n",
    "- $\\sigma_{t+1}$ = `sigma_1`\n",
    "## Einstellungen und Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ab565a-fc02-41df-89e3-9888204d845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Debugger: Aktiviert\n",
    "debug_mode = True\n",
    "# Normalisierung der Daten: Deaktiviert\n",
    "normalize_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccebd6-ea34-4979-a87a-59aec6f551e9",
   "metadata": {},
   "source": [
    "## Laden der Daten aus `oedo_trainingsdata.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649daf452361b99a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.087047Z",
     "start_time": "2025-03-12T08:30:30.555114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Geladene Exceldaten\n",
      "{'sigma_0': array([ 1.        ,  1.2       ,  1.44      ,  1.728     ,  2.0736    ,\n",
      "        2.48832   ,  2.985984  ,  3.5831808 ,  4.29981696,  5.15978035,\n",
      "        6.19173642,  7.43008371,  8.91610045, 10.69932054, 12.83918465,\n",
      "       15.40702157, 18.48842589, 22.18611107, 26.62333328, 31.94799994]), 'delta_epsilon': array([0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "       0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "       0.0005, 0.0005, 0.0005, 0.0005]), 'sigma_1': array([0.2       , 0.24      , 0.288     , 0.3456    , 0.41472   ,\n",
      "       0.497664  , 0.5971968 , 0.71663616, 0.85996339, 1.03195607,\n",
      "       1.23834728, 1.48601674, 1.78322009, 2.13986411, 2.56783693,\n",
      "       3.08140431, 3.69768518, 4.43722221, 5.32466666, 6.38959999])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy.integrals.heurisch import components\n",
    "\n",
    "file_path = \"files/oedometer/oedo_trainingsdata.xlsx\"\n",
    "sheet_name = \"Res\"\n",
    "selected_columns = [1, 3, 5] # Spaltenauswahl Spalte B, D und E\n",
    "row_start_range = 0\n",
    "\n",
    "def extract_excel(file_path, sheet_name, selected_columns, row_start_range):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Dynamische Ermittlung der letzten Zeile mit Daten\n",
    "    row_start_range = 0  # Startet bei Zeile 6 (0-basiert)\n",
    "    row_end_range = df.dropna(how=\"all\").last_valid_index() + 1  # Letzte Zeile mit Daten\n",
    "        \n",
    "    # Daten extrahieren\n",
    "    data_subset = df.iloc[row_start_range:row_end_range, selected_columns]\n",
    "    data_dict = {col: np.array(data_subset[col]) for col in data_subset.columns}\n",
    "    \n",
    "    if debug_mode:\n",
    "        print('‼️Geladene Exceldaten')\n",
    "        print(data_dict)\n",
    "    \n",
    "    # Daten als dict speichern\n",
    "    return data_dict\n",
    "\n",
    "data_dict = extract_excel(file_path, sheet_name, selected_columns, row_start_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb386144-1aae-4b43-aeb1-c3b715d7eac2",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "\n",
    "## Daten normalisieren\n",
    "Die Normalisierung von Daten für neuronale Netze bedeutet, dass Eingabedaten auf eine vergleichbare Skala gebracht werden, um das Training stabiler und effizienter zu machen. Hier verwendete Methode:\n",
    "- Min-Max-Skalierung: Werte auf einen Bereich (0 bis 1) bringen.  <i class=\"fa fa-info\"> [Wiki](https://en.wikipedia.org/wiki/Feature_scaling#Methods)</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd8f39a-6d82-480e-a011-2e432797803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️ Es wurde keine Normalisierung der Werte vorgenommen.\n"
     ]
    }
   ],
   "source": [
    "if normalize_data:\n",
    "    data_dict.update({'sigma_0_raw': data_dict.pop('sigma_0')})\n",
    "    data_dict.update({'sigma_1_raw': data_dict.pop('sigma_1')})\n",
    "    \n",
    "    sigma_0_min, sigma_0_max = data_dict['sigma_0_raw'].min(), data_dict['sigma_0_raw'].max()\n",
    "    sigma_1_min, sigma_1_max = data_dict['sigma_1_raw'].min(), data_dict['sigma_1_raw'].max()\n",
    "    \n",
    "    # Min-Max-Normalisierung\n",
    "    data_dict['sigma_0'] = (data_dict['sigma_0_raw'] - sigma_0_min) / (sigma_0_max - sigma_0_min)\n",
    "    data_dict['sigma_1'] = (data_dict['sigma_1_raw'] - sigma_1_min) / (sigma_1_max - sigma_1_min)\n",
    "    print('‼️Tabellenwerte des Oedometerversuches normalisiert.')\n",
    "else:\n",
    "    print('‼️ Es wurde keine Normalisierung der Werte vorgenommen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d182c1ff77877a1",
   "metadata": {},
   "source": [
    "## **Datenvorbereitung für PINA mit LabelTensor**\n",
    "In diesem Code werden die Eingabedaten aus `data_dict` als **LabelTensor** gespeichert, um sie strukturiert und mit benannten Dimensionen für das neuronale Netz in PINA bereitzustellen.  \n",
    "\n",
    "- `sigma_0_train`, `delta_epsilon_train` und `sigma_1_train` werden als **einzelne beschriftete Tensoren** erstellt.  \n",
    "- `input_points_combined` kombiniert `sigma_0` und `delta_epsilon` in einem **2D-Tensor** für das Training.  \n",
    "- `LabelTensor` erleichtert die Nutzung der Daten in PINA, indem es Variablen klar zuordnet und mit physischen Größen verknüpft.\n",
    "\n",
    "**Mehr zu `LabelTensor`:**  \n",
    "[PINA Documentation – LabelTensor](https://mathlab.github.io/PINA/_rst/label_tensor.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506469cd2477431e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.150519Z",
     "start_time": "2025-03-12T08:30:31.125143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Data Loaded\n",
      " sigma_0: torch.Size([20, 1])\n",
      " delta_epsilon: torch.Size([20, 1])\n",
      " sigma_0 und delta_epsilon combined: torch.Size([20, 2])\n",
      " sigma_1: torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pina.utils import LabelTensor\n",
    "from torch import tensor\n",
    "\n",
    "# Beispiel-Daten\n",
    "sigma_0_train = LabelTensor(tensor(data_dict['sigma_0'], dtype=torch.float).unsqueeze(-1), ['sigma_0'])\n",
    "delta_epsilon_train = LabelTensor(tensor(data_dict['delta_epsilon'], dtype=torch.float).unsqueeze(-1), ['delta_epsilon'])\n",
    "sigma_1_train = LabelTensor(tensor(data_dict['sigma_1'], dtype=torch.float).unsqueeze(-1), ['sigma_1'])\n",
    "\n",
    "# Kombinieren der Trainingsdaten (Verwendung von 'np.column_stack' für bessere Performance)\n",
    "input_points_combined = LabelTensor(torch.tensor(np.column_stack([data_dict['sigma_0'], data_dict['delta_epsilon']]), dtype=torch.float), ['sigma_0', 'delta_epsilon'])\n",
    "\n",
    "if debug_mode:\n",
    "    print('‼️Data Loaded')\n",
    "    print(f' sigma_0: {sigma_0_train.size()}')\n",
    "    print(f' delta_epsilon: {delta_epsilon_train.shape}')\n",
    "    print(f' sigma_0 und delta_epsilon combined: {input_points_combined.size()}')\n",
    "    print(f' sigma_1: {sigma_1_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8c6ec-bac1-4d00-83cb-63b178a72be6",
   "metadata": {},
   "source": [
    "### **Definition eines einfachen PINN-Problems in PINA**  \n",
    "Dieser Code definiert ein **Physics-Informed Neural Network (PINN)**-Problem mithilfe der PINA-Bibliothek.  \n",
    " \n",
    "- **Klassenstruktur (`SimpleODE`)**: Erbt von `AbstractProblem` und spezifiziert die Eingabe- und Ausgabevariablen basierend auf `LabelTensor`.\n",
    "    - [PINA-Dokumentation - AbstractProblem](https://mathlab.github.io/PINA/_rst/problem/abstractproblem.html) \n",
    "- **Definitionsbereich (`domain`)**: Der Wertebereich der Eingabevariablen (`sigma_0`, `delta_epsilon`) wird als `CartesianDomain` festgelegt.\n",
    "    - **Hinweis:** `domain` muss immer definiert sein, selbst wenn sie nicht direkt zur Datengenerierung verwendet wird.  \n",
    "    - [PINA-Dokumentation - CartesianDomain](https://mathlab.github.io/PINA/_rst/geometry/cartesian.html) \n",
    "- **Randbedingungen (`conditions`)**: Die echten Messwerte (`in sigma_0, delta_epsilon` `out sigma_1_train`) werden als Randbedingung (`Condition`) für das Modell definiert.\n",
    "    - [PINA-Dokumentation - Condition](https://mathlab.github.io/PINA/_rst/condition.html) \n",
    "- **\"Wahre Lösung\" (`truth_solution`)**: Falls erforderlich, kann eine analytische Lösung (hier `torch.exp(...)`) zur Validierung genutzt werden.\n",
    "    - **Hinweis:** Funktioniert in unserem Fall nicht, da die Implementierung nicht für reine Input und Outpunkt Punkte implementiert ist.\n",
    "    - [PINA-Tutorial - Physics Informed Neural Networks on PINA](https://mathlab.github.io/PINA/_rst/tutorials/tutorial1/tutorial.html) \n",
    "- **Probleminstanz (`problem = SimpleODE()`)**: Erstellt das Problem, das für das Training eines PINN verwendet wird.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2de5194c7f49fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:31.712233Z",
     "start_time": "2025-03-12T08:30:31.590633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Geladene Input Variablen:  ['sigma_0', 'delta_epsilon']\n",
      "‼️Geladene Output Variablen:  ['sigma_1']\n",
      "‼️Input points: {'data': LabelTensor([[[1.0000e+00, 5.0000e-04]],\n",
      "             [[1.2000e+00, 5.0000e-04]],\n",
      "             [[1.4400e+00, 5.0000e-04]],\n",
      "             [[1.7280e+00, 5.0000e-04]],\n",
      "             [[2.0736e+00, 5.0000e-04]],\n",
      "             [[2.4883e+00, 5.0000e-04]],\n",
      "             [[2.9860e+00, 5.0000e-04]],\n",
      "             [[3.5832e+00, 5.0000e-04]],\n",
      "             [[4.2998e+00, 5.0000e-04]],\n",
      "             [[5.1598e+00, 5.0000e-04]],\n",
      "             [[6.1917e+00, 5.0000e-04]],\n",
      "             [[7.4301e+00, 5.0000e-04]],\n",
      "             [[8.9161e+00, 5.0000e-04]],\n",
      "             [[1.0699e+01, 5.0000e-04]],\n",
      "             [[1.2839e+01, 5.0000e-04]],\n",
      "             [[1.5407e+01, 5.0000e-04]],\n",
      "             [[1.8488e+01, 5.0000e-04]],\n",
      "             [[2.2186e+01, 5.0000e-04]],\n",
      "             [[2.6623e+01, 5.0000e-04]],\n",
      "             [[3.1948e+01, 5.0000e-04]]])}\n"
     ]
    }
   ],
   "source": [
    "from pina.problem import AbstractProblem\n",
    "from pina.geometry import CartesianDomain\n",
    "from pina import Condition\n",
    "class SimpleODE(AbstractProblem):\n",
    "\n",
    "    # Definition der Eingabe- und Ausgabevariablen basierend auf LabelTensor\n",
    "    input_variables = input_points_combined.labels\n",
    "    output_variables = sigma_1_train.labels\n",
    "\n",
    "    # Wertebereich\n",
    "    domain = CartesianDomain({'sigma_0': [0, 1], 'delta_epsilon': [0, 1]})  # Wertebereich immer definieren!\n",
    "\n",
    "    # Definition der Randbedingungen und (hier: nur) vorberechnetet Punkte\n",
    "    conditions = {\n",
    "        'data': Condition(input_points=input_points_combined, output_points=sigma_1_train),\n",
    "    }\n",
    "\n",
    "    output_pts=sigma_1_train\n",
    "\n",
    "    # Methode zur Definition der \"wahren Lösung\" des Problems\n",
    "    def truth_solution(self, pts):\n",
    "        return torch.exp(pts.extract(['sigma_0']))\n",
    "\n",
    "# Problem-Instanz erzeugen\n",
    "problem = SimpleODE()\n",
    "\n",
    "# Datengenerierung, falls Randbedingungen definiert\n",
    "# problem.discretise_domain(n=993, mode='random', variables='all', locations='all') # Notwendig, wenn \"input_pts\" und \"output_pts\" nicht vorgegeben sind\n",
    "\n",
    "if debug_mode:\n",
    "    # Debugging-Ausgaben\n",
    "    print(\"‼️Geladene Input Variablen: \", problem.input_variables)\n",
    "    print(\"‼️Geladene Output Variablen: \", problem.output_variables)\n",
    "    print('‼️Input points:', problem.input_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017454f5732f1b5",
   "metadata": {},
   "source": [
    "## Visualisierung Sampling\n",
    "Darstellung Input: `sigma_0` und `delta_epsilon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8177115081d371bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:30:33.410973Z",
     "start_time": "2025-03-12T08:30:32.818773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![Result of sampling](./graph/visual_sampling.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pina import Plotter\n",
    "\n",
    "pl = Plotter()\n",
    "pl.plot_samples(problem=problem, filename='./graph/visual_sampling.png', variables=['delta_epsilon','sigma_0'])\n",
    "display(Markdown('![Result of sampling](./graph/visual_sampling.png)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b78c6b-22bf-4a9a-8d00-be05b47deb71",
   "metadata": {},
   "source": [
    "## **Training eines Physics-Informed Neural Networks (PINN) mit PINA**\n",
    "\n",
    "Dieser Code definiert und trainiert ein **Physics-Informed Neural Network (PINN)** zur Lösung des Problems in PINA.\n",
    "\n",
    "- **Modell (`FeedForward`)**: Ein neuronales Netz mit drei versteckten Schichten (`[50, 50, 50]`), das mit der ReLU-Aktivierungsfunktion arbeitet.\n",
    "- **PINN-Objekt (`PINN`)**: Erstellt das PINN-Modell, das die physikalischen Randbedingungen des Problems berücksichtigt.\n",
    "- **TensorBoard-Logger (`TensorBoardLogger`)**: Speichert Trainingsmetriken zur Visualisierung.\n",
    "- **Trainer (`Trainer`)**: Führt das Training für 1500 Epochen mit Batch-Größe 10 durch.\n",
    "- **Training starten (`trainer.train()`)**: Startet den Optimierungsprozess und protokolliert die Metriken.\n",
    "\n",
    "Am Ende wird die **finale Loss-Funktion** ausgegeben, um die Trainingsqualität zu bewerten.\n",
    "\n",
    "**Mehr zu `Trainer`:**  \n",
    "[PINA-Dokumentation – Trainer](https://mathlab.github.io/PINA/_rst/trainer.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb7ce50b0b515f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-12T08:30:34.000486Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Info:\n",
      "‼️Länge der Eingabepunkte (input_pts): 20\n",
      "‼️Länge der Ausgabepunkte (output_pts): 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hab185\\Documents\\00_Tim\\01_Implementierung\\pina_oedometer\\venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c581f3875422482caa7b52fa2c96aac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finale Loss Werte\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_loss': tensor(5.7616e-07), 'mean_loss': tensor(5.7616e-07)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pina import Trainer\n",
    "from pina.solvers import PINN\n",
    "from pina.model import FeedForward\n",
    "from pina.callbacks import MetricTracker\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  # Import TensorBoard Logger\n",
    "\n",
    "if debug_mode:\n",
    "    print('Debugging Info:')\n",
    "    # Überprüfen der Größe der Eingabepunkte und Ausgabepunkte\n",
    "    print(\"‼️Länge der Eingabepunkte (input_pts):\", len(problem.input_pts['data']))\n",
    "    print(\"‼️Länge der Ausgabepunkte (output_pts):\", len(problem.output_pts))\n",
    "\n",
    "# Model erstellen\n",
    "model = FeedForward(\n",
    "    layers=[50, 50, 50],\n",
    "    func=torch.nn.ReLU,\n",
    "    output_dimensions=len(problem.output_variables),\n",
    "    input_dimensions=len(problem.input_variables)\n",
    ")\n",
    "\n",
    "# PINN-Objekt erstellen\n",
    "pinn = PINN(problem, model)\n",
    "\n",
    "# TensorBoard-Logger\n",
    "logger = TensorBoardLogger(\"tensorboard_logs\", name=\"pina_experiment\")\n",
    "\n",
    "# Trainer erstellen mit TensorBoard-Logger\n",
    "trainer = Trainer(\n",
    "    solver=pinn,\n",
    "    max_epochs=1000,\n",
    "    callbacks=[MetricTracker()],\n",
    "    batch_size=10,\n",
    "    accelerator='cpu',\n",
    "    logger=logger,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Training starten\n",
    "trainer.train()\n",
    "\n",
    "print('\\nFinale Loss Werte')\n",
    "# Inspect final loss\n",
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a21a7-66f3-4684-b49f-e1d1aeaaa974",
   "metadata": {},
   "source": [
    "## **Visualisierung der Modellvorhersage für sigma_1**\n",
    "\n",
    "Dieser Code erstellt einen **Plot der wahren Werte (`sigma_1`)** im Vergleich zur **Vorhersage des neuronalen Netzwerks**.\n",
    "\n",
    "- **Datenvorbereitung (`input_data`)**: Die Eingabedaten (`sigma_0` und `delta_epsilon`) werden als `LabelTensor` für das trainierte Modell erstellt.\n",
    "- **Modellvorhersage (`pinn(input_data)`)**: Das trainierte PINN-Modell gibt eine Prognose für `sigma_1` aus.\n",
    "- **Plot-Erstellung mit `matplotlib`**:  \n",
    "  - Die wahre Lösung (`sigma_1`) wird als **blaue gestrichelte Linie** dargestellt.  \n",
    "  - Die Vorhersage des neuronalen Netzwerks wird als **rote durchgezogene Linie** geplottet.  \n",
    "\n",
    "**Zusätzlicher Schritt:**  \n",
    "Die Nutzung von `matplotlib` war notwendig, da die interne Plot-Funktion von PINA `pl.plot()` das Diagramm nicht wie in den Tutorials erwartungsgemäß generierte, selbst wenn `delta_epsilon` auf einen fixen Wert gesetzt wurde. Dies könnte auf eine fehlerhafte Nutzung der Funktion oder auf eine Inkompatibilität in der Darstellung zurückzuführen sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de070fe2-16f3-40f1-8602-36aebfb3818a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-Loss bis simga_19\n",
      "\n",
      "     sigma_t  True sigma_t+1  Predicted sigma_t+1  Loss (True - Predicted)\n",
      "0    1.00000         0.20000              0.20023                 -0.00023\n",
      "1    1.20000         0.24000              0.23986                  0.00014\n",
      "2    1.44000         0.28800              0.28768                  0.00032\n",
      "3    1.72800         0.34560              0.34581                 -0.00021\n",
      "4    2.07360         0.41472              0.41472                 -0.00000\n",
      "5    2.48832         0.49766              0.49814                 -0.00048\n",
      "6    2.98598         0.59720              0.59679                  0.00041\n",
      "7    3.58318         0.71664              0.71615                  0.00048\n",
      "8    4.29982         0.85996              0.85938                  0.00059\n",
      "9    5.15978         1.03196              1.03295                 -0.00099\n",
      "10   6.19174         1.23835              1.23977                 -0.00142\n",
      "11   7.43008         1.48602              1.48690                 -0.00089\n",
      "12   8.91610         1.78322              1.78347                 -0.00025\n",
      "13  10.69932         2.13986              2.13934                  0.00052\n",
      "14  12.83918         2.56784              2.56639                  0.00144\n",
      "15  15.40702         3.08140              3.08001                  0.00140\n",
      "16  18.48843         3.69769              3.69703                  0.00066\n",
      "17  22.18611         4.43722              4.43745                 -0.00023\n",
      "18  26.62333         5.32467              5.32596                 -0.00130\n",
      "19  31.94800         6.38960              6.38960                  0.00000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "![Prediction vs True Solution](./graph/visual_prediction-vs-truesolution.png)<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg') # Keine doppelte Darstellung des Plottes\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "max_i = 20\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((data_dict['sigma_0'], data_dict['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_0', 'delta_epsilon'])\n",
    "\n",
    "# Model-Vorhersage für sigma_1 berechnen\n",
    "sigma_1_pred = pinn(input_data).detach().numpy()\n",
    "\n",
    "# Plot der wahren vs. vorhergesagten Werte\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(data_dict['sigma_0'][0:max_i], data_dict['sigma_1'][0:max_i], label=\"True Solution (sigma_1)\", linestyle='dashed', color='blue')\n",
    "plt.plot(data_dict['sigma_0'][0:max_i], sigma_1_pred[0:max_i], label=\"NN Prediction (sigma_1)\", linestyle='solid', color='red')\n",
    "\n",
    "plt.xlabel(\"sigma_0\")\n",
    "plt.ylabel(\"sigma_1\")\n",
    "plt.title(f\"Prediction vs. True Solution (delta_epsilon=0.0005, max_i={str(max_i-1)})\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('./graph/visual_prediction-vs-truesolution.png',)\n",
    "\n",
    "# Überprüfen, ob die notwendigen Variablen existieren\n",
    "if 'data_dict' in globals() and 'sigma_1_pred' in globals():\n",
    "    # Erstelle eine Tabelle für die übersichtliche Darstellung\n",
    "    data_loss_table = pd.DataFrame({\n",
    "        \"sigma_t\": np.round(data_dict[\"sigma_0\"][0:max_i], 5),\n",
    "        \"True sigma_t+1\": np.round(data_dict[\"sigma_1\"][0:max_i], 5),\n",
    "        \"Predicted sigma_t+1\": np.round(sigma_1_pred[0:max_i].flatten(), 5),\n",
    "        \"Loss (True - Predicted)\": np.round(data_dict[\"sigma_1\"][0:max_i] - sigma_1_pred[0:max_i].flatten(), 5)\n",
    "    })\n",
    "\n",
    "    pd.set_option('display.max_rows', None)  # Keine Begrenzung der Zeilen\n",
    "    pd.set_option('display.max_columns', None)  # Keine Begrenzung der Spalten\n",
    "    pd.set_option('display.width', 1000)  # Breite für bessere Lesbarkeit\n",
    "\n",
    "    print(f'Data-Loss bis simga_{str(max_i-1)}\\n')\n",
    "    print(data_loss_table)\n",
    "else:\n",
    "    print(\"Fehler: `data_dict` oder `sigma_1_pred` ist nicht definiert!\")\n",
    "\n",
    "display(Markdown('![Prediction vs True Solution](./graph/visual_prediction-vs-truesolution.png)<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51709f02-c3c7-4076-b873-41e9d45d0c97",
   "metadata": {},
   "source": [
    "## Visualisierung Error-Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367434e3c1076341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:26:45.282465Z",
     "start_time": "2025-03-12T08:26:44.026059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![NN Error result](./graph/visual_nn-result-error.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.plot(solver=pinn, filename='./graph/visual_nn-result-error.png')\n",
    "display(Markdown('![NN Error result](./graph/visual_nn-result-error.png)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875cc14cf077767",
   "metadata": {},
   "source": [
    "## Visualisierung Loss-Kurve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc792fe16f92e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:21:28.768753Z",
     "start_time": "2025-03-12T08:21:26.295329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![Loss Kurve](./graph/visual_loss.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the solution\n",
    "pl.plot_loss(trainer, label='mean_loss', logy=True, filename='./graph/visual_loss.png')\n",
    "display(Markdown('![Loss Kurve](./graph/visual_loss.png)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979e1d6-7feb-442b-b59f-afe2593f58d6",
   "metadata": {},
   "source": [
    "# Fazit\n",
    "\n",
    "Das Problem dieser Implementation ist, dass wir das Modell mit 20 Inpt Parametern gefüttert haben, die daraufhin auch immer erneut gefordert werden. Es ist also nicht möglich einen einzelnen Wert zu bestimmen, da das Modell nun weitere 19 Parameter braucht, um weitere Ausgaben zu generieren. <br>\n",
    "\n",
    "Im folgenden wird dargestellt, wie es aussehen würde, wenn man bspw. das Modell mit einem Tensor füttert, der nur den ersten Wert mit einem Wert gefüllt hat (Rest 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38bb6ae2-4899-447e-932e-73df4d710efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‼️Geladene Exceldaten\n",
      "{'sigma_0': array([1500,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int64), 'delta_epsilon': array([0.0005, 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.    , 0.    , 0.    ]), 'sigma_1': array([300,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0], dtype=int64)}\n",
      "Data-Loss bis sigma_19\n",
      "\n",
      "    sigma_t  True sigma_t+1  Predicted sigma_t+1  Loss (True - Predicted)\n",
      "0      1500             300           299.636871                  0.36313\n",
      "1         0               0             0.038610                 -0.03861\n",
      "2         0               0             0.038610                 -0.03861\n",
      "3         0               0             0.038610                 -0.03861\n",
      "4         0               0             0.038610                 -0.03861\n",
      "5         0               0             0.038610                 -0.03861\n",
      "6         0               0             0.038610                 -0.03861\n",
      "7         0               0             0.038610                 -0.03861\n",
      "8         0               0             0.038610                 -0.03861\n",
      "9         0               0             0.038610                 -0.03861\n",
      "10        0               0             0.038610                 -0.03861\n",
      "11        0               0             0.038610                 -0.03861\n",
      "12        0               0             0.038610                 -0.03861\n",
      "13        0               0             0.038610                 -0.03861\n",
      "14        0               0             0.038610                 -0.03861\n",
      "15        0               0             0.038610                 -0.03861\n",
      "16        0               0             0.038610                 -0.03861\n",
      "17        0               0             0.038610                 -0.03861\n",
      "18        0               0             0.038610                 -0.03861\n",
      "19        0               0             0.038610                 -0.03861\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "![Prediction vs True Solution](./graph/visual_prediction-vs-truesolution_comp.png)<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_data = extract_excel(file_path=\"files/oedometer/oedo_trainingsdata_compare.xlsx\", sheet_name=\"Res\", selected_columns=[1, 3, 5], row_start_range=0)\n",
    "\n",
    "# Erstelle die Eingabedaten als LabelTensor für das trainierte Modell\n",
    "input_data = LabelTensor(torch.tensor(\n",
    "    np.column_stack((new_data['sigma_0'], new_data['delta_epsilon'])), dtype=torch.float\n",
    "), ['sigma_0', 'delta_epsilon'])\n",
    "\n",
    "# Model-Vorhersage für sigma_1 berechnen\n",
    "sigma_1_pred = pinn(input_data).detach().numpy()\n",
    "\n",
    "# Plot der wahren vs. vorhergesagten Werte\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# True Solution als Punkte darstellen\n",
    "plt.scatter(new_data['sigma_0'][0:max_i], new_data['sigma_1'][0:max_i], label=\"True Solution (sigma_1)\", color='blue', marker='o')\n",
    "# NN Prediction als Linie darstellen\n",
    "plt.scatter(new_data['sigma_0'][0:max_i], sigma_1_pred[0:max_i], label=\"NN Prediction (sigma_1)\", linestyle='solid', color='red')\n",
    "\n",
    "plt.xlabel(\"sigma_0\")\n",
    "plt.ylabel(\"sigma_1\")\n",
    "plt.title(f\"Prediction vs. True Solution (delta_epsilon=0.0005, max_i={str(max_i-1)})\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('./graph/visual_prediction-vs-truesolution_comp.png')\n",
    "\n",
    "# Überprüfen, ob die notwendigen Variablen existieren\n",
    "if 'data_dict' in globals() and 'sigma_1_pred' in globals():\n",
    "    # Erstelle eine Tabelle für die übersichtliche Darstellung\n",
    "    data_loss_table = pd.DataFrame({\n",
    "        \"sigma_t\": np.round(new_data[\"sigma_0\"][0:max_i], 5),\n",
    "        \"True sigma_t+1\": np.round(new_data[\"sigma_1\"][0:max_i], 5),\n",
    "        \"Predicted sigma_t+1\": np.round(sigma_1_pred[0:max_i].flatten(), 5),\n",
    "        \"Loss (True - Predicted)\": np.round(new_data[\"sigma_1\"][0:max_i] - sigma_1_pred[0:max_i].flatten(), 5)\n",
    "    })\n",
    "\n",
    "    pd.set_option('display.max_rows', None)  # Keine Begrenzung der Zeilen\n",
    "    pd.set_option('display.max_columns', None)  # Keine Begrenzung der Spalten\n",
    "    pd.set_option('display.width', 1000)  # Breite für bessere Lesbarkeit\n",
    "\n",
    "    print(f'Data-Loss bis sigma_{str(max_i-1)}\\n')\n",
    "    print(data_loss_table)\n",
    "else:\n",
    "    print(\"Fehler: `data_dict` oder `sigma_1_pred` ist nicht definiert!\")\n",
    "\n",
    "display(Markdown('![Prediction vs True Solution](./graph/visual_prediction-vs-truesolution_comp.png)<br>**Hinweis:** Datenpunkte liegen sehr nahe beieinander.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb148e33-5cce-4311-91f3-f4e11197f8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
